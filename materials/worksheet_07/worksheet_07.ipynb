{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f1e1d845873036f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 7: Model Evaluation and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-82d9926086d47a80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Lecture and Tutorial Learning Goals:\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "\n",
    "1. List model metrics that are suitable for evaluation of a statistical model developed to make inference about the data-generating mechanism (e.g., $R^2$, $\\text{AIC}$, Likelihood ratio test/$F$-test), their strengths and limitations, as well as how they are calculated.\n",
    "2. Write a computer script to calculate these model metrics. Interpret and communicate the results from that computer script.\n",
    "3. Explain the algorithms for the following variable selection methods:\n",
    "\n",
    "    - $F$-test to compare nested models.\n",
    "    - Forward selection.\n",
    "    - Backward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a2a153352bc44a68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6      \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.5 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8      \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.10\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1      \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.3      \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2 \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Attaching package: ‘testthat’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    matches\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    is_null\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:readr’:\n",
      "\n",
      "    edition_get, local_edition\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    matches\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before continuing.\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(broom)\n",
    "library(leaps)\n",
    "library(latex2exp)\n",
    "source(\"tests_worksheet_07.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30d72e348848492c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART I: Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-459184ff51dbea84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Inference vs Predition\n",
    "\n",
    "To assess or select a model there is a more essential question to answer: \n",
    "    \n",
    "### <font color=red>  What is your goal??\n",
    "    \n",
    "The evaluation metrics are different depending on the goal of the analysis\n",
    "    \n",
    "> the estimation methodologies can also differ although we cover only LS in the course\n",
    "    \n",
    "- **Inference**: your primary goal is to understand the relation between a response variable $Y$ and a set of input variables $X_1, \\ldots, X_p$ \n",
    "    \n",
    "    > you estimate the LR using a sample to understand how variables are associated (in the population)\n",
    "    \n",
    "    > you use methods to draw conclusions about the population from the results obtained in the sample (inference)\n",
    "    \n",
    "- **Prediction**: your primary goal is to make predictions about the response $Y$, and you are not so concerned about how you got those predictions\n",
    "    \n",
    "    > you estimate the LR using a sample to make predictions of the response for *new* units (houses, subjects, counties, etc) from the population\n",
    "    \n",
    "    \n",
    "**Examples of inference problems**: \n",
    "    \n",
    "- A real estate agent wants to identify factors that are related to the assessed values of homes (e.g., size of houses, age, amenities, etc) \n",
    "    \n",
    "    \n",
    "- Biologists want to verify empirically the central dogma of biology that relates mRNA to protein values \n",
    "    \n",
    "    \n",
    "**Examples of prediction problems**: \n",
    "    \n",
    "\n",
    "- A real estate agent is interested in determining if a house is under- or over-valued given its characteristics (prediction problem)\n",
    "\n",
    "\n",
    "- Biologists want to use mRNA data to predict protein values\n",
    "    \n",
    "**In this worksheet you will learn different methods to evaluate and select appropriate models depending on the goal of your study.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9be71f65643c5906",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Case Study: protein vs mRNA\n",
    "\n",
    "In this section we will introduce a new case study to learn how to examine the goodness of the fitted model and choose among different nested models. The data and some of the discussions related to this case were published in Nature (see citations below).\n",
    "\n",
    "In 2014, a research group claimed to find a \"predictive model\", which can be used to predict protein from mRNA expression!! \n",
    "\n",
    "> Wilhelm, M. et al. Mass-spectrometry-based draft of the human proteome. Nature 509, 582–587 (2014)\n",
    "\n",
    "Although their hypotheses were funded in the Central Dogma of Biology, most experimental results have shown very low correlation values between protein and mRNA values. \n",
    "\n",
    "Further examination of their analysis has shwon that their data do not support their claims:\n",
    "\n",
    "> Paper from my research group: Fortelny N, Overall CM, Pavlidis P, Freue GVC. Can we predict protein from mRNA levels? Nature. 2017 Jul 26;547(7664):E19-E20. doi: 10.1038/nature22293.\n",
    "\n",
    "We'll use data from this group submitted to the Journal to (re)analyse their data and evalute different models using concepts learned in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2f2ad804e83a969",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Relation between mRNA and protein levels\n",
    "\n",
    "The picture illustrates what is known as the Central Dogma of Biology\n",
    "\n",
    "![](https://github.com/UBC-STAT/stat-301/blob/master/materials/worksheet_07/img/prot_gene.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5104ce4905d3cf2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's start by taking a glance at the data.\n",
    "\n",
    "> Protein and mRNA values were measured for 6104 genes on 12 different tissues. \n",
    "\n",
    "Note that these are 2 different dataset!! \n",
    "\n",
    "> However, many proteins were not detected by the technology used due to values below limits of detection and the protein dataset contains many missing values!! \n",
    "\n",
    "For simplicity, we will use **a set of 1392 genes** that were measured in **all 12 tissues** and thus contain complete data on both protein and mRNA sets. \n",
    "\n",
    "You can find in Canvas the script that was used to wrangle the original datases from the Journal.\n",
    "\n",
    "*Run the cell below before continuing to read in the data.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c3a6eba286971086",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t16704 obs. of  4 variables:\n",
      " $ gene  : Factor w/ 1392 levels \"ENSG00000000419\",..: 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ tissue: Factor w/ 12 levels \"adrenal.gland\",..: 12 12 12 12 12 12 12 12 12 12 ...\n",
      " $ prot  : num  9.97e-06 3.63e-05 1.69e-05 6.75e-05 5.55e-05 ...\n",
      " $ mrna  : num  3.44e-05 1.42e-05 1.92e-05 3.64e-05 3.89e-05 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>gene</th><th scope=col>tissue</th><th scope=col>prot</th><th scope=col>mrna</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>ENSG00000000419</td><td>uterus</td><td>9.966484e-06</td><td>3.44e-05</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>ENSG00000000971</td><td>uterus</td><td>3.633516e-05</td><td>1.42e-05</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>ENSG00000001084</td><td>uterus</td><td>1.693588e-05</td><td>1.92e-05</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & gene & tissue & prot & mrna\\\\\n",
       "  & <fct> & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & ENSG00000000419 & uterus & 9.966484e-06 & 3.44e-05\\\\\n",
       "\t3 & ENSG00000000971 & uterus & 3.633516e-05 & 1.42e-05\\\\\n",
       "\t5 & ENSG00000001084 & uterus & 1.693588e-05 & 1.92e-05\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 4\n",
       "\n",
       "| <!--/--> | gene &lt;fct&gt; | tissue &lt;fct&gt; | prot &lt;dbl&gt; | mrna &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | ENSG00000000419 | uterus | 9.966484e-06 | 3.44e-05 |\n",
       "| 3 | ENSG00000000971 | uterus | 3.633516e-05 | 1.42e-05 |\n",
       "| 5 | ENSG00000001084 | uterus | 1.693588e-05 | 1.92e-05 |\n",
       "\n"
      ],
      "text/plain": [
       "  gene            tissue prot         mrna    \n",
       "1 ENSG00000000419 uterus 9.966484e-06 3.44e-05\n",
       "3 ENSG00000000971 uterus 3.633516e-05 1.42e-05\n",
       "5 ENSG00000001084 uterus 1.693588e-05 1.92e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 3 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>gene</th><th scope=col>tissue</th><th scope=col>prot</th><th scope=col>mrna</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>57882</th><td>ENSG00000262246</td><td>esophagus</td><td>3.337902e-05</td><td>6.90e-06</td></tr>\n",
       "\t<tr><th scope=row>57886</th><td>ENSG00000269190</td><td>esophagus</td><td>3.703505e-06</td><td>7.80e-06</td></tr>\n",
       "\t<tr><th scope=row>57888</th><td>ENSG00000272325</td><td>esophagus</td><td>2.574201e-05</td><td>1.35e-05</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 3 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & gene & tissue & prot & mrna\\\\\n",
       "  & <fct> & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t57882 & ENSG00000262246 & esophagus & 3.337902e-05 & 6.90e-06\\\\\n",
       "\t57886 & ENSG00000269190 & esophagus & 3.703505e-06 & 7.80e-06\\\\\n",
       "\t57888 & ENSG00000272325 & esophagus & 2.574201e-05 & 1.35e-05\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 3 × 4\n",
       "\n",
       "| <!--/--> | gene &lt;fct&gt; | tissue &lt;fct&gt; | prot &lt;dbl&gt; | mrna &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 57882 | ENSG00000262246 | esophagus | 3.337902e-05 | 6.90e-06 |\n",
       "| 57886 | ENSG00000269190 | esophagus | 3.703505e-06 | 7.80e-06 |\n",
       "| 57888 | ENSG00000272325 | esophagus | 2.574201e-05 | 1.35e-05 |\n",
       "\n"
      ],
      "text/plain": [
       "      gene            tissue    prot         mrna    \n",
       "57882 ENSG00000262246 esophagus 3.337902e-05 6.90e-06\n",
       "57886 ENSG00000269190 esophagus 3.703505e-06 7.80e-06\n",
       "57888 ENSG00000272325 esophagus 2.574201e-05 1.35e-05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read and take a look at the data.\n",
    "dat_bio <- read.csv(\"data/nature_dat.csv\", row.names = 1, stringsAsFactors=TRUE)\n",
    "str(dat_bio)\n",
    "head(dat_bio,3)\n",
    "tail(dat_bio,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e6b7bf58e2eb7a77",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can think that we have **1392 datasets**, one for each gene!\n",
    "\n",
    "> each dataset contains **12 observations**, one per tissue, and 2 variables, `protein` and `mrna`, along with an accession number for the gene (`gene`, an ID for each gene) and the name of the tissue (`tissue`, that works as an ID for each observation).\n",
    "\n",
    "*Run the cell below to get the data for gene ENSG00000085733.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-28e85de12a1890ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 12 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>gene</th><th scope=col>tissue</th><th scope=col>prot</th><th scope=col>mrna</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>585</th><td>ENSG00000085733</td><td>uterus        </td><td>1.648298e-06</td><td>0.0001278</td></tr>\n",
       "\t<tr><th scope=row>5409</th><td>ENSG00000085733</td><td>kidney        </td><td>1.349573e-05</td><td>0.0000673</td></tr>\n",
       "\t<tr><th scope=row>10233</th><td>ENSG00000085733</td><td>testis        </td><td>4.069264e-05</td><td>0.0000862</td></tr>\n",
       "\t<tr><th scope=row>15057</th><td>ENSG00000085733</td><td>pancreas      </td><td>9.279162e-06</td><td>0.0000358</td></tr>\n",
       "\t<tr><th scope=row>19881</th><td>ENSG00000085733</td><td>stomach       </td><td>2.254923e-05</td><td>0.0001167</td></tr>\n",
       "\t<tr><th scope=row>24705</th><td>ENSG00000085733</td><td>prostate      </td><td>6.259907e-06</td><td>0.0000931</td></tr>\n",
       "\t<tr><th scope=row>29529</th><td>ENSG00000085733</td><td>ovary         </td><td>8.225857e-05</td><td>0.0001345</td></tr>\n",
       "\t<tr><th scope=row>34353</th><td>ENSG00000085733</td><td>thyroid.gland </td><td>5.948111e-07</td><td>0.0000885</td></tr>\n",
       "\t<tr><th scope=row>39177</th><td>ENSG00000085733</td><td>adrenal.gland </td><td>2.461557e-05</td><td>0.0001172</td></tr>\n",
       "\t<tr><th scope=row>44001</th><td>ENSG00000085733</td><td>salivary.gland</td><td>6.050506e-05</td><td>0.0000661</td></tr>\n",
       "\t<tr><th scope=row>48825</th><td>ENSG00000085733</td><td>spleen        </td><td>1.854525e-05</td><td>0.0000661</td></tr>\n",
       "\t<tr><th scope=row>53649</th><td>ENSG00000085733</td><td>esophagus     </td><td>1.872389e-05</td><td>0.0000857</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 12 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & gene & tissue & prot & mrna\\\\\n",
       "  & <fct> & <fct> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t585 & ENSG00000085733 & uterus         & 1.648298e-06 & 0.0001278\\\\\n",
       "\t5409 & ENSG00000085733 & kidney         & 1.349573e-05 & 0.0000673\\\\\n",
       "\t10233 & ENSG00000085733 & testis         & 4.069264e-05 & 0.0000862\\\\\n",
       "\t15057 & ENSG00000085733 & pancreas       & 9.279162e-06 & 0.0000358\\\\\n",
       "\t19881 & ENSG00000085733 & stomach        & 2.254923e-05 & 0.0001167\\\\\n",
       "\t24705 & ENSG00000085733 & prostate       & 6.259907e-06 & 0.0000931\\\\\n",
       "\t29529 & ENSG00000085733 & ovary          & 8.225857e-05 & 0.0001345\\\\\n",
       "\t34353 & ENSG00000085733 & thyroid.gland  & 5.948111e-07 & 0.0000885\\\\\n",
       "\t39177 & ENSG00000085733 & adrenal.gland  & 2.461557e-05 & 0.0001172\\\\\n",
       "\t44001 & ENSG00000085733 & salivary.gland & 6.050506e-05 & 0.0000661\\\\\n",
       "\t48825 & ENSG00000085733 & spleen         & 1.854525e-05 & 0.0000661\\\\\n",
       "\t53649 & ENSG00000085733 & esophagus      & 1.872389e-05 & 0.0000857\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 12 × 4\n",
       "\n",
       "| <!--/--> | gene &lt;fct&gt; | tissue &lt;fct&gt; | prot &lt;dbl&gt; | mrna &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 585 | ENSG00000085733 | uterus         | 1.648298e-06 | 0.0001278 |\n",
       "| 5409 | ENSG00000085733 | kidney         | 1.349573e-05 | 0.0000673 |\n",
       "| 10233 | ENSG00000085733 | testis         | 4.069264e-05 | 0.0000862 |\n",
       "| 15057 | ENSG00000085733 | pancreas       | 9.279162e-06 | 0.0000358 |\n",
       "| 19881 | ENSG00000085733 | stomach        | 2.254923e-05 | 0.0001167 |\n",
       "| 24705 | ENSG00000085733 | prostate       | 6.259907e-06 | 0.0000931 |\n",
       "| 29529 | ENSG00000085733 | ovary          | 8.225857e-05 | 0.0001345 |\n",
       "| 34353 | ENSG00000085733 | thyroid.gland  | 5.948111e-07 | 0.0000885 |\n",
       "| 39177 | ENSG00000085733 | adrenal.gland  | 2.461557e-05 | 0.0001172 |\n",
       "| 44001 | ENSG00000085733 | salivary.gland | 6.050506e-05 | 0.0000661 |\n",
       "| 48825 | ENSG00000085733 | spleen         | 1.854525e-05 | 0.0000661 |\n",
       "| 53649 | ENSG00000085733 | esophagus      | 1.872389e-05 | 0.0000857 |\n",
       "\n"
      ],
      "text/plain": [
       "      gene            tissue         prot         mrna     \n",
       "585   ENSG00000085733 uterus         1.648298e-06 0.0001278\n",
       "5409  ENSG00000085733 kidney         1.349573e-05 0.0000673\n",
       "10233 ENSG00000085733 testis         4.069264e-05 0.0000862\n",
       "15057 ENSG00000085733 pancreas       9.279162e-06 0.0000358\n",
       "19881 ENSG00000085733 stomach        2.254923e-05 0.0001167\n",
       "24705 ENSG00000085733 prostate       6.259907e-06 0.0000931\n",
       "29529 ENSG00000085733 ovary          8.225857e-05 0.0001345\n",
       "34353 ENSG00000085733 thyroid.gland  5.948111e-07 0.0000885\n",
       "39177 ENSG00000085733 adrenal.gland  2.461557e-05 0.0001172\n",
       "44001 ENSG00000085733 salivary.gland 6.050506e-05 0.0000661\n",
       "48825 ENSG00000085733 spleen         1.854525e-05 0.0000661\n",
       "53649 ENSG00000085733 esophagus      1.872389e-05 0.0000857"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dat_g1 <- dat_bio  %>% subset(gene == \"ENSG00000085733\") \n",
    "dat_g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4135e761a8664bad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.Estimation and Inference\n",
    "\n",
    "In the paper, the authors used a linear regression to estimate the relation between protein and mRNA levels *per gene*, and used that model to predict protein levels *per gene*.\n",
    "\n",
    "> it will be important at a later phase of the analysis to note that models are *gene-specific*\n",
    "\n",
    "**Gene-specific models**: for each gene they estimated the following model (for simplicity we do not use a subscript $g$)  \n",
    "\n",
    "$$\\text{prot}_{t} = \\beta_1 \\; \\times \\text{mrna}_{t} + \\varepsilon$$ \n",
    "\n",
    "where $\\hat{\\beta}_1 = median_t(\\text{mrna}_{t}/\\text{prot}_{t})$\n",
    "\n",
    "> $prot_{t}$ and $mrna_{t}$ are the protein and mRNA levels of a gene $g$ in tissue $t$, respectively\n",
    "\n",
    "<font color=\"blue\"> **Note that these models do not contain an intercept! and they were not estimated by LS.**</font> \n",
    "    \n",
    "While in general different models and estimation methods can be used to analyze the same data, it is important to evaluate the results according to the assumptions and the methodology used. \n",
    "    \n",
    "> The evaluation and interpretation of the results in the paper were not appropriate\n",
    "    \n",
    "*We will start by (re)anlayzing the data using a SLR and LS estimation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f76d01efb9d4c744",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Gene-specific SLR**: for each gene we will use LS to estimate the following SLR (for simplicity we do not use a subscript $g$)  \n",
    "\n",
    "$$prot_{t} = \\beta_0 +\\beta_1 \\; \\times mrna_{t} + \\varepsilon$$ \n",
    "\n",
    "where $\\hat{\\beta}_g$ is estimated by LS\n",
    "\n",
    "> using `lm()` and `group_by(gene)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b8733fe0b705dbdb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Visualization and Estimation:\n",
    "\n",
    "Let's focus on the proposed model for one gene (geneID: ENSG00000085733)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52582d5c438817c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`geom_smooth()` using formula 'y ~ x'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/pdf": "JVBERi0xLjUKJbXtrvsKNCAwIG9iago8PCAvTGVuZ3RoIDUgMCBSCiAgIC9GaWx0ZXIgL0Zs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\nRgo=",
      "image/jpeg": "/9j/4AAQSkZJRgABAQEAeAB4AAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoM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\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAFoCAIAAADxRFtOAAAACXBIWXMAABJ0AAASdAHeZh94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\n25ZLGtisFQAAAABJRU5ErkJggg==",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"432pt\" height=\"216pt\" viewBox=\"0 0 432 216\" version=\"1.1\">\n",
       "<defs>\n",
       "<g>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-0\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.296875 0 L 0.296875 -5.859375 L 2.625 -5.859375 L 2.625 0 Z M 0.578125 -0.296875 L 2.34375 -0.296875 L 2.34375 -5.578125 L 0.578125 -5.578125 Z M 0.578125 -0.296875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.546875 -3.03125 C 4.546875 -2.445312 4.488281 -1.957031 4.375 -1.5625 C 4.269531 -1.164062 4.117188 -0.84375 3.921875 -0.59375 C 3.734375 -0.351562 3.507812 -0.179688 3.25 -0.078125 C 3 0.0234375 2.726562 0.078125 2.4375 0.078125 C 2.144531 0.078125 1.867188 0.0234375 1.609375 -0.078125 C 1.359375 -0.179688 1.140625 -0.351562 0.953125 -0.59375 C 0.765625 -0.84375 0.613281 -1.164062 0.5 -1.5625 C 0.394531 -1.957031 0.34375 -2.445312 0.34375 -3.03125 C 0.34375 -3.632812 0.394531 -4.132812 0.5 -4.53125 C 0.613281 -4.9375 0.765625 -5.257812 0.953125 -5.5 C 1.140625 -5.738281 1.359375 -5.90625 1.609375 -6 C 1.867188 -6.09375 2.15625 -6.140625 2.46875 -6.140625 C 2.75 -6.140625 3.015625 -6.09375 3.265625 -6 C 3.523438 -5.90625 3.75 -5.738281 3.9375 -5.5 C 4.125 -5.257812 4.269531 -4.9375 4.375 -4.53125 C 4.488281 -4.132812 4.546875 -3.632812 4.546875 -3.03125 Z M 3.765625 -3.03125 C 3.765625 -3.507812 3.734375 -3.90625 3.671875 -4.21875 C 3.617188 -4.539062 3.535156 -4.796875 3.421875 -4.984375 C 3.304688 -5.179688 3.164062 -5.316406 3 -5.390625 C 2.84375 -5.472656 2.664062 -5.515625 2.46875 -5.515625 C 2.25 -5.515625 2.054688 -5.472656 1.890625 -5.390625 C 1.722656 -5.316406 1.582031 -5.179688 1.46875 -4.984375 C 1.351562 -4.796875 1.265625 -4.539062 1.203125 -4.21875 C 1.148438 -3.90625 1.125 -3.507812 1.125 -3.03125 C 1.125 -2.5625 1.148438 -2.164062 1.203125 -1.84375 C 1.265625 -1.53125 1.351562 -1.273438 1.46875 -1.078125 C 1.582031 -0.890625 1.71875 -0.753906 1.875 -0.671875 C 2.039062 -0.585938 2.226562 -0.546875 2.4375 -0.546875 C 2.644531 -0.546875 2.828125 -0.585938 2.984375 -0.671875 C 3.148438 -0.753906 3.289062 -0.890625 3.40625 -1.078125 C 3.519531 -1.273438 3.609375 -1.53125 3.671875 -1.84375 C 3.734375 -2.164062 3.765625 -2.5625 3.765625 -3.03125 Z M 3.765625 -3.03125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 1.1875 -2.15625 C 1.1875 -1.914062 1.207031 -1.691406 1.25 -1.484375 C 1.300781 -1.285156 1.378906 -1.109375 1.484375 -0.953125 C 1.597656 -0.804688 1.734375 -0.691406 1.890625 -0.609375 C 2.054688 -0.535156 2.253906 -0.5 2.484375 -0.5 C 2.816406 -0.5 3.082031 -0.5625 3.28125 -0.6875 C 3.488281 -0.820312 3.628906 -0.992188 3.703125 -1.203125 L 4.375 -1.015625 C 4.320312 -0.890625 4.253906 -0.757812 4.171875 -0.625 C 4.085938 -0.488281 3.972656 -0.367188 3.828125 -0.265625 C 3.679688 -0.160156 3.5 -0.078125 3.28125 -0.015625 C 3.0625 0.046875 2.796875 0.078125 2.484375 0.078125 C 1.796875 0.078125 1.269531 -0.125 0.90625 -0.53125 C 0.550781 -0.9375 0.375 -1.546875 0.375 -2.359375 C 0.375 -2.785156 0.425781 -3.148438 0.53125 -3.453125 C 0.644531 -3.753906 0.796875 -4 0.984375 -4.1875 C 1.171875 -4.382812 1.390625 -4.523438 1.640625 -4.609375 C 1.890625 -4.691406 2.160156 -4.734375 2.453125 -4.734375 C 2.835938 -4.734375 3.160156 -4.671875 3.421875 -4.546875 C 3.691406 -4.421875 3.90625 -4.242188 4.0625 -4.015625 C 4.21875 -3.796875 4.328125 -3.535156 4.390625 -3.234375 C 4.460938 -2.929688 4.5 -2.609375 4.5 -2.265625 L 4.5 -2.15625 Z M 3.703125 -2.75 C 3.660156 -3.238281 3.535156 -3.59375 3.328125 -3.8125 C 3.117188 -4.039062 2.820312 -4.15625 2.4375 -4.15625 C 2.3125 -4.15625 2.175781 -4.132812 2.03125 -4.09375 C 1.894531 -4.050781 1.765625 -3.976562 1.640625 -3.875 C 1.515625 -3.769531 1.410156 -3.625 1.328125 -3.4375 C 1.253906 -3.257812 1.207031 -3.03125 1.1875 -2.75 Z M 3.703125 -2.75 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.875 -2.609375 L 2.875 -0.765625 L 2.25 -0.765625 L 2.25 -2.609375 L 0.421875 -2.609375 L 0.421875 -3.234375 L 2.25 -3.234375 L 2.25 -5.078125 L 2.875 -5.078125 L 2.875 -3.234375 L 4.703125 -3.234375 L 4.703125 -2.609375 Z M 2.875 -2.609375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.4375 0 L 0.4375 -0.546875 C 0.582031 -0.878906 0.757812 -1.171875 0.96875 -1.421875 C 1.1875 -1.679688 1.410156 -1.914062 1.640625 -2.125 C 1.867188 -2.332031 2.097656 -2.523438 2.328125 -2.703125 C 2.554688 -2.878906 2.757812 -3.054688 2.9375 -3.234375 C 3.125 -3.410156 3.273438 -3.597656 3.390625 -3.796875 C 3.503906 -3.992188 3.5625 -4.210938 3.5625 -4.453125 C 3.5625 -4.628906 3.535156 -4.78125 3.484375 -4.90625 C 3.429688 -5.039062 3.351562 -5.148438 3.25 -5.234375 C 3.15625 -5.328125 3.039062 -5.394531 2.90625 -5.4375 C 2.769531 -5.476562 2.617188 -5.5 2.453125 -5.5 C 2.296875 -5.5 2.148438 -5.476562 2.015625 -5.4375 C 1.878906 -5.394531 1.757812 -5.332031 1.65625 -5.25 C 1.550781 -5.164062 1.460938 -5.054688 1.390625 -4.921875 C 1.328125 -4.796875 1.285156 -4.648438 1.265625 -4.484375 L 0.484375 -4.5625 C 0.503906 -4.78125 0.5625 -4.984375 0.65625 -5.171875 C 0.75 -5.359375 0.878906 -5.523438 1.046875 -5.671875 C 1.210938 -5.816406 1.410156 -5.929688 1.640625 -6.015625 C 1.878906 -6.097656 2.148438 -6.140625 2.453125 -6.140625 C 2.753906 -6.140625 3.019531 -6.101562 3.25 -6.03125 C 3.488281 -5.957031 3.6875 -5.847656 3.84375 -5.703125 C 4.007812 -5.566406 4.132812 -5.394531 4.21875 -5.1875 C 4.3125 -4.988281 4.359375 -4.753906 4.359375 -4.484375 C 4.359375 -4.273438 4.320312 -4.078125 4.25 -3.890625 C 4.175781 -3.710938 4.078125 -3.539062 3.953125 -3.375 C 3.828125 -3.207031 3.6875 -3.046875 3.53125 -2.890625 C 3.375 -2.742188 3.207031 -2.59375 3.03125 -2.4375 C 2.851562 -2.289062 2.675781 -2.144531 2.5 -2 C 2.320312 -1.863281 2.15625 -1.722656 2 -1.578125 C 1.84375 -1.429688 1.703125 -1.28125 1.578125 -1.125 C 1.453125 -0.976562 1.359375 -0.820312 1.296875 -0.65625 L 4.453125 -0.65625 L 4.453125 0 Z M 0.4375 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-5\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.390625 -2 L 0.390625 -2.6875 L 2.53125 -2.6875 L 2.53125 -2 Z M 0.390625 -2 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-6\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.515625 -1.96875 C 4.515625 -1.664062 4.46875 -1.390625 4.375 -1.140625 C 4.289062 -0.890625 4.15625 -0.671875 3.96875 -0.484375 C 3.789062 -0.304688 3.566406 -0.164062 3.296875 -0.0625 C 3.035156 0.03125 2.726562 0.078125 2.375 0.078125 C 2.0625 0.078125 1.785156 0.0390625 1.546875 -0.03125 C 1.304688 -0.101562 1.101562 -0.203125 0.9375 -0.328125 C 0.78125 -0.460938 0.648438 -0.613281 0.546875 -0.78125 C 0.453125 -0.957031 0.390625 -1.148438 0.359375 -1.359375 L 1.140625 -1.4375 C 1.171875 -1.320312 1.210938 -1.210938 1.265625 -1.109375 C 1.328125 -1.003906 1.40625 -0.910156 1.5 -0.828125 C 1.601562 -0.742188 1.722656 -0.675781 1.859375 -0.625 C 2.003906 -0.570312 2.179688 -0.546875 2.390625 -0.546875 C 2.585938 -0.546875 2.769531 -0.578125 2.9375 -0.640625 C 3.101562 -0.703125 3.242188 -0.789062 3.359375 -0.90625 C 3.472656 -1.03125 3.5625 -1.175781 3.625 -1.34375 C 3.6875 -1.519531 3.71875 -1.722656 3.71875 -1.953125 C 3.71875 -2.140625 3.6875 -2.3125 3.625 -2.46875 C 3.570312 -2.625 3.488281 -2.757812 3.375 -2.875 C 3.257812 -2.988281 3.117188 -3.078125 2.953125 -3.140625 C 2.796875 -3.203125 2.613281 -3.234375 2.40625 -3.234375 C 2.28125 -3.234375 2.160156 -3.21875 2.046875 -3.1875 C 1.941406 -3.164062 1.84375 -3.132812 1.75 -3.09375 C 1.65625 -3.0625 1.570312 -3.015625 1.5 -2.953125 C 1.425781 -2.898438 1.351562 -2.847656 1.28125 -2.796875 L 0.53125 -2.796875 L 0.734375 -6.046875 L 4.171875 -6.046875 L 4.171875 -5.390625 L 1.4375 -5.390625 L 1.3125 -3.46875 C 1.457031 -3.582031 1.628906 -3.675781 1.828125 -3.75 C 2.035156 -3.820312 2.28125 -3.859375 2.5625 -3.859375 C 2.863281 -3.859375 3.132812 -3.8125 3.375 -3.71875 C 3.613281 -3.632812 3.816406 -3.503906 3.984375 -3.328125 C 4.160156 -3.160156 4.289062 -2.960938 4.375 -2.734375 C 4.46875 -2.503906 4.515625 -2.25 4.515625 -1.96875 Z M 4.515625 -1.96875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-7\">\n",
       "<path style=\"stroke:none;\" d=\"M 3.78125 -1.375 L 3.78125 0 L 3.046875 0 L 3.046875 -1.375 L 0.203125 -1.375 L 0.203125 -1.96875 L 2.96875 -6.046875 L 3.78125 -6.046875 L 3.78125 -1.984375 L 4.640625 -1.984375 L 4.640625 -1.375 Z M 3.046875 -5.1875 C 3.046875 -5.164062 3.035156 -5.132812 3.015625 -5.09375 C 2.992188 -5.050781 2.96875 -5.003906 2.9375 -4.953125 C 2.90625 -4.898438 2.875 -4.847656 2.84375 -4.796875 C 2.8125 -4.742188 2.785156 -4.703125 2.765625 -4.671875 L 1.21875 -2.390625 C 1.195312 -2.359375 1.171875 -2.320312 1.140625 -2.28125 C 1.117188 -2.25 1.09375 -2.210938 1.0625 -2.171875 C 1.039062 -2.140625 1.015625 -2.101562 0.984375 -2.0625 C 0.953125 -2.03125 0.929688 -2.003906 0.921875 -1.984375 L 3.046875 -1.984375 Z M 3.046875 -5.1875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-8\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.5 -1.984375 C 4.5 -1.679688 4.457031 -1.398438 4.375 -1.140625 C 4.289062 -0.890625 4.164062 -0.671875 4 -0.484375 C 3.84375 -0.304688 3.640625 -0.164062 3.390625 -0.0625 C 3.148438 0.03125 2.867188 0.078125 2.546875 0.078125 C 2.191406 0.078125 1.882812 0.015625 1.625 -0.109375 C 1.363281 -0.242188 1.144531 -0.4375 0.96875 -0.6875 C 0.789062 -0.945312 0.660156 -1.257812 0.578125 -1.625 C 0.492188 -2 0.453125 -2.421875 0.453125 -2.890625 C 0.453125 -3.421875 0.5 -3.890625 0.59375 -4.296875 C 0.695312 -4.703125 0.835938 -5.039062 1.015625 -5.3125 C 1.203125 -5.59375 1.429688 -5.800781 1.703125 -5.9375 C 1.972656 -6.070312 2.273438 -6.140625 2.609375 -6.140625 C 2.816406 -6.140625 3.007812 -6.117188 3.1875 -6.078125 C 3.375 -6.035156 3.539062 -5.960938 3.6875 -5.859375 C 3.832031 -5.765625 3.957031 -5.640625 4.0625 -5.484375 C 4.175781 -5.328125 4.269531 -5.132812 4.34375 -4.90625 L 3.59375 -4.78125 C 3.519531 -5.039062 3.394531 -5.226562 3.21875 -5.34375 C 3.039062 -5.457031 2.835938 -5.515625 2.609375 -5.515625 C 2.390625 -5.515625 2.191406 -5.460938 2.015625 -5.359375 C 1.847656 -5.265625 1.703125 -5.117188 1.578125 -4.921875 C 1.460938 -4.722656 1.375 -4.472656 1.3125 -4.171875 C 1.25 -3.867188 1.21875 -3.515625 1.21875 -3.109375 C 1.351562 -3.367188 1.546875 -3.566406 1.796875 -3.703125 C 2.054688 -3.835938 2.351562 -3.90625 2.6875 -3.90625 C 2.957031 -3.90625 3.203125 -3.859375 3.421875 -3.765625 C 3.648438 -3.679688 3.84375 -3.554688 4 -3.390625 C 4.164062 -3.222656 4.289062 -3.019531 4.375 -2.78125 C 4.457031 -2.539062 4.5 -2.273438 4.5 -1.984375 Z M 3.71875 -1.953125 C 3.71875 -2.160156 3.691406 -2.347656 3.640625 -2.515625 C 3.585938 -2.679688 3.507812 -2.820312 3.40625 -2.9375 C 3.300781 -3.0625 3.171875 -3.15625 3.015625 -3.21875 C 2.867188 -3.28125 2.695312 -3.3125 2.5 -3.3125 C 2.363281 -3.3125 2.222656 -3.289062 2.078125 -3.25 C 1.929688 -3.207031 1.800781 -3.140625 1.6875 -3.046875 C 1.570312 -2.953125 1.476562 -2.828125 1.40625 -2.671875 C 1.332031 -2.523438 1.296875 -2.34375 1.296875 -2.125 C 1.296875 -1.90625 1.320312 -1.695312 1.375 -1.5 C 1.4375 -1.3125 1.519531 -1.144531 1.625 -1 C 1.726562 -0.851562 1.851562 -0.738281 2 -0.65625 C 2.15625 -0.570312 2.332031 -0.53125 2.53125 -0.53125 C 2.71875 -0.53125 2.882812 -0.5625 3.03125 -0.625 C 3.175781 -0.695312 3.300781 -0.789062 3.40625 -0.90625 C 3.507812 -1.03125 3.585938 -1.179688 3.640625 -1.359375 C 3.691406 -1.535156 3.71875 -1.734375 3.71875 -1.953125 Z M 3.71875 -1.953125 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-9\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.515625 -1.6875 C 4.515625 -1.425781 4.472656 -1.1875 4.390625 -0.96875 C 4.304688 -0.757812 4.179688 -0.578125 4.015625 -0.421875 C 3.847656 -0.265625 3.632812 -0.140625 3.375 -0.046875 C 3.113281 0.0351562 2.804688 0.078125 2.453125 0.078125 C 2.097656 0.078125 1.789062 0.0351562 1.53125 -0.046875 C 1.269531 -0.140625 1.050781 -0.265625 0.875 -0.421875 C 0.707031 -0.578125 0.582031 -0.757812 0.5 -0.96875 C 0.414062 -1.1875 0.375 -1.421875 0.375 -1.671875 C 0.375 -1.898438 0.40625 -2.097656 0.46875 -2.265625 C 0.539062 -2.441406 0.632812 -2.59375 0.75 -2.71875 C 0.863281 -2.84375 0.992188 -2.941406 1.140625 -3.015625 C 1.285156 -3.085938 1.4375 -3.140625 1.59375 -3.171875 L 1.59375 -3.1875 C 1.414062 -3.226562 1.257812 -3.289062 1.125 -3.375 C 1 -3.46875 0.890625 -3.578125 0.796875 -3.703125 C 0.710938 -3.828125 0.644531 -3.960938 0.59375 -4.109375 C 0.550781 -4.265625 0.53125 -4.425781 0.53125 -4.59375 C 0.53125 -4.800781 0.566406 -5 0.640625 -5.1875 C 0.722656 -5.375 0.84375 -5.535156 1 -5.671875 C 1.164062 -5.816406 1.367188 -5.929688 1.609375 -6.015625 C 1.847656 -6.097656 2.125 -6.140625 2.4375 -6.140625 C 2.757812 -6.140625 3.039062 -6.097656 3.28125 -6.015625 C 3.53125 -5.929688 3.734375 -5.816406 3.890625 -5.671875 C 4.046875 -5.535156 4.160156 -5.375 4.234375 -5.1875 C 4.316406 -5 4.359375 -4.796875 4.359375 -4.578125 C 4.359375 -4.410156 4.332031 -4.25 4.28125 -4.09375 C 4.238281 -3.945312 4.171875 -3.8125 4.078125 -3.6875 C 3.992188 -3.5625 3.882812 -3.457031 3.75 -3.375 C 3.613281 -3.289062 3.457031 -3.226562 3.28125 -3.1875 L 3.28125 -3.171875 C 3.457031 -3.140625 3.617188 -3.085938 3.765625 -3.015625 C 3.921875 -2.941406 4.050781 -2.84375 4.15625 -2.71875 C 4.269531 -2.59375 4.359375 -2.441406 4.421875 -2.265625 C 4.484375 -2.097656 4.515625 -1.90625 4.515625 -1.6875 Z M 3.5625 -4.546875 C 3.5625 -4.691406 3.539062 -4.828125 3.5 -4.953125 C 3.457031 -5.078125 3.390625 -5.1875 3.296875 -5.28125 C 3.210938 -5.375 3.097656 -5.441406 2.953125 -5.484375 C 2.816406 -5.535156 2.644531 -5.5625 2.4375 -5.5625 C 2.226562 -5.5625 2.050781 -5.535156 1.90625 -5.484375 C 1.769531 -5.441406 1.65625 -5.375 1.5625 -5.28125 C 1.476562 -5.1875 1.414062 -5.078125 1.375 -4.953125 C 1.332031 -4.828125 1.3125 -4.691406 1.3125 -4.546875 C 1.3125 -4.421875 1.328125 -4.296875 1.359375 -4.171875 C 1.390625 -4.046875 1.445312 -3.929688 1.53125 -3.828125 C 1.613281 -3.722656 1.726562 -3.632812 1.875 -3.5625 C 2.019531 -3.5 2.207031 -3.46875 2.4375 -3.46875 C 2.6875 -3.46875 2.882812 -3.5 3.03125 -3.5625 C 3.175781 -3.632812 3.285156 -3.722656 3.359375 -3.828125 C 3.441406 -3.929688 3.492188 -4.046875 3.515625 -4.171875 C 3.546875 -4.296875 3.5625 -4.421875 3.5625 -4.546875 Z M 3.703125 -1.765625 C 3.703125 -1.910156 3.679688 -2.050781 3.640625 -2.1875 C 3.609375 -2.320312 3.539062 -2.441406 3.4375 -2.546875 C 3.34375 -2.648438 3.210938 -2.734375 3.046875 -2.796875 C 2.878906 -2.859375 2.675781 -2.890625 2.4375 -2.890625 C 2.207031 -2.890625 2.007812 -2.859375 1.84375 -2.796875 C 1.6875 -2.734375 1.554688 -2.648438 1.453125 -2.546875 C 1.359375 -2.441406 1.289062 -2.316406 1.25 -2.171875 C 1.207031 -2.035156 1.1875 -1.894531 1.1875 -1.75 C 1.1875 -1.5625 1.207031 -1.390625 1.25 -1.234375 C 1.289062 -1.078125 1.363281 -0.941406 1.46875 -0.828125 C 1.570312 -0.722656 1.703125 -0.640625 1.859375 -0.578125 C 2.023438 -0.523438 2.222656 -0.5 2.453125 -0.5 C 2.691406 -0.5 2.890625 -0.523438 3.046875 -0.578125 C 3.210938 -0.640625 3.34375 -0.722656 3.4375 -0.828125 C 3.53125 -0.941406 3.597656 -1.078125 3.640625 -1.234375 C 3.679688 -1.390625 3.703125 -1.566406 3.703125 -1.765625 Z M 3.703125 -1.765625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-10\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.796875 0 L 0.796875 -0.9375 L 1.640625 -0.9375 L 1.640625 0 Z M 0.796875 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-11\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.46875 -3.15625 C 4.46875 -2.613281 4.414062 -2.140625 4.3125 -1.734375 C 4.21875 -1.328125 4.078125 -0.988281 3.890625 -0.71875 C 3.703125 -0.445312 3.472656 -0.242188 3.203125 -0.109375 C 2.929688 0.015625 2.625 0.078125 2.28125 0.078125 C 2.050781 0.078125 1.84375 0.0507812 1.65625 0 C 1.46875 -0.0390625 1.300781 -0.109375 1.15625 -0.203125 C 1.007812 -0.304688 0.882812 -0.4375 0.78125 -0.59375 C 0.675781 -0.757812 0.59375 -0.953125 0.53125 -1.171875 L 1.28125 -1.296875 C 1.351562 -1.035156 1.472656 -0.84375 1.640625 -0.71875 C 1.816406 -0.59375 2.035156 -0.53125 2.296875 -0.53125 C 2.503906 -0.53125 2.691406 -0.578125 2.859375 -0.671875 C 3.035156 -0.773438 3.1875 -0.925781 3.3125 -1.125 C 3.4375 -1.320312 3.53125 -1.566406 3.59375 -1.859375 C 3.664062 -2.160156 3.707031 -2.515625 3.71875 -2.921875 C 3.65625 -2.785156 3.570312 -2.664062 3.46875 -2.5625 C 3.363281 -2.457031 3.242188 -2.367188 3.109375 -2.296875 C 2.972656 -2.222656 2.828125 -2.164062 2.671875 -2.125 C 2.515625 -2.082031 2.359375 -2.0625 2.203125 -2.0625 C 1.929688 -2.0625 1.679688 -2.109375 1.453125 -2.203125 C 1.234375 -2.304688 1.046875 -2.445312 0.890625 -2.625 C 0.742188 -2.800781 0.625 -3.015625 0.53125 -3.265625 C 0.445312 -3.515625 0.40625 -3.796875 0.40625 -4.109375 C 0.40625 -4.421875 0.453125 -4.703125 0.546875 -4.953125 C 0.640625 -5.203125 0.769531 -5.414062 0.9375 -5.59375 C 1.113281 -5.769531 1.328125 -5.90625 1.578125 -6 C 1.828125 -6.09375 2.109375 -6.140625 2.421875 -6.140625 C 3.097656 -6.140625 3.609375 -5.890625 3.953125 -5.390625 C 4.296875 -4.890625 4.46875 -4.144531 4.46875 -3.15625 Z M 3.640625 -3.890625 C 3.640625 -4.117188 3.609375 -4.332031 3.546875 -4.53125 C 3.492188 -4.726562 3.414062 -4.898438 3.3125 -5.046875 C 3.207031 -5.191406 3.078125 -5.304688 2.921875 -5.390625 C 2.773438 -5.472656 2.601562 -5.515625 2.40625 -5.515625 C 2.21875 -5.515625 2.046875 -5.476562 1.890625 -5.40625 C 1.742188 -5.34375 1.617188 -5.25 1.515625 -5.125 C 1.410156 -5.007812 1.332031 -4.863281 1.28125 -4.6875 C 1.226562 -4.507812 1.203125 -4.316406 1.203125 -4.109375 C 1.203125 -3.898438 1.222656 -3.707031 1.265625 -3.53125 C 1.316406 -3.363281 1.394531 -3.210938 1.5 -3.078125 C 1.601562 -2.953125 1.726562 -2.851562 1.875 -2.78125 C 2.019531 -2.707031 2.191406 -2.671875 2.390625 -2.671875 C 2.535156 -2.671875 2.679688 -2.695312 2.828125 -2.75 C 2.972656 -2.800781 3.101562 -2.875 3.21875 -2.96875 C 3.34375 -3.070312 3.441406 -3.195312 3.515625 -3.34375 C 3.597656 -3.5 3.640625 -3.679688 3.640625 -3.890625 Z M 3.640625 -3.890625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph0-12\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.671875 0 L 0.671875 -0.65625 L 2.21875 -0.65625 L 2.21875 -5.3125 L 0.84375 -4.34375 L 0.84375 -5.0625 L 2.28125 -6.046875 L 2.984375 -6.046875 L 2.984375 -0.65625 L 4.46875 -0.65625 L 4.46875 0 Z M 0.671875 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-0\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.359375 0 L 0.359375 -7.328125 L 3.28125 -7.328125 L 3.28125 0 Z M 0.734375 -0.359375 L 2.921875 -0.359375 L 2.921875 -6.96875 L 0.734375 -6.96875 Z M 0.734375 -0.359375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-1\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.125 0 L 4.125 -3.6875 C 4.125 -3.96875 4.101562 -4.203125 4.0625 -4.390625 C 4.03125 -4.578125 3.972656 -4.726562 3.890625 -4.84375 C 3.804688 -4.96875 3.695312 -5.050781 3.5625 -5.09375 C 3.425781 -5.144531 3.257812 -5.171875 3.0625 -5.171875 C 2.851562 -5.171875 2.664062 -5.128906 2.5 -5.046875 C 2.34375 -4.972656 2.203125 -4.859375 2.078125 -4.703125 C 1.960938 -4.546875 1.875 -4.351562 1.8125 -4.125 C 1.75 -3.90625 1.71875 -3.65625 1.71875 -3.375 L 1.71875 0 L 0.765625 0 L 0.765625 -4.578125 C 0.765625 -4.691406 0.757812 -4.816406 0.75 -4.953125 C 0.75 -5.085938 0.75 -5.210938 0.75 -5.328125 C 0.75 -5.453125 0.742188 -5.554688 0.734375 -5.640625 C 0.734375 -5.734375 0.734375 -5.789062 0.734375 -5.8125 L 1.640625 -5.8125 C 1.648438 -5.789062 1.65625 -5.738281 1.65625 -5.65625 C 1.65625 -5.582031 1.65625 -5.492188 1.65625 -5.390625 C 1.664062 -5.296875 1.671875 -5.191406 1.671875 -5.078125 C 1.679688 -4.972656 1.6875 -4.882812 1.6875 -4.8125 L 1.703125 -4.8125 C 1.785156 -4.988281 1.875 -5.144531 1.96875 -5.28125 C 2.070312 -5.414062 2.191406 -5.53125 2.328125 -5.625 C 2.460938 -5.71875 2.617188 -5.789062 2.796875 -5.84375 C 2.972656 -5.894531 3.175781 -5.921875 3.40625 -5.921875 C 3.84375 -5.921875 4.1875 -5.832031 4.4375 -5.65625 C 4.695312 -5.476562 4.878906 -5.195312 4.984375 -4.8125 L 5 -4.8125 C 5.082031 -4.988281 5.175781 -5.144531 5.28125 -5.28125 C 5.394531 -5.414062 5.519531 -5.53125 5.65625 -5.625 C 5.800781 -5.71875 5.960938 -5.789062 6.140625 -5.84375 C 6.316406 -5.894531 6.519531 -5.921875 6.75 -5.921875 C 7.050781 -5.921875 7.304688 -5.878906 7.515625 -5.796875 C 7.734375 -5.722656 7.910156 -5.601562 8.046875 -5.4375 C 8.179688 -5.269531 8.28125 -5.054688 8.34375 -4.796875 C 8.40625 -4.535156 8.4375 -4.226562 8.4375 -3.875 L 8.4375 0 L 7.484375 0 L 7.484375 -3.6875 C 7.484375 -3.96875 7.460938 -4.203125 7.421875 -4.390625 C 7.390625 -4.578125 7.332031 -4.726562 7.25 -4.84375 C 7.164062 -4.96875 7.054688 -5.050781 6.921875 -5.09375 C 6.785156 -5.144531 6.617188 -5.171875 6.421875 -5.171875 C 6.210938 -5.171875 6.023438 -5.128906 5.859375 -5.046875 C 5.703125 -4.972656 5.5625 -4.859375 5.4375 -4.703125 C 5.320312 -4.554688 5.234375 -4.367188 5.171875 -4.140625 C 5.109375 -3.921875 5.078125 -3.664062 5.078125 -3.375 L 5.078125 0 Z M 4.125 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 0.765625 0 L 0.765625 -4.453125 C 0.765625 -4.578125 0.757812 -4.703125 0.75 -4.828125 C 0.75 -4.953125 0.75 -5.070312 0.75 -5.1875 C 0.75 -5.3125 0.742188 -5.425781 0.734375 -5.53125 C 0.734375 -5.632812 0.734375 -5.726562 0.734375 -5.8125 L 1.640625 -5.8125 C 1.648438 -5.726562 1.65625 -5.632812 1.65625 -5.53125 C 1.664062 -5.425781 1.671875 -5.316406 1.671875 -5.203125 C 1.679688 -5.085938 1.6875 -4.976562 1.6875 -4.875 C 1.6875 -4.78125 1.6875 -4.695312 1.6875 -4.625 L 1.703125 -4.625 C 1.773438 -4.84375 1.847656 -5.035156 1.921875 -5.203125 C 2.003906 -5.367188 2.097656 -5.503906 2.203125 -5.609375 C 2.304688 -5.710938 2.425781 -5.789062 2.5625 -5.84375 C 2.707031 -5.894531 2.882812 -5.921875 3.09375 -5.921875 C 3.164062 -5.921875 3.238281 -5.910156 3.3125 -5.890625 C 3.382812 -5.878906 3.441406 -5.867188 3.484375 -5.859375 L 3.484375 -4.984375 C 3.421875 -4.992188 3.34375 -5.003906 3.25 -5.015625 C 3.164062 -5.023438 3.070312 -5.03125 2.96875 -5.03125 C 2.738281 -5.03125 2.546875 -4.976562 2.390625 -4.875 C 2.242188 -4.78125 2.117188 -4.644531 2.015625 -4.46875 C 1.921875 -4.289062 1.847656 -4.078125 1.796875 -3.828125 C 1.753906 -3.585938 1.734375 -3.320312 1.734375 -3.03125 L 1.734375 0 Z M 0.765625 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-3\">\n",
       "<path style=\"stroke:none;\" d=\"M 4.4375 0 L 4.4375 -3.6875 C 4.4375 -3.96875 4.414062 -4.203125 4.375 -4.390625 C 4.332031 -4.578125 4.265625 -4.726562 4.171875 -4.84375 C 4.078125 -4.96875 3.953125 -5.050781 3.796875 -5.09375 C 3.648438 -5.144531 3.460938 -5.171875 3.234375 -5.171875 C 3.003906 -5.171875 2.796875 -5.128906 2.609375 -5.046875 C 2.429688 -4.972656 2.273438 -4.859375 2.140625 -4.703125 C 2.003906 -4.546875 1.898438 -4.351562 1.828125 -4.125 C 1.765625 -3.90625 1.734375 -3.65625 1.734375 -3.375 L 1.734375 0 L 0.765625 0 L 0.765625 -4.578125 C 0.765625 -4.691406 0.757812 -4.816406 0.75 -4.953125 C 0.75 -5.085938 0.75 -5.210938 0.75 -5.328125 C 0.75 -5.453125 0.742188 -5.554688 0.734375 -5.640625 C 0.734375 -5.734375 0.734375 -5.789062 0.734375 -5.8125 L 1.640625 -5.8125 C 1.648438 -5.789062 1.65625 -5.738281 1.65625 -5.65625 C 1.65625 -5.582031 1.65625 -5.492188 1.65625 -5.390625 C 1.664062 -5.296875 1.671875 -5.191406 1.671875 -5.078125 C 1.679688 -4.972656 1.6875 -4.882812 1.6875 -4.8125 L 1.703125 -4.8125 C 1.796875 -4.988281 1.894531 -5.144531 2 -5.28125 C 2.113281 -5.414062 2.242188 -5.53125 2.390625 -5.625 C 2.535156 -5.71875 2.703125 -5.789062 2.890625 -5.84375 C 3.085938 -5.894531 3.3125 -5.921875 3.5625 -5.921875 C 3.882812 -5.921875 4.160156 -5.878906 4.390625 -5.796875 C 4.628906 -5.722656 4.820312 -5.601562 4.96875 -5.4375 C 5.113281 -5.269531 5.222656 -5.054688 5.296875 -4.796875 C 5.367188 -4.535156 5.40625 -4.226562 5.40625 -3.875 L 5.40625 0 Z M 4.4375 0 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph1-4\">\n",
       "<path style=\"stroke:none;\" d=\"M 2.21875 0.109375 C 1.632812 0.109375 1.195312 -0.0390625 0.90625 -0.34375 C 0.613281 -0.65625 0.46875 -1.082031 0.46875 -1.625 C 0.46875 -2.007812 0.539062 -2.320312 0.6875 -2.5625 C 0.832031 -2.8125 1.019531 -3.003906 1.25 -3.140625 C 1.488281 -3.285156 1.757812 -3.382812 2.0625 -3.4375 C 2.363281 -3.488281 2.664062 -3.519531 2.96875 -3.53125 L 4.28125 -3.546875 L 4.28125 -3.859375 C 4.28125 -4.097656 4.253906 -4.300781 4.203125 -4.46875 C 4.148438 -4.644531 4.070312 -4.78125 3.96875 -4.875 C 3.863281 -4.976562 3.734375 -5.054688 3.578125 -5.109375 C 3.429688 -5.160156 3.25 -5.1875 3.03125 -5.1875 C 2.84375 -5.1875 2.671875 -5.171875 2.515625 -5.140625 C 2.367188 -5.117188 2.238281 -5.070312 2.125 -5 C 2.019531 -4.925781 1.929688 -4.828125 1.859375 -4.703125 C 1.796875 -4.585938 1.753906 -4.441406 1.734375 -4.265625 L 0.71875 -4.34375 C 0.757812 -4.570312 0.828125 -4.78125 0.921875 -4.96875 C 1.023438 -5.164062 1.171875 -5.332031 1.359375 -5.46875 C 1.546875 -5.613281 1.773438 -5.722656 2.046875 -5.796875 C 2.328125 -5.878906 2.664062 -5.921875 3.0625 -5.921875 C 3.789062 -5.921875 4.335938 -5.753906 4.703125 -5.421875 C 5.078125 -5.085938 5.265625 -4.601562 5.265625 -3.96875 L 5.265625 -1.46875 C 5.265625 -1.175781 5.300781 -0.957031 5.375 -0.8125 C 5.445312 -0.664062 5.585938 -0.59375 5.796875 -0.59375 C 5.847656 -0.59375 5.898438 -0.597656 5.953125 -0.609375 C 6.015625 -0.617188 6.070312 -0.628906 6.125 -0.640625 L 6.125 -0.03125 C 6 0 5.875 0.0195312 5.75 0.03125 C 5.632812 0.0390625 5.507812 0.046875 5.375 0.046875 C 5.1875 0.046875 5.023438 0.0234375 4.890625 -0.015625 C 4.765625 -0.0664062 4.660156 -0.140625 4.578125 -0.234375 C 4.492188 -0.335938 4.429688 -0.460938 4.390625 -0.609375 C 4.347656 -0.753906 4.320312 -0.921875 4.3125 -1.109375 L 4.28125 -1.109375 C 4.175781 -0.921875 4.0625 -0.75 3.9375 -0.59375 C 3.8125 -0.445312 3.664062 -0.320312 3.5 -0.21875 C 3.34375 -0.113281 3.15625 -0.0351562 2.9375 0.015625 C 2.726562 0.078125 2.488281 0.109375 2.21875 0.109375 Z M 2.4375 -0.625 C 2.75 -0.625 3.019531 -0.675781 3.25 -0.78125 C 3.476562 -0.894531 3.671875 -1.039062 3.828125 -1.21875 C 3.984375 -1.394531 4.097656 -1.585938 4.171875 -1.796875 C 4.242188 -2.003906 4.28125 -2.203125 4.28125 -2.390625 L 4.28125 -2.875 L 3.21875 -2.84375 C 2.988281 -2.84375 2.765625 -2.828125 2.546875 -2.796875 C 2.335938 -2.765625 2.148438 -2.703125 1.984375 -2.609375 C 1.828125 -2.523438 1.703125 -2.398438 1.609375 -2.234375 C 1.515625 -2.078125 1.46875 -1.867188 1.46875 -1.609375 C 1.46875 -1.296875 1.550781 -1.050781 1.71875 -0.875 C 1.882812 -0.707031 2.125 -0.625 2.4375 -0.625 Z M 2.4375 -0.625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-0\">\n",
       "<path style=\"stroke:none;\" d=\"M 0 -0.359375 L -7.328125 -0.359375 L -7.328125 -3.28125 L 0 -3.28125 Z M -0.359375 -0.734375 L -0.359375 -2.921875 L -6.96875 -2.921875 L -6.96875 -0.734375 Z M -0.359375 -0.734375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-1\">\n",
       "<path style=\"stroke:none;\" d=\"M -2.9375 -5.65625 C -2.488281 -5.65625 -2.078125 -5.617188 -1.703125 -5.546875 C -1.335938 -5.472656 -1.019531 -5.351562 -0.75 -5.1875 C -0.476562 -5.019531 -0.265625 -4.800781 -0.109375 -4.53125 C 0.0351562 -4.257812 0.109375 -3.921875 0.109375 -3.515625 C 0.109375 -3.097656 0.03125 -2.734375 -0.125 -2.421875 C -0.28125 -2.109375 -0.539062 -1.875 -0.90625 -1.71875 L -0.90625 -1.6875 C -0.894531 -1.6875 -0.859375 -1.6875 -0.796875 -1.6875 C -0.742188 -1.695312 -0.675781 -1.703125 -0.59375 -1.703125 C -0.507812 -1.703125 -0.410156 -1.703125 -0.296875 -1.703125 C -0.191406 -1.703125 -0.0859375 -1.703125 0.015625 -1.703125 L 2.28125 -1.703125 L 2.28125 -0.734375 L -4.625 -0.734375 C -4.757812 -0.734375 -4.890625 -0.734375 -5.015625 -0.734375 C -5.148438 -0.734375 -5.269531 -0.726562 -5.375 -0.71875 C -5.476562 -0.71875 -5.566406 -0.71875 -5.640625 -0.71875 C -5.722656 -0.71875 -5.78125 -0.710938 -5.8125 -0.703125 L -5.8125 -1.640625 C -5.800781 -1.648438 -5.765625 -1.65625 -5.703125 -1.65625 C -5.640625 -1.664062 -5.5625 -1.671875 -5.46875 -1.671875 C -5.375 -1.679688 -5.273438 -1.6875 -5.171875 -1.6875 C -5.066406 -1.695312 -4.96875 -1.703125 -4.875 -1.703125 L -4.875 -1.71875 C -5.0625 -1.8125 -5.21875 -1.914062 -5.34375 -2.03125 C -5.476562 -2.144531 -5.585938 -2.273438 -5.671875 -2.421875 C -5.753906 -2.566406 -5.8125 -2.726562 -5.84375 -2.90625 C -5.882812 -3.09375 -5.90625 -3.296875 -5.90625 -3.515625 C -5.90625 -3.921875 -5.832031 -4.257812 -5.6875 -4.53125 C -5.550781 -4.800781 -5.351562 -5.019531 -5.09375 -5.1875 C -4.832031 -5.351562 -4.519531 -5.472656 -4.15625 -5.546875 C -3.789062 -5.617188 -3.382812 -5.65625 -2.9375 -5.65625 Z M -2.90625 -4.640625 C -3.269531 -4.640625 -3.585938 -4.617188 -3.859375 -4.578125 C -4.140625 -4.535156 -4.375 -4.457031 -4.5625 -4.34375 C -4.757812 -4.238281 -4.910156 -4.097656 -5.015625 -3.921875 C -5.117188 -3.753906 -5.171875 -3.535156 -5.171875 -3.265625 C -5.171875 -3.054688 -5.140625 -2.851562 -5.078125 -2.65625 C -5.015625 -2.46875 -4.894531 -2.300781 -4.71875 -2.15625 C -4.550781 -2.019531 -4.316406 -1.910156 -4.015625 -1.828125 C -3.710938 -1.742188 -3.320312 -1.703125 -2.84375 -1.703125 C -2.425781 -1.703125 -2.070312 -1.734375 -1.78125 -1.796875 C -1.5 -1.867188 -1.269531 -1.96875 -1.09375 -2.09375 C -0.925781 -2.226562 -0.800781 -2.394531 -0.71875 -2.59375 C -0.644531 -2.789062 -0.609375 -3.015625 -0.609375 -3.265625 C -0.609375 -3.523438 -0.660156 -3.742188 -0.765625 -3.921875 C -0.867188 -4.097656 -1.019531 -4.238281 -1.21875 -4.34375 C -1.414062 -4.457031 -1.65625 -4.535156 -1.9375 -4.578125 C -2.21875 -4.617188 -2.539062 -4.640625 -2.90625 -4.640625 Z M -2.90625 -4.640625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-2\">\n",
       "<path style=\"stroke:none;\" d=\"M 0 -0.765625 L -4.453125 -0.765625 C -4.578125 -0.765625 -4.703125 -0.757812 -4.828125 -0.75 C -4.953125 -0.75 -5.070312 -0.75 -5.1875 -0.75 C -5.3125 -0.75 -5.425781 -0.742188 -5.53125 -0.734375 C -5.632812 -0.734375 -5.726562 -0.734375 -5.8125 -0.734375 L -5.8125 -1.640625 C -5.726562 -1.648438 -5.632812 -1.65625 -5.53125 -1.65625 C -5.425781 -1.664062 -5.316406 -1.671875 -5.203125 -1.671875 C -5.085938 -1.679688 -4.976562 -1.6875 -4.875 -1.6875 C -4.78125 -1.6875 -4.695312 -1.6875 -4.625 -1.6875 L -4.625 -1.703125 C -4.84375 -1.773438 -5.035156 -1.847656 -5.203125 -1.921875 C -5.367188 -2.003906 -5.503906 -2.097656 -5.609375 -2.203125 C -5.710938 -2.304688 -5.789062 -2.425781 -5.84375 -2.5625 C -5.894531 -2.707031 -5.921875 -2.882812 -5.921875 -3.09375 C -5.921875 -3.164062 -5.910156 -3.238281 -5.890625 -3.3125 C -5.878906 -3.382812 -5.867188 -3.441406 -5.859375 -3.484375 L -4.984375 -3.484375 C -4.992188 -3.421875 -5.003906 -3.34375 -5.015625 -3.25 C -5.023438 -3.164062 -5.03125 -3.070312 -5.03125 -2.96875 C -5.03125 -2.738281 -4.976562 -2.546875 -4.875 -2.390625 C -4.78125 -2.242188 -4.644531 -2.117188 -4.46875 -2.015625 C -4.289062 -1.921875 -4.078125 -1.847656 -3.828125 -1.796875 C -3.585938 -1.753906 -3.320312 -1.734375 -3.03125 -1.734375 L 0 -1.734375 Z M 0 -0.765625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-3\">\n",
       "<path style=\"stroke:none;\" d=\"M -2.90625 -5.65625 C -1.894531 -5.65625 -1.140625 -5.429688 -0.640625 -4.984375 C -0.140625 -4.535156 0.109375 -3.882812 0.109375 -3.03125 C 0.109375 -2.625 0.046875 -2.257812 -0.078125 -1.9375 C -0.203125 -1.625 -0.390625 -1.359375 -0.640625 -1.140625 C -0.890625 -0.921875 -1.203125 -0.753906 -1.578125 -0.640625 C -1.953125 -0.523438 -2.394531 -0.46875 -2.90625 -0.46875 C -4.914062 -0.46875 -5.921875 -1.332031 -5.921875 -3.0625 C -5.921875 -3.519531 -5.859375 -3.910156 -5.734375 -4.234375 C -5.609375 -4.566406 -5.421875 -4.835938 -5.171875 -5.046875 C -4.921875 -5.253906 -4.601562 -5.40625 -4.21875 -5.5 C -3.84375 -5.601562 -3.40625 -5.65625 -2.90625 -5.65625 Z M -2.90625 -4.640625 C -3.363281 -4.640625 -3.738281 -4.601562 -4.03125 -4.53125 C -4.320312 -4.46875 -4.554688 -4.367188 -4.734375 -4.234375 C -4.910156 -4.097656 -5.03125 -3.929688 -5.09375 -3.734375 C -5.164062 -3.546875 -5.203125 -3.328125 -5.203125 -3.078125 C -5.203125 -2.835938 -5.164062 -2.613281 -5.09375 -2.40625 C -5.019531 -2.207031 -4.894531 -2.039062 -4.71875 -1.90625 C -4.539062 -1.769531 -4.304688 -1.664062 -4.015625 -1.59375 C -3.722656 -1.519531 -3.351562 -1.484375 -2.90625 -1.484375 C -2.457031 -1.484375 -2.082031 -1.519531 -1.78125 -1.59375 C -1.488281 -1.675781 -1.253906 -1.785156 -1.078125 -1.921875 C -0.910156 -2.054688 -0.789062 -2.21875 -0.71875 -2.40625 C -0.644531 -2.59375 -0.609375 -2.800781 -0.609375 -3.03125 C -0.609375 -3.269531 -0.640625 -3.488281 -0.703125 -3.6875 C -0.773438 -3.894531 -0.898438 -4.066406 -1.078125 -4.203125 C -1.253906 -4.347656 -1.488281 -4.457031 -1.78125 -4.53125 C -2.082031 -4.601562 -2.457031 -4.640625 -2.90625 -4.640625 Z M -2.90625 -4.640625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-4\">\n",
       "<path style=\"stroke:none;\" d=\"M -0.046875 -2.96875 C -0.00390625 -2.820312 0.0234375 -2.671875 0.046875 -2.515625 C 0.078125 -2.367188 0.09375 -2.195312 0.09375 -2 C 0.09375 -1.226562 -0.347656 -0.84375 -1.234375 -0.84375 L -5.109375 -0.84375 L -5.109375 -0.171875 L -5.8125 -0.171875 L -5.8125 -0.875 L -7.109375 -1.15625 L -7.109375 -1.8125 L -5.8125 -1.8125 L -5.8125 -2.875 L -5.109375 -2.875 L -5.109375 -1.8125 L -1.4375 -1.8125 C -1.15625 -1.8125 -0.957031 -1.851562 -0.84375 -1.9375 C -0.738281 -2.03125 -0.6875 -2.191406 -0.6875 -2.421875 C -0.6875 -2.515625 -0.691406 -2.601562 -0.703125 -2.6875 C -0.710938 -2.769531 -0.726562 -2.863281 -0.75 -2.96875 Z M -0.046875 -2.96875 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-5\">\n",
       "<path style=\"stroke:none;\" d=\"M -2.703125 -1.484375 C -2.398438 -1.484375 -2.117188 -1.515625 -1.859375 -1.578125 C -1.609375 -1.640625 -1.390625 -1.734375 -1.203125 -1.859375 C -1.015625 -1.992188 -0.867188 -2.160156 -0.765625 -2.359375 C -0.671875 -2.566406 -0.625 -2.816406 -0.625 -3.109375 C -0.625 -3.523438 -0.707031 -3.859375 -0.875 -4.109375 C -1.039062 -4.359375 -1.253906 -4.53125 -1.515625 -4.625 L -1.265625 -5.46875 C -1.109375 -5.40625 -0.945312 -5.316406 -0.78125 -5.203125 C -0.613281 -5.097656 -0.460938 -4.953125 -0.328125 -4.765625 C -0.203125 -4.585938 -0.0976562 -4.363281 -0.015625 -4.09375 C 0.0664062 -3.820312 0.109375 -3.492188 0.109375 -3.109375 C 0.109375 -2.242188 -0.144531 -1.585938 -0.65625 -1.140625 C -1.164062 -0.691406 -1.925781 -0.46875 -2.9375 -0.46875 C -3.488281 -0.46875 -3.953125 -0.535156 -4.328125 -0.671875 C -4.703125 -0.804688 -5.007812 -0.988281 -5.25 -1.21875 C -5.488281 -1.457031 -5.660156 -1.734375 -5.765625 -2.046875 C -5.867188 -2.367188 -5.921875 -2.707031 -5.921875 -3.0625 C -5.921875 -3.550781 -5.84375 -3.957031 -5.6875 -4.28125 C -5.53125 -4.613281 -5.3125 -4.878906 -5.03125 -5.078125 C -4.75 -5.273438 -4.421875 -5.414062 -4.046875 -5.5 C -3.671875 -5.582031 -3.265625 -5.625 -2.828125 -5.625 L -2.703125 -5.625 Z M -3.4375 -4.625 C -4.050781 -4.570312 -4.5 -4.414062 -4.78125 -4.15625 C -5.0625 -3.90625 -5.203125 -3.535156 -5.203125 -3.046875 C -5.203125 -2.890625 -5.175781 -2.722656 -5.125 -2.546875 C -5.070312 -2.367188 -4.976562 -2.203125 -4.84375 -2.046875 C -4.71875 -1.898438 -4.539062 -1.773438 -4.3125 -1.671875 C -4.082031 -1.566406 -3.789062 -1.507812 -3.4375 -1.5 Z M -3.4375 -4.625 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-6\">\n",
       "<path style=\"stroke:none;\" d=\"M -7.046875 -0.734375 L -7.96875 -0.734375 L -7.96875 -1.703125 L -7.046875 -1.703125 Z M 0 -0.734375 L -5.8125 -0.734375 L -5.8125 -1.703125 L 0 -1.703125 Z M 0 -0.734375 \"/>\n",
       "</symbol>\n",
       "<symbol overflow=\"visible\" id=\"glyph2-7\">\n",
       "<path style=\"stroke:none;\" d=\"M 0 -4.4375 L -3.6875 -4.4375 C -3.96875 -4.4375 -4.203125 -4.414062 -4.390625 -4.375 C -4.578125 -4.332031 -4.726562 -4.265625 -4.84375 -4.171875 C -4.96875 -4.078125 -5.050781 -3.953125 -5.09375 -3.796875 C -5.144531 -3.648438 -5.171875 -3.460938 -5.171875 -3.234375 C -5.171875 -3.003906 -5.128906 -2.796875 -5.046875 -2.609375 C -4.972656 -2.429688 -4.859375 -2.273438 -4.703125 -2.140625 C -4.546875 -2.003906 -4.351562 -1.898438 -4.125 -1.828125 C -3.90625 -1.765625 -3.65625 -1.734375 -3.375 -1.734375 L 0 -1.734375 L 0 -0.765625 L -4.578125 -0.765625 C -4.691406 -0.765625 -4.816406 -0.757812 -4.953125 -0.75 C -5.085938 -0.75 -5.210938 -0.75 -5.328125 -0.75 C -5.453125 -0.75 -5.554688 -0.742188 -5.640625 -0.734375 C -5.734375 -0.734375 -5.789062 -0.734375 -5.8125 -0.734375 L -5.8125 -1.640625 C -5.789062 -1.648438 -5.738281 -1.65625 -5.65625 -1.65625 C -5.582031 -1.65625 -5.492188 -1.65625 -5.390625 -1.65625 C -5.296875 -1.664062 -5.191406 -1.671875 -5.078125 -1.671875 C -4.972656 -1.679688 -4.882812 -1.6875 -4.8125 -1.6875 L -4.8125 -1.703125 C -4.988281 -1.796875 -5.144531 -1.894531 -5.28125 -2 C -5.414062 -2.113281 -5.53125 -2.242188 -5.625 -2.390625 C -5.71875 -2.535156 -5.789062 -2.703125 -5.84375 -2.890625 C -5.894531 -3.085938 -5.921875 -3.3125 -5.921875 -3.5625 C -5.921875 -3.882812 -5.878906 -4.160156 -5.796875 -4.390625 C -5.722656 -4.628906 -5.601562 -4.820312 -5.4375 -4.96875 C -5.269531 -5.113281 -5.054688 -5.222656 -4.796875 -5.296875 C -4.535156 -5.367188 -4.226562 -5.40625 -3.875 -5.40625 L 0 -5.40625 Z M 0 -4.4375 \"/>\n",
       "</symbol>\n",
       "</g>\n",
       "<clipPath id=\"clip1\">\n",
       "  <path d=\"M 48.152344 5.480469 L 426.523438 5.480469 L 426.523438 183.851562 L 48.152344 183.851562 Z M 48.152344 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip2\">\n",
       "  <path d=\"M 48.152344 156 L 426.523438 156 L 426.523438 158 L 48.152344 158 Z M 48.152344 156 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip3\">\n",
       "  <path d=\"M 48.152344 117 L 426.523438 117 L 426.523438 118 L 48.152344 118 Z M 48.152344 117 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip4\">\n",
       "  <path d=\"M 48.152344 77 L 426.523438 77 L 426.523438 78 L 48.152344 78 Z M 48.152344 77 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip5\">\n",
       "  <path d=\"M 48.152344 37 L 426.523438 37 L 426.523438 39 L 48.152344 39 Z M 48.152344 37 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip6\">\n",
       "  <path d=\"M 97 5.480469 L 98 5.480469 L 98 183.851562 L 97 183.851562 Z M 97 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip7\">\n",
       "  <path d=\"M 201 5.480469 L 203 5.480469 L 203 183.851562 L 201 183.851562 Z M 201 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip8\">\n",
       "  <path d=\"M 306 5.480469 L 307 5.480469 L 307 183.851562 L 306 183.851562 Z M 306 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip9\">\n",
       "  <path d=\"M 410 5.480469 L 412 5.480469 L 412 183.851562 L 410 183.851562 Z M 410 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip10\">\n",
       "  <path d=\"M 48.152344 176 L 426.523438 176 L 426.523438 178 L 48.152344 178 Z M 48.152344 176 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip11\">\n",
       "  <path d=\"M 48.152344 136 L 426.523438 136 L 426.523438 138 L 48.152344 138 Z M 48.152344 136 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip12\">\n",
       "  <path d=\"M 48.152344 96 L 426.523438 96 L 426.523438 99 L 48.152344 99 Z M 48.152344 96 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip13\">\n",
       "  <path d=\"M 48.152344 57 L 426.523438 57 L 426.523438 59 L 48.152344 59 Z M 48.152344 57 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip14\">\n",
       "  <path d=\"M 48.152344 17 L 426.523438 17 L 426.523438 19 L 48.152344 19 Z M 48.152344 17 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip15\">\n",
       "  <path d=\"M 149 5.480469 L 151 5.480469 L 151 183.851562 L 149 183.851562 Z M 149 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip16\">\n",
       "  <path d=\"M 253 5.480469 L 255 5.480469 L 255 183.851562 L 253 183.851562 Z M 253 5.480469 \"/>\n",
       "</clipPath>\n",
       "<clipPath id=\"clip17\">\n",
       "  <path d=\"M 358 5.480469 L 360 5.480469 L 360 183.851562 L 358 183.851562 Z M 358 5.480469 \"/>\n",
       "</clipPath>\n",
       "</defs>\n",
       "<g id=\"surface87\">\n",
       "<rect x=\"0\" y=\"0\" width=\"432\" height=\"216\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n",
       "<rect x=\"0\" y=\"0\" width=\"432\" height=\"216\" style=\"fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;\"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 0 216 L 432 216 L 432 0 L 0 0 Z M 0 216 \"/>\n",
       "<g clip-path=\"url(#clip1)\" clip-rule=\"nonzero\">\n",
       "<path style=\" stroke:none;fill-rule:nonzero;fill:rgb(92.156863%,92.156863%,92.156863%);fill-opacity:1;\" d=\"M 48.152344 183.847656 L 426.523438 183.847656 L 426.523438 5.476562 L 48.152344 5.476562 Z M 48.152344 183.847656 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip2)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 157.066406 L 426.519531 157.066406 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 117.355469 L 426.519531 117.355469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 77.640625 L 426.519531 77.640625 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip5)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 37.929688 L 426.519531 37.929688 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 97.410156 183.847656 L 97.410156 5.480469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip7)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 201.960938 183.847656 L 201.960938 5.480469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip8)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 306.511719 183.847656 L 306.511719 5.480469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip9)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:0.533489;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 411.0625 183.847656 L 411.0625 5.480469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip10)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 176.921875 L 426.519531 176.921875 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip11)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 137.210938 L 426.519531 137.210938 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip12)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 97.496094 L 426.519531 97.496094 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip13)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 57.785156 L 426.519531 57.785156 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip14)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 48.152344 18.070312 L 426.519531 18.070312 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip15)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 149.6875 183.847656 L 149.6875 5.480469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip16)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 254.238281 183.847656 L 254.238281 5.480469 \"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip17)\" clip-rule=\"nonzero\">\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 358.789062 183.847656 L 358.789062 5.480469 \"/>\n",
       "</g>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 387.925781 173.648438 C 387.925781 176.257812 384.015625 176.257812 384.015625 173.648438 C 384.015625 171.042969 387.925781 171.042969 387.925781 173.648438 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 177.082031 150.125 C 177.082031 152.730469 173.171875 152.730469 173.171875 150.125 C 173.171875 147.519531 177.082031 147.519531 177.082031 150.125 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 242.949219 96.121094 C 242.949219 98.726562 239.039062 98.726562 239.039062 96.121094 C 239.039062 93.515625 242.949219 93.515625 242.949219 96.121094 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 67.304688 158.496094 C 67.304688 161.105469 63.394531 161.105469 63.394531 158.496094 C 63.394531 155.890625 67.304688 155.890625 67.304688 158.496094 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 349.242188 132.148438 C 349.242188 134.753906 345.332031 134.753906 345.332031 132.148438 C 345.332031 129.542969 349.242188 129.542969 349.242188 132.148438 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 266.996094 164.492188 C 266.996094 167.097656 263.085938 167.097656 263.085938 164.492188 C 263.085938 161.886719 266.996094 161.886719 266.996094 164.492188 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 411.277344 13.585938 C 411.277344 16.195312 407.367188 16.195312 407.367188 13.585938 C 407.367188 10.980469 411.277344 10.980469 411.277344 13.585938 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 250.964844 175.742188 C 250.964844 178.347656 247.054688 178.347656 247.054688 175.742188 C 247.054688 173.136719 250.964844 173.136719 250.964844 175.742188 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 350.984375 128.046875 C 350.984375 130.652344 347.074219 130.652344 347.074219 128.046875 C 347.074219 125.4375 350.984375 125.4375 350.984375 128.046875 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 172.902344 56.78125 C 172.902344 59.386719 168.992188 59.386719 168.992188 56.78125 C 168.992188 54.175781 172.902344 54.175781 172.902344 56.78125 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 172.902344 140.097656 C 172.902344 142.703125 168.992188 142.703125 168.992188 140.097656 C 168.992188 137.492188 172.902344 137.492188 172.902344 140.097656 \"/>\n",
       "<path style=\"fill-rule:nonzero;fill:rgb(0%,0%,0%);fill-opacity:1;stroke-width:0.708661;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 241.207031 139.742188 C 241.207031 142.351562 237.296875 142.351562 237.296875 139.742188 C 237.296875 137.136719 241.207031 137.136719 241.207031 139.742188 \"/>\n",
       "<path style=\"fill:none;stroke-width:2.560748;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 65.347656 149.730469 L 69.703125 149.222656 L 74.058594 148.710938 L 78.410156 148.199219 L 82.765625 147.691406 L 87.121094 147.179688 L 91.472656 146.667969 L 95.828125 146.160156 L 100.183594 145.648438 L 104.535156 145.136719 L 108.890625 144.628906 L 113.246094 144.117188 L 117.597656 143.605469 L 121.953125 143.097656 L 126.304688 142.585938 L 130.660156 142.074219 L 135.015625 141.566406 L 139.367188 141.054688 L 143.722656 140.542969 L 148.078125 140.035156 L 152.429688 139.523438 L 156.785156 139.011719 L 161.140625 138.503906 L 165.492188 137.992188 L 169.847656 137.480469 L 174.203125 136.972656 L 178.554688 136.460938 L 182.910156 135.949219 L 187.261719 135.441406 L 191.617188 134.929688 L 195.972656 134.421875 L 200.324219 133.910156 L 204.679688 133.398438 L 209.035156 132.890625 L 213.386719 132.378906 L 217.742188 131.867188 L 222.097656 131.359375 L 226.449219 130.847656 L 230.804688 130.335938 L 235.160156 129.828125 L 239.511719 129.316406 L 243.867188 128.804688 L 248.222656 128.296875 L 252.574219 127.785156 L 256.929688 127.273438 L 261.28125 126.765625 L 269.992188 125.742188 L 274.34375 125.234375 L 283.054688 124.210938 L 287.40625 123.703125 L 296.117188 122.679688 L 300.46875 122.171875 L 309.179688 121.148438 L 313.53125 120.640625 L 322.242188 119.617188 L 326.59375 119.109375 L 330.949219 118.597656 L 335.300781 118.085938 L 339.65625 117.578125 L 344.011719 117.066406 L 348.363281 116.554688 L 352.71875 116.046875 L 357.074219 115.535156 L 361.425781 115.023438 L 365.78125 114.515625 L 370.136719 114.003906 L 374.488281 113.492188 L 378.84375 112.984375 L 383.199219 112.472656 L 387.550781 111.960938 L 391.90625 111.453125 L 396.257812 110.941406 L 400.613281 110.429688 L 404.96875 109.921875 L 409.320312 109.410156 \"/>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"18.21875\" y=\"180.387695\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"23.21875\" y=\"180.387695\"/>\n",
       "  <use xlink:href=\"#glyph0-3\" x=\"28.21875\" y=\"180.387695\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"33.21875\" y=\"180.387695\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"38.21875\" y=\"180.387695\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"20.21875\" y=\"140.676758\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"25.21875\" y=\"140.676758\"/>\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"30.21875\" y=\"140.676758\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"33.21875\" y=\"140.676758\"/>\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"38.21875\" y=\"140.676758\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-7\" x=\"20.21875\" y=\"100.961914\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"25.21875\" y=\"100.961914\"/>\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"30.21875\" y=\"100.961914\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"33.21875\" y=\"100.961914\"/>\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"38.21875\" y=\"100.961914\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"20.21875\" y=\"61.250977\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"25.21875\" y=\"61.250977\"/>\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"30.21875\" y=\"61.250977\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"33.21875\" y=\"61.250977\"/>\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"38.21875\" y=\"61.250977\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-9\" x=\"20.21875\" y=\"21.536133\"/>\n",
       "  <use xlink:href=\"#glyph0-2\" x=\"25.21875\" y=\"21.536133\"/>\n",
       "  <use xlink:href=\"#glyph0-5\" x=\"30.21875\" y=\"21.536133\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"33.21875\" y=\"21.536133\"/>\n",
       "  <use xlink:href=\"#glyph0-6\" x=\"38.21875\" y=\"21.536133\"/>\n",
       "</g>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 45.410156 176.921875 L 48.152344 176.921875 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 45.410156 137.210938 L 48.152344 137.210938 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 45.410156 97.496094 L 48.152344 97.496094 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 45.410156 57.785156 L 48.152344 57.785156 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 45.410156 18.070312 L 48.152344 18.070312 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 149.6875 186.589844 L 149.6875 183.847656 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 254.238281 186.589844 L 254.238281 183.847656 \"/>\n",
       "<path style=\"fill:none;stroke-width:1.066978;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(20%,20%,20%);stroke-opacity:1;stroke-miterlimit:10;\" d=\"M 358.789062 186.589844 L 358.789062 183.847656 \"/>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"133.6875\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-10\" x=\"138.6875\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"140.6875\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"145.6875\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"150.6875\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"155.6875\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-8\" x=\"160.6875\" y=\"195.74707\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"238.238281\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-10\" x=\"243.238281\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"245.238281\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"250.238281\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"255.238281\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"260.238281\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-11\" x=\"265.238281\" y=\"195.74707\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(30.196078%,30.196078%,30.196078%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"342.789062\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-10\" x=\"347.789062\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"349.789062\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"354.789062\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-1\" x=\"359.789062\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-12\" x=\"364.789062\" y=\"195.74707\"/>\n",
       "  <use xlink:href=\"#glyph0-4\" x=\"369.789062\" y=\"195.74707\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph1-1\" x=\"224.835938\" y=\"208.477539\"/>\n",
       "  <use xlink:href=\"#glyph1-2\" x=\"233.835938\" y=\"208.477539\"/>\n",
       "  <use xlink:href=\"#glyph1-3\" x=\"237.835938\" y=\"208.477539\"/>\n",
       "  <use xlink:href=\"#glyph1-4\" x=\"243.835938\" y=\"208.477539\"/>\n",
       "</g>\n",
       "<g style=\"fill:rgb(0%,0%,0%);fill-opacity:1;\">\n",
       "  <use xlink:href=\"#glyph2-1\" x=\"13.438477\" y=\"111.164062\"/>\n",
       "  <use xlink:href=\"#glyph2-2\" x=\"13.438477\" y=\"105.164062\"/>\n",
       "  <use xlink:href=\"#glyph2-3\" x=\"13.438477\" y=\"101.164062\"/>\n",
       "  <use xlink:href=\"#glyph2-4\" x=\"13.438477\" y=\"95.164062\"/>\n",
       "  <use xlink:href=\"#glyph2-5\" x=\"13.438477\" y=\"92.164062\"/>\n",
       "  <use xlink:href=\"#glyph2-6\" x=\"13.438477\" y=\"86.164062\"/>\n",
       "  <use xlink:href=\"#glyph2-7\" x=\"13.438477\" y=\"84.164062\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "application/pdf": {
       "height": 180,
       "width": 360
      },
      "image/jpeg": {
       "height": 180,
       "width": 360
      },
      "image/png": {
       "height": 180,
       "width": 360
      },
      "image/svg+xml": {
       "height": 180,
       "isolated": true,
       "width": 360
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 3) # Adjust these numbers so the plot looks good in your desktop.\n",
    "\n",
    "plot_g1 <- dat_g1 %>% ggplot(aes(mrna,prot)) +\n",
    "                ylab(\"protein\")+\n",
    "                geom_point() + geom_smooth(aes(mrna,prot), method = lm, se = FALSE, size = 1.2, color=\"red\")\n",
    "\n",
    "plot_g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4166dc30d7557b4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can get results from the LS estimates and corresponding tests for this particular gene:\n",
    "\n",
    "> remember that this is *only 1* gene in the dataset but there are 1391 more genes!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c05f3277a48ee808",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>term</th><th scope=col>estimate</th><th scope=col>std.error</th><th scope=col>statistic</th><th scope=col>p.value</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>(Intercept)</td><td>6.327928e-06</td><td>2.446664e-05</td><td>0.2586349</td><td>0.8011625</td></tr>\n",
       "\t<tr><td>mrna       </td><td>2.057447e-01</td><td>2.583776e-01</td><td>0.7962945</td><td>0.4443536</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 5\n",
       "\\begin{tabular}{lllll}\n",
       " term & estimate & std.error & statistic & p.value\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t (Intercept) & 6.327928e-06 & 2.446664e-05 & 0.2586349 & 0.8011625\\\\\n",
       "\t mrna        & 2.057447e-01 & 2.583776e-01 & 0.7962945 & 0.4443536\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 5\n",
       "\n",
       "| term &lt;chr&gt; | estimate &lt;dbl&gt; | std.error &lt;dbl&gt; | statistic &lt;dbl&gt; | p.value &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 6.327928e-06 | 2.446664e-05 | 0.2586349 | 0.8011625 |\n",
       "| mrna        | 2.057447e-01 | 2.583776e-01 | 0.7962945 | 0.4443536 |\n",
       "\n"
      ],
      "text/plain": [
       "  term        estimate     std.error    statistic p.value  \n",
       "1 (Intercept) 6.327928e-06 2.446664e-05 0.2586349 0.8011625\n",
       "2 mrna        2.057447e-01 2.583776e-01 0.7962945 0.4443536"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "slr_g1 <- lm(prot ~ mrna,data=dat_g1)\n",
    "tidy(slr_g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-95546104fe6954ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Predicted values and Residuals\n",
    "\n",
    "#### The predicted values:\n",
    "\n",
    "The blue dot, <font color=\"blue\"> $\\hat{Y}$ </font> in the line, is the *predicted* protein level for a given amount of mRNA in this gene, predicted by our estimated model! \n",
    "\n",
    "> In `R` output all predicted values are stored in the column `.fitted`. \n",
    "\n",
    "$$\\hat{y}_i = \\hat{\\beta}_0 +  \\hat{\\beta}_1 * x_{i}$$\n",
    "\n",
    "In our case:\n",
    "\n",
    "$$ \\hat{\\text{prot}}_{t} = 6.33e-06 + 0.02 * \\text{mrna}_{t}$$\n",
    "\n",
    "> we put a \"hat\" on $y$ to indicate that it's a predicted value using the estimated regression \n",
    "\n",
    "> NOTE: there's no error term in the predicted model!\n",
    "\n",
    "The predictions $\\hat{Y}_i$ are random variables since they are functions of the estimators of the coefficients. \n",
    "\n",
    "> we can estimate their standard error and CI!!\n",
    "\n",
    "But once we get a value based on an observed sample, they become a non-random real number. *Deja vu??*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b34958a1cbb9bad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### The residuals:\n",
    "\n",
    "The *residual* is the difference between the predicted and the observed value of the response\n",
    "\n",
    "> In `R` output all predicted values are stored in the column `.resid`. \n",
    "\n",
    "\n",
    "$$ \\text{res}_i = y_{i}-\\hat{y}_{i}$$\n",
    "\n",
    "In our case:\n",
    "\n",
    "$$ \\text{res}_t=\\text{prot}_{t}-\\hat{\\text{prot}}_{t}$$\n",
    "\n",
    "> **Note**: $\\varepsilon_i \\ne \\text{res}_i$\n",
    "\n",
    "The residuals are the errors of the prediction and estimates of the error terms in the regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a1e79445b6d7a877",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dat_g1 <- dat_g1 %>% do(augment(slr_g1))\n",
    "dat_g1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1d143f9099847c9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#one particular point in the data to illustrate new concepts\n",
    "dat_g1_0 <- dat_g1[10,]\n",
    "\n",
    "plot_g1 <- dat_g1 %>% \n",
    "    ggplot(aes(mrna,prot)) +\n",
    "    geom_point() + \n",
    "    geom_smooth(aes(mrna,prot), method = lm, se = FALSE, size = 1.2, color=\"red\")+\n",
    "    geom_point(aes(x = dat_g1_0$mrna, y = dat_g1_0$.fitted), \n",
    "               color=\"blue\", size=3)+\n",
    "    geom_text(aes(x=dat_g1_0$mrna + 3.7*10^(-6),y=dat_g1_0$.fitted - 5*10^(-6),\n",
    "                  label=TeX(r\"($\\hat{y}_i$)\", output = \"character\")), \n",
    "                  color=\"blue\", size=5,parse = TRUE)+\n",
    "    geom_text(aes(x=dat_g1_0$mrna + 2.5*10^(-6),y=dat_g1_0$prot+ 5*10^(-6),\n",
    "                  label=TeX(r\"($y_i$)\", output = \"character\")), size=5,parse = TRUE)+\n",
    "    geom_segment(x=dat_g1_0$mrna, y=dat_g1_0$.fitted,\n",
    "                 xend=dat_g1_0$mrna,yend=dat_g1_0$prot, \n",
    "                 linetype=\"dotted\",color=\"brown\")+\n",
    "    geom_text(aes(x=dat_g1_0$mrna + 3.7*10^(-6),y=dat_g1_0$prot - 10^(-5),\n",
    "                  label=TeX(r\"(res$_i$)\", output = \"character\")), \n",
    "                  color=\"brown\", size=5,parse = TRUE)+\n",
    "    ylab(\"protein\")\n",
    "    \n",
    "plot_g1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c99faa80e472321f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Goodness of fit: is our model better than \"nothing\"?\n",
    "\n",
    "We are now ready to evaluate the fit of our model to the observed data.\n",
    "\n",
    "Without any additional information, the best predictor of the response $Y$ is $E[Y]$ which we can estimate with the sample mean of $Y$ ...\n",
    "\n",
    "> \"nothing\" means no explanatory variables, intercept-only model\n",
    "\n",
    "<font color=\"blue\"> so why do we need a LR?? </font>\n",
    "\n",
    "**Because, given the (additional) information** in $\\mathbf{X}$, the \"best\" predictor is $E[Y|\\mathbf{X}]$ which we can model as a LR to estimate it!! \n",
    "\n",
    "> \"best\" according to a criteria: minimizes the mean square error!\n",
    "\n",
    "> Note that there are different ways of estimating this conditional expectation!\n",
    "\n",
    "So, here is an important question: \n",
    "\n",
    "> Is our linear regression better than just using $E[Y]$ to predict??\n",
    "\n",
    "**Statistically, we want to compare our prediction <font color=\"blue\"> $\\hat{Y}$ </font> (the best estimate of $E[Y|\\mathbf{X}]$) with <font color=\"red\"> $\\bar{Y}$ </font> (the best estimate of $E[Y]$)** (note that font colors match the plots below).\n",
    "\n",
    "Let's represent the errors of these 2 predictors with squares of their errors since in LS we want to minimize the sum of the squares of these errors. \n",
    "\n",
    "**Visually**:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/800px-Coefficient_of_Determination.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4c35b7548cf84ac3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Mathematically**:\n",
    "\n",
    "#### 1.3.1 Sum of squares decomposition\n",
    "\n",
    "<font color=\"blue\"> If parameters are estimated using LS and the LR has an intercept</font>, it can be proved that \n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-\\bar{y})^2 = \\sum_{i=1}^n(\\hat{y}_i-\\bar{y})^2 + \\sum_{i=1}^n(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Each of these sums carry important information to evaluate our analysis:\n",
    "\n",
    "**Total Sum of Squares**: $TSS=\\sum_{i=1}^n(y_i-\\bar{y})^2$\n",
    "\n",
    "- this is the sum of the squares of the residuals from the intercept-only (no explanatory variables) model\n",
    "\n",
    "- the squares of these residuals are represented with red squares in the plot above\n",
    "\n",
    "- when properly scaled, it is the sample variance of $Y$ which *estimates* the population variance of $Y$\n",
    "\n",
    "\n",
    "**Explained Sum of Squares**: $ESS=\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})^2$\n",
    "\n",
    "- $\\hat{y}_i$ predicts $y_i$ using the LR, while $\\bar{y}$ predicts $y_i$ without a model. If our model is better than nothing, this should be large!!\n",
    "\n",
    "- it measures how much it is *explained* by the additional information given by the LR\n",
    "\n",
    "\n",
    "**Residual Sum of Squares**: $RSS=\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$\n",
    "\n",
    "- this is the sum of the squares of the residuals from the *fitted* LR with explanatory variables\n",
    "\n",
    "- the squares of these residuals are represented with blue squares in the plot above\n",
    "\n",
    "- our estimated parameters minimize these errors, this should be small!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f06b2b137bc46e5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.3.2 The coefficient of determination\n",
    "\n",
    "If our model provides a good fit, we expect the TSS (residuals from the empty model, in red) to be much larger than the RSS (residuals from the fitted LR with explanatory variables, in blue)!! \n",
    "\n",
    "Using the decomposition above and dividing by TSS: \n",
    "\n",
    "$$1=\\frac{\\text{ESS}}{\\text{TSS}} + \\frac{\\text{RSS}}{\\text{TSS}}$$\n",
    "\n",
    "\n",
    "**The Coefficient of determination** was first defined as:\n",
    "\n",
    "$$R^2=1 - \\frac{\\text{RSS}}{\\text{TSS}}$$\n",
    "\n",
    "*For a LR with an intercept and estimated by LS* it is equivalent to \n",
    "\n",
    "$$R^2=\\frac{\\text{ESS}}{\\text{TSS}}$$ \n",
    "\n",
    "#### Interpretations \n",
    "\n",
    "For a LR with an intercept and estimated by LS, the coefficient of determination:\n",
    "\n",
    "- measures the gain in predicting the response using the LR instead of the sample mean, relative to the total variation in the response. \n",
    "\n",
    "\n",
    "- is also interpreted as the proportion of variance of the response (TSS) explained by the model (ESS)\n",
    "\n",
    "\n",
    "- is between 0 and 1 since we expect TSS to be much larger than RSS (thus their ratio is smaller than 1)\n",
    "\n",
    "*Don't worry, R computes this statistic for you!!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52f593f50e45adde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glance(slr_g1)\n",
    "\n",
    "(my_Rsq <- 1-sum(dat_g1$.resid^2)/(sd(dat_g1$prot)^2*(nrow(dat_g1)-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bbaa62c34332d83c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The $R^2$ compares $Y$ vs $\\hat{Y}$ using the RSS but *relative to* the TSS \n",
    "\n",
    "<font color=\"blue\"> **In a SLR, the coefficient of determination equals the square of the correlation coefficient** </font>\n",
    "\n",
    "> you probably noticed this in the SLR: $r^2=R^2$\n",
    "\n",
    "**Note**: this is not true for any type of estimation. In particular, it is not true for the estimation method suggested in the Nature's paper or their models since they do not have an intercept!\n",
    "\n",
    "<font color=\"blue\"> **In LR, the coefficient of determination equals the square of the coefficient of multiple correlation** </font>\n",
    "\n",
    "\n",
    "> in fact, the coefficient of determination was first introduced this way in 1921!\n",
    "\n",
    "\n",
    "> the $R^2 = cor(Y, \\hat{Y})^2$, if $\\hat{Y}$ is a predition obtained from a LR with an intercept estimated by LS\n",
    "\n",
    "**Note**: in the paper the authors computed this measure but *not* per each gene, which flawed their conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48d1de4e5ced402a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Scope and limitations of the coefficient of determination\n",
    "\n",
    "The $R^2$ is computed based on *in-sample* observations and it does not provide a sense of how good is our model in predicting *out-of-sample* cases (aka test set)!!\n",
    "\n",
    "Note that $R^2$ computed as $R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}}$ ranges between 0 and 1 *if* the LR model has an intercept and is estimated by LS!! \n",
    "\n",
    "> otherwise, this definition can result in negative values!! (see discussion in Wooldridge)\n",
    "\n",
    "> A negative $R^2$ indicates that the sample mean is a better predictor than the estimated linear regression. We'll come to this point later.\n",
    "\n",
    "*Let's compute the $R^2$ for all the genes in the dataset*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-79247febad83752b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "In this problem you will: \n",
    "\n",
    "- fit 1392 SLR, one for each gene in the dataset using `lm()` and `group_by()`\n",
    "\n",
    "- use the function `augment()` to compute residuals from each fitted SLRs\n",
    "\n",
    "- compute the RSS and the TSS for each gene and estimated SLR\n",
    "\n",
    "- use the RSS and the TSS to compute the $R^2$ for each gene and estimated SLR\n",
    "\n",
    "Collect all these quantities in an object called `data_ss`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-30b40631b6494c74",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_tissues = ...\n",
    "\n",
    "#dat_ss <- dat_bio %>%  \n",
    "#  group_by(...) %>%\n",
    "#  do(augment(...(prot ~ ..., data = .)))   %>% \n",
    "#  summarize(RSS= sum(...),TSS=...(...)^2*(n_tissues - 1),\n",
    "#           myR2 = 1- .../...)\n",
    "\n",
    "# head(dat_ss,3)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "n_tissues = 12\n",
    "\n",
    "dat_ss <- dat_bio %>%  \n",
    "  group_by(gene) %>%\n",
    "  do(augment(lm(prot ~ mrna, data = .)))   %>% \n",
    "  summarize(RSS= sum(.resid^2),TSS=sd(prot)^2*(n_tissues - 1),\n",
    "           myR2 = 1- RSS/TSS)\n",
    "\n",
    "head(dat_ss,3)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b3ad10a8f196443d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4b70ba83b183cc69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "In this problem you will compute the $R^2$ for each gene and estimated SLR using the function `glance()`\n",
    "\n",
    "- select the columns `gene` and `r.squared` and store them in an object called `data_r2`\n",
    "\n",
    "- extend `data_r2` by joining it `data_ss` to compare your calculation of the $R^2$ with that given by `glance()`\n",
    "\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fcff0641f931f0b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#dat_glance <- dat_slr  %>% \n",
    "#  group_by(...)  %>% \n",
    "#  do(glance(...(... ~ ..., data = .))) \n",
    "\n",
    "#dat_r2 <- dat_glance %>% \n",
    "#  select(..., ...)\n",
    "\n",
    "#dat_r2 <- dat_ss  %>%  full_join(dat_r2, by = c(\"gene\")) \n",
    "\n",
    "#tail(dat_r2,3)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "dat_glance <- dat_slr  %>% \n",
    "  group_by(gene)  %>% \n",
    "  do(glance(lm(prot ~ mrna, data = .))) \n",
    "\n",
    "dat_r2 <- dat_glance  %>% \n",
    "  select(gene, r.squared)\n",
    "\n",
    "dat_r2 <- dat_ss  %>%  full_join(dat_r2, by = c(\"gene\")) \n",
    "\n",
    "tail(dat_r2,3)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-dc341effd245527e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfaabf410163976a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Visualization of results \n",
    "\n",
    "We have computed 1392 coefficients of determination, one for each *gene-specific* fitted model. Let's visualize the results using a histogram of the coefficients of determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dd8c3a8d46da2f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hist_ls_r2 <- dat_r2  %>% \n",
    "  ggplot(aes(x=r.squared)) + \n",
    "  geom_histogram(color=\"navy\", bins=20) + \n",
    "  geom_vline(xintercept=median(dat_r2$r.squared, na.rm=T),color=\"red\")+\n",
    "  labs(\n",
    "    title = \"Rsq of gene-specific LS models\",\n",
    "    x = \"Rsq\",\n",
    "    y = \"Count\")+\n",
    "  xlim(0, 1)\n",
    "\n",
    "hist_ls_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9d98e89fc0d5560",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "In the following claims, a \"gene-specific model\" refers to a SLR using `mRNA` as an input variable and estimated by LS for each gene.\n",
    "\n",
    "Select all the claims that are true based on the $R^2$ computed for each gene.\n",
    "\n",
    "**A.** These results suggest that the quality of the proposed models vary greatly across genes. For some genes, a gene-specific model explains more than 80% of the observed variation in protein abundance. However, for half of the genes it explains less than 15% of the observed variation in protein levels.\n",
    "\n",
    "**B.** For the majority of the genes, a gene-specific model fits the data well. \n",
    "\n",
    "**C.** With the suggested gene-specific models, it now becomes possible to predict protein abundance in any given tissue with good accuracy from the measured mRNA for any gene.  \n",
    "\n",
    "**D.** For gene ENSG00000262246, the gene-specific model explains approximately 87% of the observed variation in protein abundance, making `mRNA` statistically significant.\n",
    "\n",
    "*Assign your answer to an object called `answer1.2`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6f09b9a6725554ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.2 <- \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "answer1.2 <- \"A\"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-7c63e0b50f9f1aca",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98eac64db7a12412",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Claim from the paper\n",
    "\n",
    "Using the median ratio of protein to mRNA levels per gene as a proxy for translation rates, our data show that [...] ***it now becomes possible to predict protein abundance in any given tissue with good accuracy from the measured mRNA abundance***\n",
    "\n",
    "<font color=\"blue\"> Hmmmm .... how??? is the median ratio a much better estimate of the regression coefficients?? </font>\n",
    "\n",
    "*We'll come back for this later ....*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d442678a3b10e7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.3.3 Model Evaluation via Adjusted $R^2$\n",
    "\n",
    "A drawback of the $R^2$ is that it increases as more input variables are added to teh model, *regardless of the relevance of the input variables added* since the $\\text{RSS} = \\sum_{i = 1}^n(y_i - \\hat{y}_i)^2$ as more input variables are included in the model. \n",
    "\n",
    "To overcome this issue with $R^2$, we can obtain an **adjusted $R^2$** as follows:\n",
    "\n",
    "$$ \\text{adjusted } R^2 = 1- \\frac{\\text{RSS}/(n - p)}{\\text{TSS}/(n - 1)},$$\n",
    "\n",
    "where \n",
    "\n",
    "- $p$ is the number of regression parameters of the model, including $\\beta_0$.\n",
    "- $n$ is our sample size to train the model.\n",
    "\n",
    "This adjusted coefficient of determination penalizes $\\text{RSS}$ with $n - p$. Hence, even if the $\\text{RSS}$ decreases, we divide it by $n - p$ to compensate for the model's size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0475ff0a71595824",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 1.3.4 Other evaluation metrics\n",
    "\n",
    "Other related metrics used to evaluate LR which measure how far $Y$ is from $\\hat{Y}$ are:\n",
    "\n",
    "\n",
    "- **Residuals Standard Error**: RSE = $\\sqrt{\\frac{1}{n-p} \\text{RSS}}$\n",
    "\n",
    "> called `sigma` in `glance()` output\n",
    "\n",
    "> estimates the standard deviation of the error term $\\varepsilon$ (the RSS is divided by the appropriate degrees of freedom to give a \"good\" estimate of $\\sigma = \\sqrt{Var(\\varepsilon)}$)\n",
    "\n",
    "> needed to estimate the standard errors of $\\hat{\\beta}_j$ in classical theory! (for inference)\n",
    "\n",
    "> a measure based on *training* data to evaluate the fit of the model (for inference)\n",
    "\n",
    "> gives an idea of the size of the *irreducible* error, very similar to the RSS, small is good\n",
    "\n",
    "\n",
    "- **Mean Squared Error**: MSE = $\\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$\n",
    "\n",
    "> *Training MSE*: if we use the original sample $y_1, \\ldots, y_n$ and their predicted values (formula above). It can be easily obtained from `.resid` column in `augment()` output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d65854ba88ab7d8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.4 Selection of nested models: the *F*-test\n",
    "\n",
    "Are the $R^2$ or its adjusted version useful?? \n",
    "\n",
    "- For some genes, the $R^2$ is around 50%, is this value large??\n",
    "\n",
    "The $R^2$ can be used to compare the size of the residuals of the fitted model with those of an empty model. However, we can't use it to *test* any hypothesis to answer this question since its sampling distribution is unknown.\n",
    "\n",
    "\n",
    "Alternatively, the **$F$-test** can be used to compare *nested* models. \n",
    "\n",
    "> what do we mean by *nested models*?\n",
    "\n",
    "> <font color=blue> nested </font>: the full model contains all the variables from the reduced model together with $k$ additional input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0e0703b41e37a2f6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Case 1:**\n",
    "Let's compare a SLR with an intercept only model:\n",
    "\n",
    "- model reduced: $Y_i=\\beta_0 + \\varepsilon_i$ \n",
    "\n",
    "    > LR with no input variables\n",
    "\n",
    "\n",
    "- model full:  $Y_i=\\beta_0 + \\beta_1 X_{i} + \\varepsilon_i$ \n",
    "\n",
    "    > SLR with 1 additional input variable\n",
    "\n",
    "\n",
    "#### <font color=red> Is the full model significantly different from the reduced model? </font>\n",
    "\n",
    "To compare and test nested models we need an **$F$-test**\n",
    "\n",
    "> the function `anova()` can be used to compute this test\n",
    "\n",
    "> `glance()` also includes this statistic and its corresponding p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0858334cd62a4536",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lm_red <- lm(prot~1, dat_g1)\n",
    "\n",
    "lm_full <- lm(prot~ mrna, dat_g1)\n",
    "\n",
    "anova(lm_red,lm_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-68e9eecc55019cda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that in this simple case, the only difference between the reduced and the full model is the term with $\\beta_1$\n",
    "\n",
    "> we are testing if $\\beta_1$ is different from zero!! $H_0: \\beta_1 = 0$\n",
    "\n",
    "Same as before!! \n",
    "\n",
    "> Note the $p$-values are the same. This is not a coincidence! \n",
    "\n",
    "When we test only one parameter: $t^2 = F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c0b972863e8e2814",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anova(lm_red,lm_full)\n",
    "glance(slr_g1)  %>% select(statistic, p.value)\n",
    "tidy(slr_g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77633c07793baf4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For this gene, the full model is not statistically different from the reduced (intercept only) model at a significance level of 5%.\n",
    "\n",
    "> for this gene, the full model, including `mrna` does not fit the data significantly better than then intercept only model! \n",
    "\n",
    "**For this gene, there is not statistical evidence that mRNA is associated with protein levels**\n",
    "\n",
    "As before, we can look at the results of *all* genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-44d9b6ea19ad3cb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "hist_ls_F <- dat_glance  %>% \n",
    "  ggplot(aes(x=p.value)) + \n",
    "  geom_histogram(color=\"navy\", bins=20) + \n",
    "  geom_vline(xintercept=median(dat_glance$p.value, na.rm=T),color=\"red\")+\n",
    "  geom_vline(xintercept=0.05,linetype = 2, color=\"green\")+\n",
    "  labs(\n",
    "    title = \"F-test of gene-specific LS models\",\n",
    "    x = \"p.value\",\n",
    "    y = \"Count\")+\n",
    "  xlim(0, 1)\n",
    "\n",
    "hist_ls_F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4453fda3273e33be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Claim from the paper\n",
    "\n",
    "Using the median ratio of protein to mRNA levels per gene as a proxy for translation rates, our data show that [...] ***it now becomes possible to predict protein abundance in any given tissue with good accuracy from the measured mRNA abundance***\n",
    "\n",
    "**In our analysis, for most genes, the model with `mrna` is not significanly better, at 5% significance, than the empty model.**\n",
    "\n",
    "<font color=\"blue\"> Hmmmm .... is the median ratio a much better estimate of the regression coefficients?? </font>\n",
    "\n",
    "*We'll come back for this later ....*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3118339d0d723854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Back to the F-test:\n",
    "\n",
    "In the previous case, the $F$-test was used in a very simple case, mathematically equivalent to a (squared) $t$-test.\n",
    "\n",
    "However, the $F$-test can be generalized to compare any pair of *nested* models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31fb152ce8bbd93a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Case 2:**\n",
    "\n",
    "- model reduced: $Y_i=\\beta_0 + \\varepsilon_i$ \n",
    "\n",
    "    > LR with no input variables\n",
    "\n",
    "\n",
    "- model full:  $Y_i=\\beta_0 + \\beta_1 X_{i1} + \\beta_2 X_{i2} + \\varepsilon_i$ \n",
    "\n",
    "    > LR with 2 additional input variables\n",
    "    \n",
    "    \n",
    "#### <font color=red> Is the full model significantly different from the reduced model? </font>\n",
    "\n",
    "Note that now the full model has 2 extra terms!!\n",
    "\n",
    "> $H_0: \\beta_1 = 0 \\text{ and }  \\beta_2 = 0$\n",
    "\n",
    "We are *simulataneously* testing if *both parameters* are zero!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bfb30d92944f1b64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Case 3: general**\n",
    "\n",
    "- model reduced: $Y_i=\\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_q X_{iq} + \\varepsilon_i$ \n",
    "\n",
    "    > LR with $q+1$ variables\n",
    "\n",
    "\n",
    "- model full:  $Y_i=\\beta_0 + \\beta_1 X_{i1} +  \\ldots + \\beta_q X_{iq} + \\ldots +  \\beta_s X_{is} + \\varepsilon_i$ \n",
    "\n",
    "    > LR with $p=s+1$ variables, $k = s - q$ additional explanatory variables\n",
    "    \n",
    "    \n",
    "#### <font color=red> Is the full model significantly different from the reduced model? </font>\n",
    "\n",
    "Note that in this simple case, we are testing if $\\beta_1$ is different from zero!!\n",
    "\n",
    "> $H_0: \\beta_{q+1} = 0 \\text{ and }  \\beta_{q+2} = 0 \\text{ and } \\ldots  \\beta_{s} = 0$\n",
    "\n",
    "We are *simulataneously* testing if *k parameters* are zero!!\n",
    "\n",
    "It can be challenging to write the model and the null hypothesis mathematically. \n",
    "\n",
    "However, in any analysis, you should be able identify both the reduced and the full models being compared and tested. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f383d7ac468e9631",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**(For fun) the formula of the F-statistic is given by:** \n",
    "\n",
    "$$F = \\frac{(RSS_{reduced}-RSS_{full})/k}{RSS_{full}/(n-p)} \\sim \\mathcal{F}_{k, n-p}$$\n",
    "\n",
    "- $RSS_{reduced}$ is the **RSS** of the reduced model \n",
    "\n",
    "\n",
    "- $RSS_{full}$ is the **RSS** of the full model \n",
    "\n",
    "\n",
    "- $k$ is the number of parameters tested (difference between models)\n",
    "\n",
    "\n",
    "- $p$ is the number of parameters of the full model ($s+1$)\n",
    "\n",
    "For LS estimation, if the conditional distribution of the error terms $\\varepsilon_i$ is normal, under $H_0$:\n",
    "\n",
    "$$F \\sim \\mathcal{F}_{k, n - p}$$ \n",
    "\n",
    "i.e., the $F$-statistic has an $\\mathcal{F}$ distribution with $k$ degrees of freedom in the numerator and $n - p$ degrees of freedom in the denominator. Otherwise, this is still approximately true by results of the CLT for large samples.\n",
    "\n",
    "> the $F$ and the $R^2$ both depend on the RSS and the TSS so there is a formula that relates them!! however, the former has a known (or approximately known) sampling distribution (under certain assumptions) so we can use it to make probabilistic statements\n",
    "\n",
    "*Don't worry, R computes this statistic for you!!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3885fb69104f7fac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To illustrate other applications of the $F$-test, let's consider a subset with 3 randomly selected genes. \n",
    "\n",
    "We will use this (sub)dataset to analyze the relation between `mrna` and `prot`, *and* `gene` as a variable in the model!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ca588daa7120836",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "set.seed(561)\n",
    "dat_3genes <- dat_bio  %>%  \n",
    "         subset(gene %in% sample(gene,3)) \n",
    "\n",
    "res_per_g <- dat_3genes %>%\n",
    "         group_by(gene) %>%\n",
    "         do(glance(lm(prot ~ mrna, data = .)))  %>% \n",
    "         select(gene, r.squared, statistic, p.value)\n",
    "\n",
    "res_per_g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb62dbae14684093",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### LR with 1 categorical and 1 continuous, without interaction (additive)\n",
    "\n",
    "This model assumes that when mRNA changes the change in protein levels is the same for all 3 genes but allows different predictions for different genes:\n",
    "\n",
    "$$\\text{prot}_t=\\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_2 \\text{G2}_{t} + \\beta_3 \\text{G3}_{t} + \\varepsilon_t$$\n",
    "\n",
    "> the subscript $t$ indicates the tissue where the gene was measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4746d4cb9862031e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Recall ....\n",
    "\n",
    "\n",
    "The variables $G2$ and $G3$ are dummy variables that take only 2 values, 0 and 1\n",
    "\n",
    "> $G2 = 1$ for gene ENSG00000143553, and it's $0$ otherwise \n",
    "\n",
    "> $G3 = 1$ for gene ENSG00000168497, and it's $0$ otherwise\n",
    "\n",
    "\n",
    "> as before, we use 2 dummy variables to model 3 levels of a categorical variable\n",
    "\n",
    "Let's take a closer look at our model:\n",
    "\n",
    "- for gene ENSG00000085733, $G2=0$ and $G3=0$ : then \n",
    "\n",
    "$$\\text{prot}_t=\\beta_0 + \\beta_1 \\text{mrna}_{t} + \\varepsilon_t$$\n",
    "\n",
    "> just replace the dummy variables with 0, respectively, in the equation above\n",
    "\n",
    "> this is just a SLR with intercept $\\beta_0$ and slope $\\beta_1$ to model the relation between `protein` and `mrna`!!\n",
    "\n",
    "- for gene ENSG00000143553, $G2=1$ and $G3=0$: then \n",
    "\n",
    "$$\\text{prot}_t=\\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_2  + \\varepsilon_t$$ \n",
    "\n",
    "> just replace the dummies with 1 and 0, respectively, in the equation above\n",
    "\n",
    "> this is just a SLR with *the same* slope $\\beta_1$ to model the relation between `prot` and `mrna`!!\n",
    "\n",
    "> but note that in this case the intercept is *different*: $\\beta_0 + \\beta_2$\n",
    "\n",
    "- for gene ENSG00000168497, $G2=0$ and $G3=1$: then \n",
    "\n",
    "$$\\text{prot}_t=\\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_3  + \\varepsilon_t$$ \n",
    "\n",
    "> just replace the dummies with 0 and 1, respectively, in the equation above\n",
    "\n",
    "> this is just a SLR with *the same* slope $\\beta_1$ to model the relation between `prot` and `mrna`!!\n",
    "\n",
    "> but note that in this case the intercept is *different*: $\\beta_0 + \\beta_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2b5f6d0a48ebc993",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using the data from the 3 selected genes `data_3genes`, fit the additive model outlined above. Store the results in an object called `mlr_3genes_add`.\n",
    "\n",
    "Use `tidy` to obtain a table with results from the LS estimation and inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b19aacfa7238f6ed",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mlr_3genes_add <- ...(...~ ..., data = dat_3genes)\n",
    "#mlr_3genes_add_res <- tidy(mlr_3genes_add)\n",
    "#mlr_3genes_add_res\n",
    "\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "mlr_3genes_add <- lm(prot~ gene + mrna,dat_3genes)\n",
    "mlr_3genes_add_res <- tidy(mlr_3genes_add)\n",
    "mlr_3genes_add_res\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ee55b94ef330046a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2afa8c39d578b70c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Visualizing the data and fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5eb98ebfc04c163",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Define a grid to extend the estimated LR\n",
    "newdat = expand.grid(mrna = seq(min(dat_3genes$mrna), max(dat_3genes$mrna), by = 1e-06),\n",
    "                     gene = unique(dat_3genes$gene) )\n",
    "newdat$pred_add = predict(mlr_3genes_add, newdata = newdat)\n",
    "\n",
    "plot_add <- ggplot(dat_3genes, aes(x = mrna, y = prot, color = gene)) +\n",
    "     geom_point(size=.5) +     \n",
    "     geom_line(data = newdat, aes(y = pred_add), size = 0.5)+\n",
    "     labs(title = 'Additive Model', x = \"mRNA\", y = \"Protein\") + \n",
    "     theme(plot.title = element_text(face = \"bold\", size = 12, hjust = 0.5),\n",
    "        axis.title = element_text(face = \"bold\", size = 12))\n",
    "\n",
    "plot_add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-898f36e96547cf93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### LR with 1 categorical and 1 continuous, *plus* interactions: \n",
    "\n",
    "Let's now consider a model that assumes that when mRNA changes the change in protein levels is different for each genes. Each gene should have its own translation rate!!\n",
    "\n",
    "> isn't this the same as the *gene-specific* models??\n",
    "\n",
    "> Wilhelm et al.: \"translation rate is a fundamental, encoded (constant) *characteristic of a transcript [gene]*\"\n",
    "\n",
    "\n",
    "$$\\text{prot}_t = \\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_2 G2_{t}  + \\beta_3 G3_{t}  + \\beta_4 G2_{t} * \\text{mrna}_{t} + \\beta_5 G3_{t} * \\text{mrna}_{t} +\\varepsilon_t$$\n",
    "\n",
    "\n",
    "> mathematically, we multiply variables\n",
    "\n",
    "> Recall: 6 parameters related to 3 intercepts and 3 slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a26def16487f21f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the data from the 3 selected genes `data_3genes`, we will now fit the model with interaction terms outlined above. \n",
    "\n",
    "We will store the results in an object called `mlr_3genes_int` and use `tidy` to obtain a table with results from the LS estimation and inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5f1240b71f992980",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlr_3genes_int <- lm(prot ~ gene * mrna, dat_3genes)\n",
    "tidy(mlr_3genes_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-009e2d6fa2652a0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "newdat = expand.grid(mrna = seq(min(dat_3genes$mrna), max(dat_3genes$mrna), by = 1e-06),\n",
    "                     gene = unique(dat_3genes$gene) )\n",
    "newdat$pred_int = predict(mlr_3genes_int, newdata = newdat)\n",
    "\n",
    "plot_int <- ggplot(dat_3genes, aes(x = mrna, y = prot, color = gene)) +\n",
    "     geom_point(size=.5) +     \n",
    "     geom_line(data = newdat, aes(y = pred_int), size = 0.5)+\n",
    "     labs(title = 'Model with interaction', x = \"mRNA\", y = \"Protein\") + \n",
    "     theme(plot.title = element_text(face = \"bold\", size = 12, hjust = 0.5),\n",
    "        axis.title = element_text(face = \"bold\", size = 12))\n",
    "\n",
    "plot_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-377ceb2f92921288",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "Note that to decide if we need to add interaction terms in the LR, we need to compare the following nested models:\n",
    "\n",
    "$$\\textbf{reduced}:\\text{prot}_t=\\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_2 \\text{G2}_{t} + \\beta_3 \\text{G3}_{t} + \\varepsilon_t$$\n",
    "\n",
    "$$\\textbf{full}:\\text{prot}_t = \\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_2 G2_{t}  + \\beta_3 G3_{t}  + \\beta_4 G2_{t} * \\text{mrna}_{t} + \\beta_5 G3_{t} * \\text{mrna}_{t} +\\varepsilon_t$$\n",
    "\n",
    "We want to test if the *additional terms of the full* model are useful to explain the observed variation in protein abundance.\n",
    "\n",
    "The $F$-test can be used to test *simultaneously* whether the additional parameters in the full model are zero. \n",
    "\n",
    "In plain words, the hypotheses ($H_0$ versus $H_1$) are the following:\n",
    "\n",
    "$H_0$: The additional coefficients (of the interaction terms) in the full model are equal to zero\n",
    "\n",
    "$H_1$: At least one of the additional coefficients in the full model is different from zero\n",
    "\n",
    "What is the mathematical translation of these hypotheses for our pair of MLR models?\n",
    "\n",
    "**A.** $H_0: \\beta_0 = \\beta_1 = \\beta_2 = \\beta_3 = 0$ vs. $H_1: \\text{at least one } \\beta_j \\neq 0 \\text{ (for } $j = 0, 1, 2, 3$ \\text{)}$\n",
    "\n",
    "**B.** $H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0$ vs. $H_1: \\text{at least one } \\beta_j \\neq 0 \\text{ (for } $j = 1, 2, 3$ \\text{)}$\n",
    "\n",
    "**C.** $H_0: \\beta_4 = \\beta_5 = 0$ vs. $H_1: \\beta_4 \\neq 0 \\text{ and } \\beta_5 \\neq 0$\n",
    "\n",
    "**D.** $H_0: \\beta_4 = \\beta_5 = 0$ vs. $H_1: \\text{at least one } \\beta_j \\neq 0 \\text{ (for } $j = 4, 5$ \\text{)}$\n",
    "\n",
    "**E.** $H_0: \\hat{\\beta}_4 = \\hat{\\beta}_5 = 0$ vs. $H_1: \\text{at least one } \\hat{\\beta}_j \\neq 0 \\text{ (for } $j = 4, 5$ \\text{)}$\n",
    "\n",
    "*Assign your answer to an object called `answer2.4`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, `\"D\"`, or `\"E\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d0d4fac52a22f63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.4 <- \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "answer1.4 <- \"D\"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6c817e4c8dcc41ee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-348868b77e38ce14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use the function `anova` to obtain the $F$-statistic and its associated $p$-value for the test of $H_0$ versus $H_1$.\n",
    "\n",
    "Store your results in an object called `Ftest_3genes_full_reduced`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77472b95a740aaef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ftest_3genes_full_reduced <- ...(..., ...) %>% mutate_if(is.numeric, round, 3)\n",
    "# Ftest_3genes_full_reduced\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "Ftest_3genes_full_reduced <- anova(mlr_3genes_add, mlr_3genes_int) %>% mutate_if(is.numeric, round, 3)\n",
    "Ftest_3genes_full_reduced\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6a786727cc958fbc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-feb2eb0cfc2c0ad5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using a significance level $\\alpha = 0.05$ and the results in `Ftest_3genes_full_reduced`, in plain words, what is the conclusion of the hypotheses stated in **Question 1.4**?\n",
    "\n",
    "**A.** We reject the null hypothesis; thus, the *full* model is significatly better than the *reduced* model.\n",
    "\n",
    "**B.** We fail to reject the null hypothesis; thus, there is not enough evidence that the *full* model with additional interaction terms is better than the additive (reduced) model.\n",
    "\n",
    "**C.** We accept the alternative hypothesis; thus, the *full* model is significantly better than the *reduced* model.\n",
    "\n",
    "**D.** We do not accept the alternative hypothesis; thus, the *full* model with additional interaction terms is not better than the *reduced* model.\n",
    "\n",
    "*Assign your answer to an object called `answer1.6`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1fafb5ef90566bcb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.6 <- \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "answer1.6 <- \"B\"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2a29bf3dbf308272",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_1.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4e97586f9cff53e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Observation in the context of the case study**\n",
    "\n",
    "Note that at least for these 3 genes, there is no evidence that the \"translation rate is a fundamental, encoded (constant) *characteristic of a transcript [gene]*\" (as claimed in the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c52a18cc8af85c36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.7**\n",
    "<br>{points: 1}\n",
    "\n",
    "We can also test whether any of these 2 models (the additive model or the model with interaction) are statistically different from an intercept-only model. For example:\n",
    "\n",
    "$$\\textbf{reduced}:\\text{prot}_t=\\beta_0 + \\varepsilon_t$$\n",
    "\n",
    "$$\\textbf{full}:\\text{prot}_t=\\beta_0 + \\beta_1 \\text{mrna}_{t} + \\beta_2 \\text{G2}_{t} + \\beta_3 \\text{G3}_{t} + \\varepsilon_t$$\n",
    "\n",
    "\n",
    "In plain words, the hypotheses ($H_0$ versus $H_1$) are the following:\n",
    "\n",
    "$H_0$: Excluding the intercept, all the regression coefficients in the full model are equal to zero. \n",
    "\n",
    "$H_1$: Excluding the intercept, at least one of the regression coefficients in the full model is different from zero.\n",
    "\n",
    "What is the mathematical translation of these hypotheses for our pair of MLR models?\n",
    "\n",
    "**A.** $H_0: \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = 0$ vs. $H_1: \\text{at least one } \\beta_j \\neq 0 \\text{ (for } $j = 1, 2, 3, 4, 5$ \\text{)}$\n",
    "\n",
    "**B.** $H_0: \\beta_0 = \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = 0$ vs. $H_1: \\text{at least one } \\beta_j \\neq 0 \\text{ (for } $j = 0, 1, 2, 3, 4, 5$ \\text{)}$\n",
    "\n",
    "**C.** $H_0: \\beta_1 = \\beta_2 = \\beta_3 = \\beta_4 = \\beta_5 = 0$ vs. $H_1: \\beta_1 \\neq 0 \\text{ and } \\beta_2 \\neq 0 \\text{ and } \\beta_3 \\neq 0 \\text{ and } \\beta_4 \\neq 0 \\text{ and } \\beta_5 \\neq 0$\n",
    "\n",
    "**D.** $H_0: \\hat{\\beta}_1 = \\hat{\\beta}_2 = \\hat{\\beta}_3 = \\hat{\\beta}_4 = \\hat{\\beta}_5 = 0$ vs. $H_1: \\text{at least one } \\hat{\\beta}_j \\neq 0 \\text{ (for } $j = 1, 2, 3, 4, 5$ \\text{)}$\n",
    "\n",
    "*Assign your answer to an object called `answer1.7`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-499121ebfc0f64c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.7 <- \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "answer1.7 <- \"A\"\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b65c4a6933d524a1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_1.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04dfc9903e2bbf13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To test $H_0$ versus $H_1$ with an $F$-test, you can either use the function `anova` as before or obtain the $F$-statistic and its associated $p$-value from the function `glance()`.\n",
    "\n",
    "> note `glance()` can *only* be used when the reduced model is the intercept-empty model. For other reduced models you need to use `anova()`\n",
    "\n",
    "See the columns `statistic` and `p.value` in `Prestige_MLR_Int_statistics`.\n",
    "\n",
    "*Run the cell below before continuing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bbb46fd7929b1425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Additive vs intercept-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ee5335298116580",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intercept_3genes <- lm(prot~1,data=dat_3genes)\n",
    "\n",
    "anova(intercept_3genes,mlr_3genes_add)\n",
    "glance(mlr_3genes_add)  %>% select(r.squared, statistic, p.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bae53d91a52b45c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Interaction vs intercept-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0fbccf4edd998dda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.8**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use the function `glance` to obtain the $F$-statistic and its associated $p$-value for the test if the LR with *gene-specific* coefficients (model with interaction) using `dat_3genes` gives a better prediction than the mean protein value of these 3 genes.\n",
    "\n",
    "Store $F-test$ and its correspoinding $p$-value in an object called `Ftest_3genes_interaction`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20ab328a3e81d820",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Ftest_3genes_interaction  <- glance(...)  %>% \n",
    "#        select(..., ...)\n",
    "\n",
    "# Ftest_3genes_interaction \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "Ftest_3genes_interaction  <- glance(mlr_3genes_int)  %>% \n",
    "        select(statistic, p.value)\n",
    "\n",
    "Ftest_3genes_interaction \n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-04654b98a6306078",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-af974191c796a1fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that in both case, there is enough evidence to reject the null hypothesis. Thus, both the additive and the model with interaction are significantly better than the intercept-only model.\n",
    "\n",
    "**However**, this does not prove that `mRNA` is essential to predict protein abundance\n",
    "\n",
    "> **Why??**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cd7017f83f911799",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Assessing mRNA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67b62ec15b1b6a6e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.9**\n",
    "<br>{points: 1}\n",
    "\n",
    "Think which nested models need to be compared to determine if mRNA is a fundamental quantity to predict protein!!\n",
    "\n",
    "Compute the test using `anova` and store the results in an object called `Ftest_3genes_mrna`.\n",
    "\n",
    "*Test your understanding and work on your own!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a290ce6bc1a11890",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#[write your code here]\n",
    "#Ftest_3genes_mrna\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "lm_red <- lm(prot ~ gene, dat_3genes)\n",
    "lm_full <- lm(prot ~ gene * mrna, dat_3genes)\n",
    "\n",
    "Ftest_3genes_mrna  <- anova(lm_red,lm_full)\n",
    "Ftest_3genes_mrna\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-155d2ad157394a2c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9dac937e51857aca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Prediction\n",
    "\n",
    "How do we evaluate the predictive performance of a model?\n",
    "\n",
    "- **Mean Squared Error**: MSE = $\\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$\n",
    "\n",
    "> *Test MSE*: where $y_i$ are new responses from the test set and $\\hat{y}_i$ are predicted values using the LR estimated with training data\n",
    "\n",
    "- **$R^2$**: $R^2 = 1 - \\frac{RSS}{TSS}$\n",
    "\n",
    "> Can we compute the $R^2$ on the test set??\n",
    "    \n",
    "Yes, as we mentioned for the MSE, the $R^2$ can be computed for new responses in a test set $y_{new}$ compared to the predicted values obtained using the trained LR, $\\hat{y}_{new}$   \n",
    "    \n",
    "> some functions compute the $R^2$ from a validation set or using cross validation (perhaps seen in other courses)   \n",
    "    \n",
    "> however, note that it is *no longer the coefficient of determination*. It measures the correlation between the true and the predicted responses *in a test set*   \n",
    "\n",
    "**We'll see examples in future lectures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7f0358b7a8d93f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conclusions of PART I\n",
    "\n",
    "#### Evaluation of Models when the main goal is estimation and inference:\n",
    "\n",
    "- The $R^2$, coefficient of determination, can be used to compared the sum of squares of the residuals of the fitted model with that of the null model\n",
    "\n",
    "\n",
    "- The $R^2$ is usually interpreted as the part of the variation in the response explained by the model\n",
    "\n",
    "\n",
    "- Many definitions and interpretations of the $R^2$ are for LS estimators of LR containing an intercept\n",
    "\n",
    "\n",
    "- The $R^2$ is not a test and it does not provide a probabilistic result and it's distribution is unknown!\n",
    "\n",
    "\n",
    "- Instead, we can use an $F$ test, also refer as ANOVA, to compare nested models\n",
    "\n",
    "    - tests the simultaneous significance of additional coefficients of the full model (not in the reduced model)\n",
    "    \n",
    "    - in particular, we can use it to test the significance of the fitted model over the null model\n",
    "    \n",
    "\n",
    "- These $F$ tests can be used to select variables!! since we are comparing and testing how the fit changes as we select variables\n",
    "\n",
    "#### Evaluation of Models when the main goal is prediction:\n",
    "\n",
    "- The test MSE is a natural measure to compare new responses from a test set with the predicted values $\\hat{y}_i$ from the LR estimated with training data\n",
    "\n",
    "- The $R^2$ based on test data can also be used but it should not be called a \"coefficient of determination\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0e49ee209f5c4f94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART II: Variable (model) selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f968abd3ee677d53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Do we need all the available predictors in the model?\n",
    "\n",
    "Some datasets contain *many* variables but not all are relevant\n",
    "\n",
    "> you may want to identify the *most relevant* variables to build a model\n",
    "\n",
    "But again: \n",
    "    \n",
    "#### <font color=red>  What is your goal??\n",
    "    \n",
    "> inference vs prediction\n",
    "    \n",
    "To decide if a variable (or set of variables) is relevant or not we need to choose an evaluation metric\n",
    "    \n",
    "As we have just discussed, the evaluation metric used depends on the goal of the analysis!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ea806819f87e3fec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Variable selection when the main goal is estimation and inference\n",
    "\n",
    "Do all the predictors help to explain the response, or is only a subset of the predictors useful?\n",
    "\n",
    "- ###  The $F$-test\n",
    "\n",
    "We can respond to this question testing if some coefficients are zero:\n",
    "\n",
    "#### $$H_0: \\beta_{q+1} = \\beta_{q+2} = \\ldots = \\beta_s=0$$\n",
    "\n",
    "versus the alternative\n",
    "\n",
    "#### $$H_1: \\text{ at least one of the coefficients in the questionable subset is different from 0}$$\n",
    "\n",
    "#### In PART I, we've learned that we can use an $F$-test to compare nested models and answer to this question\n",
    "\n",
    "> you can use `anova` to compare a full model (with all terms) vs a reduced model (which excludes terms from $q+1$ to $s$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-578399986fc057c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- ### The $t$- tests:\n",
    "\n",
    "In previous lectures we evaluated the contribution of individual variables to explain a response using $t$-tests calculated by `lm` and given in the `tidy` table:\n",
    "\n",
    "$$H_0: \\beta_j = 0,  \\text{ versus }  H_1: \\beta_j \\neq 0$$ \n",
    "\n",
    "> $H_0$ contains only *one* coefficient\n",
    "\n",
    "The results of the $t$-tests evaluate the contribution of *each* variable (separately) to explain the variation observed in the response ***with all other variables included*** in the model!!\n",
    "\n",
    "> sometimes refer as: \"after controlling for other explanatory variables\"\n",
    "\n",
    "#### Thus, we can use the results of these tests to establish a *selection rule* to evaluate variables one at a time:\n",
    "\n",
    "> for example: discard variables with *p-values* above a threshold\n",
    "\n",
    "> *caution note 1*: if there are many variables in the model (i.e., $p$ is large) using individual $t$-tests may result in many false discoveries (i.e., erroneously reject a true $H_0$)\n",
    "\n",
    "> *caution note2*: the *training* set is used (over an over) to select so it can't be used again to assess the final significance of the model. This problem is known as the *post-inference* problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c2b4c5148c19a5ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- ### The $R^2$ (or the RSS) and the adjusted $R^2$:\n",
    "\n",
    "Can we compare the coefficient of determinations of two models to select the best one?\n",
    "\n",
    "The RSS decreases as more variables are included in the model!! \n",
    "\n",
    "> so the $R^2$ of bigger models are *always* larger than the $R^2$ of nested models! <font color=red> *regardless of the relevance of the variables added*\n",
    "    \n",
    "To overcome this problem the **adjusted $R^2$** has been proposed:\n",
    "\n",
    "$$ \\text{adjusted } R^2 = 1- \\frac{RSS/(n-p-1)}{TSS/(n-1)} $$ \n",
    "\n",
    "> note that the RSS is penalized by the degrees of freedom. Even if the RSS decreases we divide it by a smaller number to compensate for the size of the model\n",
    "\n",
    "Thus,\n",
    "\n",
    "#### You can use the $R^2$ to compare models of equal size (not necessarily nested) \n",
    "\n",
    "or \n",
    "\n",
    "#### You can use the adjusted $R^2$ to compare models of different sizes (not necessarily nested)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dceb179479d61e36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### The $F$-statistic vs the $R^2$ and the adjusted $R^2$:\n",
    "\n",
    "- The $F$-statistic can be used *only* to compare *nested models*\n",
    "\n",
    "> $R^2$ and the adjusted $R^2$ can be used to compare any set of models of equal size!    \n",
    "    \n",
    "- The $F$-statistic is computed on the *training* set so it is only useful to understand if a subset of predictors is useful to explain the response (inference)\n",
    "    \n",
    "> same for the coefficient of determination (formal definition of $R^2$)\n",
    "    \n",
    "> however, we can compute the correlation between the observed and the predicted responses in a test set (in the context of prediction). Just be careful about the conclusions of this analysis!    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8f8a4c8fe2b330e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 An automated proceedure\n",
    "\n",
    "When we don't have any idea about which variables should be included in the model, ideally, you want to select the best model out of *all possible models* of all possible sizes. \n",
    "\n",
    "> For example: if the dataset has 2 explanatory variables $X_1$ and $X_2$, there are 4 models to compare: (1) an intercept-only model, (2) a model with only $X_1$, (3) a model with only $X_2$, and (4) a model with both $X_1$ and $X_2$. \n",
    "\n",
    "However, the number of *all possible* models become too large rapidely, even for small subset of variables\n",
    "\n",
    "> there are a total of $2^p$ models from a set of $p$ variables\n",
    "\n",
    "> if $p = 20$ (20 available explanatory variables) we need to evaluate more than a million models! \n",
    "\n",
    "There are methods to search more efficiently for a good model (although it may not find the \"best\" one out of all possible):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ea56a1329163900",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- **Forward selection**: \n",
    "Image from [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n",
    "\n",
    "![](https://github.com/UBC-STAT/stat-301/blob/master/materials/worksheet_07/img/forward.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-171001924db231a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. Start with the intercept only model: $y_i = \\beta_0 + \\varepsilon_i$\n",
    "\n",
    "> remember that $\\hat{\\beta}_0 = \\bar{y}$ from the training samples, so $\\hat{y}_{0} = \\bar{y}$ for any observation (from the training or the test set)\n",
    "\n",
    "2. Select the best model of each size\n",
    "\n",
    "**Size 1** Evaluate all models of size 1, choose the best model of size 1 (based on RSS, equal size models), call it $\\mathcal{M}_1$. \n",
    "\n",
    "**Size 2** Starting with the best size 1 model, add 1 variable and evaluate all models of size 2. Choose the best model of size 2 (based on RSS), call it $\\mathcal{M}_2$.\n",
    "\n",
    "\n",
    "$\\ldots$ continue until you reach the full model\n",
    "\n",
    "\n",
    "**Size p** there's only one full model, call it $\\mathcal{M}_p$.\n",
    "\n",
    "> note that we can stop this iteration earlier if we want a model of a predetermined size\n",
    "\n",
    "3. Now we have to select the best out of $p$ models: $\\mathcal{M}_1$ (the best model of size 1), $\\mathcal{M}_2$ (the best model of size 2 evaluated), $\\ldots, \\mathcal{M}_p$ (the full model of size $p$)\n",
    "\n",
    "> you can't use the RSS to compare models of different sizes\n",
    "\n",
    "> depending on the goal of the study you can use the adjusted $R^2$ (for *inference*), or test MSE, the $C_p$ (proportional to AIC) or the BIC (*for prediction*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-375ca4d284414316",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Other selection procedures include:\n",
    "\n",
    "- **Backward selection**: start with the full model and remove variables, one at a time\n",
    "\n",
    "\n",
    "- **Hybrid selection**: after adding a variable, the method may also remove variables \n",
    "\n",
    "### 2. Prediction\n",
    "\n",
    "Regularization offers an alternative way to select a model by penalizing the RSS\n",
    "\n",
    "> e.g., lasso \n",
    "\n",
    "These are different *estimation methods* that estimate coefficients to be exactly zero\n",
    "\n",
    "> they are mainly used when the goal is to predict (more coming next week!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9a37f4c49eb356b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- We have reviewed different metrics to evaluate a model \n",
    "   \n",
    "   \n",
    "- Different metrics should be used depending on the goal of the analysis: inference vs prediction\n",
    "\n",
    "\n",
    "- It is important to understand the set used to compute these metrics: training vs test sets\n",
    "\n",
    "\n",
    "- Different procedures exist to automate an efficient search of a good model: greedy variable selection"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
