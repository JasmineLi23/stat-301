{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2292d8cb2479afb262d33f5c9dd217be",
     "grade": false,
     "grade_id": "cell-3410823c297a225b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Worksheet 06: Prediction and Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "121dec766338069b7d734157ebd348c2",
     "grade": false,
     "grade_id": "cell-34b6d6e1de870f0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **Lecture and Tutorial Learning Goals:**\n",
    "\n",
    "By the end of this section, students will be able to:\n",
    "\n",
    "- Explain the difference between confidence intervals for prediction and prediction confidence intervals and what elements need to be estimated to construct these intervals.\n",
    "\n",
    "- Write a computer script to calculate these intervals. Interpret and communicate the results from that computer script.\n",
    "\n",
    "- Give an example of a question that can be answered by predictive modelling.\n",
    "\n",
    "- Explain the algorithms for the following variable selection methods: • Forward selection • Backward selection\n",
    "\n",
    "- Explain when linear regression is an appropriate model to predict new outcomes based on new values of the input variables.\n",
    "\n",
    "- List model metrics suitable for evaluating a statistical model developed for predictive modelling (e.g., RMSE) and how they are calculated.\n",
    "\n",
    "- Discuss how different estimation methods can result in different predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23a129a5d16c95c437d3988f960f9ef3",
     "grade": false,
     "grade_id": "cell-75c97cc6762ecd03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "\n",
    "library(broom)\n",
    "library(latex2exp)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(gridExtra)\n",
    "library(faraway)\n",
    "library(mltools)\n",
    "library(leaps)\n",
    "library(glmnet)\n",
    "library(cowplot)\n",
    "library(tidyverse)\n",
    "library(modelr)\n",
    "source(\"tests_worksheet_06.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "167d29ea78b54de86d40f4b3c7ac7d8f",
     "grade": false,
     "grade_id": "cell-1a091fc0c614272c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **Part I: Uncertainty of prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4545b0988f07984814fe0f88b229e69",
     "grade": false,
     "grade_id": "cell-5b30cf6538a4f9db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **1.1. Prediction Intervals *vs* Confidence Intervals for prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10454ed796b09029f6d838e3ea92ca5f",
     "grade": false,
     "grade_id": "cell-48c44f77b644ac2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Last week, we saw that the estimated LR can be used to predict the values of the response variable. \n",
    "\n",
    "We have also learned different metrics to evaluate the estimated model, many of which compare the observed response $y$ with its predicted value using the estimated LR $\\hat{y}$. For example:\n",
    "\n",
    "\n",
    "- Mean Squared Error (MSE): $$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- $R^2 = cor(y, \\hat{y})^2$ (for a model with an intercept estimated by LS)\n",
    "\n",
    "Today, we will measure the uncertainty of $\\hat{Y}$. Note that since the predictions are functions of the estimated LR, they also depend on the sample used. A different sample would have resulted in a different estimated LR and, thus, different predictions. Therefore, predictions are random variables. The sample-to-sample variation in the estimated coefficients translates into variation in the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5b3738021b42860e17f6f35a2137b224",
     "grade": false,
     "grade_id": "cell-34428e10444fc41f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<font color=\"darkred\">As we did when estimating the regression parameters, we can also obtain *confidence intervals* for the predictions by considering the sample-to-sample variation.</font>\n",
    "    \n",
    "Depending on the quantity we want to predict, we can construct two types of intervals: **confidence intervals for prediction (CIP)** and **prediction intervals (PI)**. Let's introduce these concepts by fitting an SLR (note that these intervals can be constructed for any LR).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67062eaadd550e32622af9703846b9a2",
     "grade": false,
     "grade_id": "cell-bbea6b83996fe162",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## **1.2. <u>Dataset: </u>[<u>2015 Property Tax Assessment from Strathcona County</u>](https://data.strathcona.ca/Housing-Buildings/2015-Property-Tax-Assessment/uexh-8sx8)**\n",
    "\n",
    "In this first part of the worksheet, we'll work with a new dataset containing data on property tax-assessed values in Strathcona County. The dataset provides a valuation date of July 1, 2014, and a property condition date of December 31, 2014. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f9d4b44052cc691a3dca6b58d18b99c",
     "grade": false,
     "grade_id": "cell-75f0e3d05e6d7159",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "![](https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/popul_AB.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21e401f7fd08a8cdbf11dfa0acf16aa5",
     "grade": false,
     "grade_id": "cell-b15ec86c716aeead",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Let's start by loading the data, but to work with smaller numbers, we will divide the assessed value by 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efda241f6a66708e35762f8de87bbf47",
     "grade": false,
     "grade_id": "cell-15acbc8c4231da91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loads the data and re-scale the assessed values.\n",
    "\n",
    "properties_data <- \n",
    "    read.csv(\"data/Assessment_2015.csv\") %>%\n",
    "    filter(ASSESSCLAS==\"Residential\")  %>% \n",
    "    mutate(assess_val = ASSESSMENT / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d3a69b114e63af753a5f2827382501e",
     "grade": false,
     "grade_id": "cell-c1f2bebff81e4887",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Unfortunately, unless we work with a simulated dataset, the true population parameters are *unknown*. However, to illustrate concepts while working with a real dataset, and avoid simulating data,  we'll use all the residencies in the dataset to obtain an LR and **pretend** that this is the population line.\n",
    "\n",
    "> <font color='darkred'>**THIS IS NOT DONE IN REAL DATA ANALYSIS!** We are doing this here for teaching purposes only. In practice, your entire dataset is your sample. </font>\n",
    "\n",
    "So, let's select a sample from our `property_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0428a253f4af88f89ba34694ca71b44",
     "grade": false,
     "grade_id": "cell-ded6505b2204daba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(561) # DO NOT CHANGE THIS.\n",
    "\n",
    "# A sample out of our bigger sample properties_data, \n",
    "# which we are PRETENDING to be population (but IT ISN'T)\n",
    "\n",
    "properties_sample <- \n",
    "    properties_data %>%\n",
    "    slice_sample(n = 100, replace = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1deeceea81e11492b2c7137201ab6665",
     "grade": false,
     "grade_id": "cell-429601c83a46a355",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Next, let's fit:\n",
    "\n",
    "- **Sample linear model** using the sample we just took in `properties_sample`;\n",
    "\n",
    "- **Population linear model** using the entire dataset in `properties_data`; (again, this is not the actual population model - we are just pretending it to be to study the sample-to-sample variability.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89d45b74858e024cca84245c8e39fec1",
     "grade": false,
     "grade_id": "cell-e2c0b2606548c5f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_pop <- lm(assess_val ~ BLDG_METRE, properties_data)\n",
    "lm_sample <- lm(assess_val ~ BLDG_METRE, properties_sample)\n",
    "\n",
    "tidy(lm_sample) %>% \n",
    "    mutate_if(is.numeric, round, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f57f370f5717849782a4b81d4d15789",
     "grade": false,
     "grade_id": "cell-c0e582aa6d451053",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols <- c(\"Population\"=\"#f04546\",\"LS Estimate\"=\"#3591d1\")\n",
    "\n",
    "plot_sample <- \n",
    "    properties_sample %>%\n",
    "    ggplot(aes(BLDG_METRE, assess_val)) + \n",
    "    xlab(\"building size (mts)\") + \n",
    "    ylab(\"assessed value ($/1000)\") +\n",
    "    xlim(50, 450) +\n",
    "    geom_point(aes(BLDG_METRE, assess_val), color=\"grey\")\n",
    "plot_sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "09a9a0b662d3c65c4c119d47890bd361",
     "grade": false,
     "grade_id": "cell-68940463627e0ff3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **1.2.1 Prediction of the assessed value of a house in Strathcona**\n",
    "\n",
    "The assessed value of a random house in Strathcona can be modelled as the average assessed value of a house with similar characteristics plus some random error.\n",
    "\n",
    "Mathematically,\n",
    "\n",
    "$$Y_i = E[Y_i|X_{i}] + \\varepsilon_i$$\n",
    "\n",
    "The $\\varepsilon_i$ term is necessary because a random residence won't have a value exactly equal to the average population value of residencies of the same size; some have higher values, and others have lower values. \n",
    "\n",
    "In addition, if we assume that the conditional expectation is linear, then:\n",
    "\n",
    "$$ E[Y_i|X_{i}] = \\beta_0 + \\beta_1 X_{i}$$\n",
    "\n",
    "which is the population regression line. \n",
    "\n",
    "Since we are **pretending** that we know this population line, we can plot it. But once again, recall that in practice this line is *unknown*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d25276f4915ae9f2ef0eea9da590d41",
     "grade": false,
     "grade_id": "cell-d5c4a34c9107d0b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this before continuing.\n",
    "\n",
    "# Don't worry about reading and understanding this code. \n",
    "# You can just run and skip it.\n",
    "\n",
    "plot_expect <- \n",
    "    plot_sample +\n",
    "    geom_smooth(data = properties_data, \n",
    "                aes(BLDG_METRE, assess_val, color = \"Population\"),\n",
    "                method = lm, \n",
    "                linetype = 2, \n",
    "                se = FALSE, \n",
    "                fullrange = TRUE) +\n",
    "    geom_point(aes(x = 251, y = predict(lm_pop, tibble(BLDG_METRE = 251))), \n",
    "               color = \"red\", \n",
    "               size = 3) +  \n",
    "    annotate('text',\n",
    "             x = 300,\n",
    "             y = 715,\n",
    "             label = \"paste('E[',Y[i],' | ', X[i],' ]')\", \n",
    "             color = \"red\", \n",
    "             size = 7,\n",
    "             parse = TRUE) +\n",
    "    geom_point(aes(x = 251,y = 534), color = \"black\", size = 3) +\n",
    "    annotate(\"text\",\n",
    "             x = 265, \n",
    "             y = 500, \n",
    "             label = 'paste(y[i])', \n",
    "             size = 7, \n",
    "             parse = TRUE) +\n",
    "    geom_segment(x = 251, \n",
    "                 y = predict(lm_pop, tibble(BLDG_METRE = 251)),\n",
    "                 xend = 251, \n",
    "                 yend = 534, \n",
    "                 linetype = \"dashed\") +\n",
    "    annotate(\"text\", \n",
    "             x = 240,\n",
    "             y = 630,\n",
    "             label = 'paste(epsilon[i])', , \n",
    "             size = 7,\n",
    "             parse = TRUE) +\n",
    "    scale_colour_manual(name = \"SLR\", values = cols) + \n",
    "    theme(text = element_text(size = 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this before continuing \n",
    "\n",
    "# Edit this to make the plot look good in your desktop\n",
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "\n",
    "plot_expect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd7a9693ffe5f84400cb15b744f32826",
     "grade": false,
     "grade_id": "cell-3553d89a222dad9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **1.2.2 Estimated Linear Regression**\n",
    "\n",
    "In practice, we use the random sample to estimate the regression line. In this case, we estimate the relation between a house's assessed value and size based on a random sample of houses from Strathcona. We use the **estimated** relation to predict the value of any house in the county.\n",
    "\n",
    " The prediction of the $i$-th observation is given by:\n",
    "\n",
    "$$\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff11ce63b6e3b523a70abe7c519981c5",
     "grade": false,
     "grade_id": "cell-536d2524f5c04a81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this before continuing.\n",
    "\n",
    "# Don't worry about reading and understanding this code. \n",
    "# You can just run and skip it.\n",
    "\n",
    "plot_ls <- \n",
    "    plot_expect +    \n",
    "    geom_smooth(data = properties_sample, \n",
    "                aes(BLDG_METRE, assess_val, color = \"LS Estimate\"),\n",
    "                method = lm,\n",
    "                se = FALSE,\n",
    "                fullrange = TRUE) +\n",
    "    geom_point(aes(x = 251, y = predict(lm_sample, tibble(BLDG_METRE = 251))),\n",
    "               color = \"blue\",\n",
    "               size = 3) +\n",
    "    annotate('text',\n",
    "             x = 240, \n",
    "             y = predict(lm_sample, tibble(BLDG_METRE = 251)) + 60, \n",
    "             label = 'paste(hat(y)[i])', \n",
    "             color = \"blue\", \n",
    "             size = 7,\n",
    "             parse = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49902cbaa7476c78a35b824cca557b0c",
     "grade": false,
     "grade_id": "cell-9b2515f924c33936",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this before continuing \n",
    "plot_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, note that the $\\varepsilon_i$ is the difference between $y_i$ and $E(Y_i|X_i)$, while the difference between $y_i$ and $\\hat{y}_i$ is the \"estimated\" error, $e_i$. Also, $\\varepsilon_i$ will always be unknown since, in practice, $E(Y_i|X_i)$ is unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6061df57663423d1544eea7fa93eb55f",
     "grade": false,
     "grade_id": "cell-5f12fdc1d66cc358",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **1.2.3 Intervals to describe uncertainty**\n",
    "\n",
    "What do we want to predict with </u><font color=blue> $\\hat{Y}_i$</font>? In general, we are interested in predicting either:\n",
    "\n",
    "- the *average* assessed value of a house of *this size*: <font color=red> $E[Y_i|X_i]$ </font>\n",
    "\n",
    "- the *actual* value of a house of *this size*: $Y_i$ (knowing its size $X_i$)\n",
    "\n",
    "Note that we predict both with *uncertainty*. \n",
    "\n",
    "**Question:** Which one do you think is more difficult to predict? Why? Discuss with a colleague.\n",
    "\n",
    "Let's start with the first case, i.e., when we want to predict $E[Y_i|X_i]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e412f494774aef44b8d40bbbc255cc7",
     "grade": false,
     "grade_id": "cell-2a551d2c94abb365",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **<u>Confidence Intervals for Prediction (CIP)</u>**\n",
    "\n",
    "In this case, we want to estimate $E[Y_i|X_i]$. The predicted value <font color=blue> $ \\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{i}$ </font> approximates, with uncertainty, the <font color=red> population $ E[Y_i| X_{i}] = \\beta_0 + \\beta_1 X_{i}$ </font>. Remember, if we take a different sample, we get different estimates (i.e., different blue lines) and, consequently, different predictions. \n",
    "\n",
    "<font color='darkred'>The only source of variation here is the sample-to-sample variation.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00afb3963688e982da14dfb72bec3bee",
     "grade": false,
     "grade_id": "cell-1dfe3556fad4bc5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then, a 95% confidence interval for prediction is a range that has a 95% probability of capturing the true average value of a house with size $X_i$. Again, remember that once we have estimated values and a numerical range based on the sample, we use the word \"confidence\" (instead of \"probability\") since nothing else is random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6dc959b0f732fbe7edeccb74cb8b18a2",
     "grade": false,
     "grade_id": "cell-cc9483f6f41a9eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**A quick look at data**\n",
    "\n",
    "Using the sample `properties_sample`, let's compute 95% confidence intervals for prediction using the function `predict`. \n",
    "\n",
    "- Create a dataframe, called `properties_cip`, that contains the response, the input, the predictions using `lm_sample`, and the lower and upper bounds of the intervals for *each* observation\n",
    "\n",
    "> each row corresponds to one (in-sample) prediction and its confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adead26e0a07d8bb2ecdbe0b437bcb2d",
     "grade": false,
     "grade_id": "cell-17c0b8c272a33e9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_cip <- \n",
    "    properties_sample  %>% \n",
    "    select(assess_val, BLDG_METRE) %>% \n",
    "    cbind(predict(lm_sample, interval=\"confidence\", se.fit=TRUE)$fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcde86ea1e6f40ea6d759ca4639cc430",
     "grade": false,
     "grade_id": "cell-d43539fbcdb32a75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(properties_cip,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9e04db2688735b64cc0e2e792a090a8d",
     "grade": false,
     "grade_id": "cell-bb887c8569f536c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "**Interpretation** for row 1: with 95% confidence, the *expected* value of a house of size 220 mts is between $\\$671,944$ and $\\$748,198$ (rounded)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10ff5bb84f7faa15832f0a835d286303",
     "grade": false,
     "grade_id": "cell-db0180cfb57e36af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a25173bffa5929e38aef147eb33997f",
     "grade": false,
     "grade_id": "cell-569e309f8224c11e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "properties_sample %>%\n",
    "    ggplot(aes(BLDG_METRE, assess_val)) + \n",
    "        xlab(\"building size (mts)\") + \n",
    "        ylab(\"assessed value ($/1000)\") +\n",
    "        xlim(50,450) + \n",
    "        geom_smooth(aes(color=\"LS Estimate\"), method = lm, se = TRUE, fullrange = TRUE) +\n",
    "        geom_smooth(data = properties_data, \n",
    "                    aes(BLDG_METRE, assess_val, color=\"Population\"),\n",
    "                    method = lm,\n",
    "                    se = FALSE,\n",
    "                    fullrange = TRUE) +        \n",
    "        scale_colour_manual(name=\"SLR\",values=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ec0f43ea9140bfb707c104156ff26c4",
     "grade": false,
     "grade_id": "cell-dd59cc5d41966b48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0** <br>\n",
    "{points: 1}\n",
    "\n",
    "Using the sample `properties_sample`, compute 90% confidence intervals for prediction. Create a data frame called `properties_cip_90` that contains the response, the input, the predictions using `lm_sample`, and the lower and upper bounds of the intervals for each observation. Columns in your data frame should be in this order.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3b1b0d15e212fc876aaba93f3d85896",
     "grade": false,
     "grade_id": "cell-4a11e2a9a809fa15",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " # properties_cip_90 <- \n",
    " #    ...  %>% \n",
    " #    select(..., ...) %>% \n",
    " #    cbind(...(..., \n",
    " #              interval = \"...\", \n",
    " #              level = ..., \n",
    " #              se.fit=TRUE)$fit)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(properties_cip_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1c0d3d532f6c22ce858034dd8f18d76",
     "grade": true,
     "grade_id": "cell-5e7d32fc59cedd6a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d80946dc8781afc0665f40dbfe82c4f5",
     "grade": false,
     "grade_id": "cell-d8d9ff2c6afb130d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1** \n",
    "{points: 1}\n",
    "\n",
    "Based on the output `properties_cip_90`, which of the following claims is correct?\n",
    "\n",
    "**A.** with 90% confidence, the *expected* value of a house of size 97 mts is between \\\\$301274 and \\\\$363407 (rounded) \n",
    "\n",
    "**B.** with 90% confidence, the value of a house of size 97 mts is between \\\\$301274 and \\\\$363407 (rounded) \n",
    "\n",
    "\n",
    "**C.** with 90% confidence, the *expected* value of a house of size 97 mts is between \\\\$678167 and \\\\$741974 (rounded) \n",
    "\n",
    "\n",
    "**D.** with 90% confidence, the *expected* value of any house is between \\\\$678167 and \\\\$741974 (rounded) \n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer1.1`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ebb566f19cdbbc14d5797c71e630a10",
     "grade": false,
     "grade_id": "cell-a00893a2d010e32a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6372a7e4720999194d16f764d001bc0",
     "grade": true,
     "grade_id": "cell-1305aba3b4830400",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67f104f1b8ff2f19f0b4064fd8ac807f",
     "grade": false,
     "grade_id": "cell-3fdcd17d46c25efa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2** \n",
    "{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "Based on the outputs `properties_cip_90` and `properties_cip`, CIP are centered at the fitted value  <font color=blue>$\\hat{Y}_i$ </font>\n",
    "\n",
    "*Assign your answer to an object called `answer1.2`. Your answer should be either `\"true\"` or `\"false\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa61354aaf212b18dc0c27e369bb4484",
     "grade": false,
     "grade_id": "cell-cea820eb6b462663",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "314699f8086eef20bd7eab7daea81d22",
     "grade": true,
     "grade_id": "cell-29dd9eb47eb77962",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "78649ea1cb6a79675d9b060b44f661ef",
     "grade": false,
     "grade_id": "cell-600f2c6e91c98ed5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3** \n",
    "{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The 90% confidence intervals for prediction are wider than the 95% confidence intervals for prediction\n",
    "\n",
    "*Assign your answer to an object called `answer1.3`. Your answer should be either `\"true\"` or `\"false\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af77b3f20ce5ca18f6493d064e8ac4d",
     "grade": false,
     "grade_id": "cell-b74a9de088fc7b1c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.3 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c9c5917084b482ecdc04fd0c78eddf5",
     "grade": true,
     "grade_id": "cell-7217e749f0e1d9b8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ac2f8693b113a87e9ebaaaab95f7c28",
     "grade": false,
     "grade_id": "cell-51c7bb13e6dedae8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **<u> Prediction Intervals (PI)</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "438a410b6658e4911fcde59a06556fb5",
     "grade": false,
     "grade_id": "cell-21e19da17bc59006",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The predicted value <font color=blue> $ \\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 X_{i}$ </font> also approximates, with uncertainty, an actual observation $ Y_i = \\beta_0 + \\beta_1 X_{i} + \\varepsilon_i$. \n",
    "However, now the uncertainty comes from the estimation (sample-to-sample variability) and the error term that generates the data. In other words, we have two sources of uncertainty:\n",
    "\n",
    "- **uncertainty 1**: because the estimated value <font color=blue> $\\hat{\\beta}_0 + \\hat{\\beta}_1 X_i$ </font> *approximates* the average (population) value <font color=red>$\\beta_0 + \\beta_1 X_i$</font>. \n",
    "\n",
    "- **uncertainty 2**: because the actual observation $Y_i$ differs from the population average value by an error $\\varepsilon_i$\n",
    "\n",
    "PIs are centred at the fitted value <font color=blue>$\\hat{Y}_i$</font> as well, but they are wider than the CIP because of the extra uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b12d173b227690e6c31e79e437ae3dd1",
     "grade": false,
     "grade_id": "cell-fd600e8d3f5fbec5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A 95% prediction interval is a range that, with 95% probability, contains the actual value of a house of this size. Again, for a particular interval based on an observed random sample, we replace \"probability\" with \"confidence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bee9036b807b6d6321460489fc49affa",
     "grade": false,
     "grade_id": "cell-eea8d815c63add87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**A quick look at data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ee06f640e04158258d16a6a934f0c9",
     "grade": false,
     "grade_id": "cell-d8ed4230865f4b11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "properties_pi <- \n",
    "    properties_sample  %>% \n",
    "    select(assess_val, BLDG_METRE) %>% \n",
    "    cbind(predict(lm_sample, interval=\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0047a7e3f332f83db386edaf086ae31b",
     "grade": false,
     "grade_id": "cell-e1aba24b87523763",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "head(properties_pi, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row corresponds to one (in-sample) prediction and its confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ead883bf34acb08a95ba530fdeb641cf",
     "grade": false,
     "grade_id": "cell-497c1bb723ea7d5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "**Interpretation** for row 1: with 95% confidence, the value of a house of size 220 mts is between $\\$454,519$ and $\\$965,622$ (rounded).\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae7d93749b32075c5b01700768ce5315",
     "grade": false,
     "grade_id": "cell-44aded3f5798da84",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4** \n",
    "{points: 1}\n",
    "\n",
    "Let's use the results in `properties_cip` and `properties_pi` to corroborate that the prediction intervals are wider than the confidence intervals for prediction. You will:\n",
    "\n",
    "1. calculate the length of the intervals for `properties_pi` (name the column `len_pi`) and `properties_cpi` (name the column `len_cip`). \n",
    "2. `left_join` the data from both tibbles by `assess_val` and `BLDG_METRE` (you'll see a warning of many-to-many relationships that you can ignore for our purposes here). \n",
    "3. count how many of the `len_cip` are higher than `len_ci` using `summarise`. \n",
    "4. pull the value out of the tibble with `pull()` and store it in a variable called `n_cpi_wider`. \n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "623d8dc1048162eb022095c3d15dbfcf",
     "grade": false,
     "grade_id": "cell-90a108fa8cd1df19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "n_cpi_wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "842a3a423618dc4591ef48d5973ffddc",
     "grade": true,
     "grade_id": "cell-d2c259279d279ada",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "23db702dadea06366761b11e6d599165",
     "grade": false,
     "grade_id": "cell-40d35493a2960b93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **1.3 Conclusions Part I: Prediction uncertainty**\n",
    "\n",
    "- Confidence intervals for prediction account for the uncertainty given by the estimated LR to predict the conditional expectation of the response\n",
    "\n",
    "\n",
    "- Prediction intervals account for the uncertainty given by the estimated LR to predict the conditional expectation of the response, *plus* the error that generates the data! \n",
    "\n",
    "\n",
    "- PIs are wider than CIPs; both are centered at the fitted value!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f730873d9311f0ffd014620bdb804e87",
     "grade": false,
     "grade_id": "cell-ed7d0d5863057855",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "![](https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/pred_error.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1593f576615c7bb9d18a706da5bc53fe",
     "grade": false,
     "grade_id": "cell-9b8b52ce313503af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# **PART II: Model Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c6a961aed53c61c07de2dcf524774d0",
     "grade": false,
     "grade_id": "cell-f968abd3ee677d53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this part, we will focus on selecting a subset of variables to include in the model. Do we actually need all the available input variables? Some datasets contain *many* variables, but not all of them are relevant. To decide if a variable (or set of variables) is relevant, we need to choose an evaluation metric. The evaluation metric used depends on the goal of the analysis. So, what is your goal? Inference or prediction?\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e69e5e2d0c43cea1935ad4882a8b7a5",
     "grade": false,
     "grade_id": "cell-f47e7121e611c1e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.1 Variable selection for generative models**\n",
    "\n",
    "In previous worksheets, we learned different selection and estimation methods when the goal is to *estimate and make inferences about* the model that generated the data. We referred to these models as *generative models*.\n",
    "\n",
    "For a LR with an intercept and estimated by LS:\n",
    "\n",
    "- The $\\mathbf{R^2}$, coefficient of determination, can be used to measure the part of the variation in the response explained by the estimated model\n",
    "\n",
    "\n",
    "- The **Adjusted $\\mathbf{R^2}$** can be used to compare the fit of estimated models of different sizes\n",
    "\n",
    "\n",
    "- The **MSE** (based on in-sample data) can be used to compare the observed values with those predicted by the estimated model  \n",
    "\n",
    "\n",
    "- These $\\mathbf{F}$ tests can be used to select variables by comparing nested models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "271e934a7c330073efe743c64e0a9039",
     "grade": false,
     "grade_id": "cell-9dac937e51857aca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.2 Variable selection for predictive models**\n",
    "\n",
    "How do we evaluate the predictive performance of a model? For regression models, two common choices are:\n",
    "\n",
    "- **Mean Squared Error (MSE)**: $$\\text{MSE}_{\\text{test}} = \\frac{1}{n_{\\text{new}}}\\sum_{i=1}^{n_{\\text{new}}}(y^{\\text{new}}_i - \\widehat{y}^{\\text{new}}_i)^2$$\n",
    "<font color='darkred'>where $y^{\\text{new}}_i$ are **new responses from the test set**</font>, $\\widehat{y}^{\\text{new}}_i$ are the predicted values using the LR estimated with the training data but with the input data from the test set, and $n_{\\text{new}}$ is the number of data points in the test set. You *do not want* to use the data in the training set to evaluate your model. \n",
    "\n",
    "- **Root Mean Squared Error (RMSE)**: this is the square root of MSE.\n",
    "$$\\text{RMSE}_{\\text{test}} = \\sqrt{\\text{MSE}_{\\text{test}}} = \\sqrt{\\frac{1}{n_{\\text{new}}}\\sum_{i=1}^{n_{\\text{new}}}(y^{\\text{new}}_i - \\widehat{y}_i)^2}$$\n",
    "Once again, remember that $y_i$ are observations in the test set and weren't used to train the model. \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Another possibility, not really common for prediction is the $R^2$.\n",
    "- **$R^2$**: remember that $R^2$ can be computed for new responses in a test set.\n",
    "$$R^2 = cor(\\boldsymbol{y}^{\\text{new}}, \\widehat{\\boldsymbol{y}}^{\\text{new}})$$\n",
    "Some functions compute the $R^2$ from a validation set or using cross-validation (perhaps seen in other courses). However, note that it is ***no longer the coefficient of determination***. It measures the correlation between the true and the predicted responses *in a test set*.   \n",
    "\n",
    "<br> \n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "There are other common metrics that have been proposed to approximate the *test MSE* but are computed with the training set only. You can use these measures to select variables of predictive models, even without using a test set.\n",
    "\n",
    "- $C_p$:\n",
    "\n",
    "- $AIC$:\n",
    "\n",
    "- $BIC$: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "566b411b2e4da15926c3f357a4ebf7bd",
     "grade": false,
     "grade_id": "cell-aa844e3860a3dcbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.3 Dataset: the [Ames `Housing` dataset](https://www.kaggle.com/c/home-data-for-ml-course/)**\n",
    "\n",
    "In this section, we will work with a real estate dataset, the [Ames `Housing` dataset](https://www.kaggle.com/c/home-data-for-ml-course/), compiled by Dean De Cock. It has 79 input variables on different characteristics of residential houses in Ames, Iowa, USA, that can be used to predict the property's final price, `SalePrice.` We will use the following continuous input variables:\n",
    "\n",
    "- `LotFrontage`: Linear $\\text{ft}$ of street connected to the house.\n",
    "- `LotArea`: Lot size in $\\text{ft}^2$.\n",
    "- `MasVnrArea`: Masonry veneer area in $\\text{ft}^2$.\n",
    "- `TotalBsmtSF`: Total $\\text{ft}^2$ of basement area.\n",
    "- `GrLivArea`: Above grade (ground) living area in $\\text{ft}^2$.\n",
    "- `BsmtFullBath`: Number of full bathrooms in the basement.\n",
    "- `BsmtHalfBath`: Number of half bathrooms in the basement.\n",
    "- `FullBath`: Number of full bathrooms above grade.\n",
    "- `HalfBath`: Number of half bathrooms above grade.\n",
    "- `BedroomAbvGr`: Number of bedrooms above grade (it does not include basement bedrooms).\n",
    "- `KitchenAbvGr`: Number of kitchens above grade.\n",
    "- `Fireplaces`: Number of fireplaces.\n",
    "- `GarageArea`: Garage's area in $\\text{ft}^2$.\n",
    "- `WoodDeckSF`: Wood deck area in $\\text{ft}^2$.\n",
    "- `OpenPorchSF`: Open porch area in $\\text{ft}^2$.\n",
    "- `EnclosedPorch`: Enclosed porch area in $\\text{ft}^2$.\n",
    "- `ScreenPorch`: Screen porch area in $\\text{ft}^2$.\n",
    "- `PoolArea`: Pool area in $\\text{ft}^2$.\n",
    "\n",
    "The following variables will be used to construct a variable `ageSold`\n",
    "- `YearBuilt`: Original construction date.\n",
    "- `YrSold`: Year sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "617c92c4ab25c5405f61960f761d0810",
     "grade": false,
     "grade_id": "cell-0e57653584382931",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run this code to prepare a working dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11e0c4914fc41c304bc96aa0cecf32ff",
     "grade": false,
     "grade_id": "cell-95e16218a5e51a83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "housing <- \n",
    "    read_csv(\"data/Housing.csv\") %>%\n",
    "    mutate(ageSold = YrSold - YearBuilt) %>%\n",
    "    select(LotFrontage, LotArea, MasVnrArea, TotalBsmtSF,\n",
    "           GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, \n",
    "           HalfBath, BedroomAbvGr, KitchenAbvGr, Fireplaces,\n",
    "           GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, \n",
    "           ScreenPorch, PoolArea, ageSold, SalePrice) %>%\n",
    "    drop_na() %>%\n",
    "    filter(LotArea < 20000)\n",
    "\n",
    "str(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95b9fa0922e3b237acb8d573ae5b1b88",
     "grade": false,
     "grade_id": "cell-04b81214318292af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "We'll first split this dataset into a training and a test set using the tidymodels package.\n",
    "\n",
    "Run this code to split the dataset `housing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ee12bac541f371f565674772ca6e9f0",
     "grade": false,
     "grade_id": "cell-7008e2fc78a22fcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run this cell\n",
    "set.seed(1234)\n",
    "\n",
    "housing_split <- \n",
    "    housing %>%\n",
    "    initial_split(prop = 0.6, strata = SalePrice)\n",
    "\n",
    "training_housing <- training(housing_split)\n",
    "testing_housing <- testing(housing_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8292db06e20e17bcb66e2a4be7c71f3e",
     "grade": false,
     "grade_id": "cell-ff62a9f7bb684c78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(training_housing, 3)\n",
    "cat('\\nTraining data has', nrow(training_housing), 'rows.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9704edc95d369e04659fa816a93d125c",
     "grade": false,
     "grade_id": "cell-4bea34ca87ec85f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You don't want to even look at the test data. \n",
    "# Set it aside.\n",
    "\n",
    "cat('\\nTest data has', nrow(testing_housing), 'rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9bd434ffcae3cf3303e09a7363e16238",
     "grade": false,
     "grade_id": "cell-cfd5f798bca9908d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **2.3.1 Estimating an MLR and Predicting**\n",
    "\n",
    "In DSCI100, you have learned how to use `tidymodels` to build a model and use it to predict. You can write your own script to perform these steps or use a `linear_reg` model specification with the `lm` engine in `tidymodels`. Below, you will use the usual tidymodels workflow to predict each house's sale price in the test set.\n",
    "\n",
    "Run this code to fit a MLR using `tidymodels` and call it `housing_full_tidy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b64d3bf69110a1fee952b80f614d7514",
     "grade": false,
     "grade_id": "cell-9f38c52756dd7dfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_spec <- \n",
    "    linear_reg() %>% \n",
    "    set_engine(\"lm\") %>% \n",
    "    set_mode(\"regression\")\n",
    "\n",
    "lm_recipe <- recipe(SalePrice ~ ., data = training_housing)\n",
    "\n",
    "housing_full_tidy <- \n",
    "    workflow() %>% \n",
    "    add_recipe(lm_recipe) %>% \n",
    "    add_model(lm_spec) %>% \n",
    "    fit(data = training_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "690ad302db9c8e93f181e935f5d5758c",
     "grade": false,
     "grade_id": "cell-55a3f1be685733c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Recall that we can extract the estimated coefficients from the workflow using the `extract_git_parsnip()` function. We then use `tidy()` to arrange them into a data frame.\n",
    "\n",
    "Run the code below to get the estimated coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74309f636afa7d828d8436aae33ea439",
     "grade": false,
     "grade_id": "cell-252bbfc230614233",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coeffs <- \n",
    "    housing_full_tidy %>% \n",
    "    extract_fit_parsnip() %>% \n",
    "    tidy()\n",
    "\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7a65ed7c4b0e86846286357d4fb04fd",
     "grade": false,
     "grade_id": "cell-92225ba1bcfd49ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 3.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Write your own code and compare the results obtained with those using `tidymodels`\n",
    "\n",
    "- Fit a MLR using data from `training_housing`. Store the output in an object named `housing_full_OLS`.\n",
    "\n",
    "- Use `tidy()` to obtain a summary table of the estimated `housing_full_OLS`. Call it `housing_full_OLS_results`.\n",
    "\n",
    "- Use the `modelr::add_predictions()` and `housing_full_OLS` to obtain the **out-of-sample predictions** for `testing_housing`. Store them as a new column in `testing_housing` called `pred_full_OLS`.\n",
    "\n",
    "> **Note**: if you enter the input variables manually in `lm`, follow the order in the dataset. This is not important for results, just to pass the tests of autograding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e94b754dc1a3d2a9328be1270da7014",
     "grade": false,
     "grade_id": "cell-d9c668e2b532fbc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code goes here. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "housing_full_OLS_results\n",
    "head(testing_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0505558214eb260f117a1d2feb03f0f",
     "grade": true,
     "grade_id": "cell-976fe40dfb808a95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f62dd6d74a3d4fe127d49b68e9377ad",
     "grade": false,
     "grade_id": "cell-018c67dd165c7d79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 3.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Running the code below, you can check whether the estimated coefficients obtained using the `tidymodels` workflow are the same as those obtained using your code. \n",
    "\n",
    "Are they the same? \n",
    "\n",
    "*Assign your answer to an object called `answer3.1`. Your answer should be either `\"true\"` or `\"false\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ede6907b2940720044e6d40fd26d2ae7",
     "grade": false,
     "grade_id": "cell-a0f01e4daa5d0b5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to compare the estimates\n",
    "tibble(estimates_your_code = housing_full_OLS_results$estimate,\n",
    "       estimate_tidymodels = coeffs$estimate, \n",
    "       difference = housing_full_OLS_results$estimate - coeffs$estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2ccb501fc38c00b59efd6b9b3782335",
     "grade": false,
     "grade_id": "cell-8ea2dda367d4fd62",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer3.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "202fdb5aa5889a5439b9ed83c5f6d921",
     "grade": true,
     "grade_id": "cell-8f424ba76018ad76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "746e19340793c3b21374ddf9b92e6b40",
     "grade": false,
     "grade_id": "cell-8cd6efd0c1c53d7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "We can use the function `metrics()` to compute the root mean squared error, the $R^2$ and the mean absolute error for the predicted `SalePrice` of the test samples. \n",
    "\n",
    "Alternatively, we can write our own code to compute these measures. In this exercise, write your code to calculate the RMSE. \n",
    "\n",
    "Create a tibble, called `housing_RMSE_models` to store the computed RMSE. We will later compare it with the RMSE of a reduced model. The new tibble will have 2 columns:\n",
    "\n",
    "- `Model`: Name of the estimated model from which we will obtain the prediction accuracy.\n",
    "- `RMSE`: The $\\text{RMSE}_{\\text{test}}$ corresponding to the estimated model.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "801ca3eb38d27db08bd46d9c03816bea",
     "grade": false,
     "grade_id": "cell-a325bd988a79aa49",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. compute the RMSE (the template below is for inspiration, but you can calculate it\n",
    "#    any way you want. \n",
    "\n",
    "# rmse_full <-\n",
    "#     ...\n",
    "#     ...\n",
    "#     ...\n",
    "#     ...\n",
    "\n",
    "# 2. store it in a tibble:\n",
    "\n",
    "# housing_RMSE_models <- tibble(\n",
    "#   Model = \"OLS Full Regression\",\n",
    "#   RMSE = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "housing_RMSE_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be4e03ed47d5ed6a3554ecd8fb6b2413",
     "grade": true,
     "grade_id": "cell-bd5363bd8cd05844",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85cf04d74feec09bbef76e71dd2ab38b",
     "grade": false,
     "grade_id": "cell-c3b15096f7ada01e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Run the code below to compare the results with those obtained with `metics()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1734f4df3a6d881745dce70d86a5c610",
     "grade": false,
     "grade_id": "cell-734c7db6f61e879a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_test_metrics <- \n",
    "    testing_housing %>%\n",
    "    metrics(truth = SalePrice, estimate = pred_full_OLS)\n",
    "\n",
    "housing_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkred'>**Tip:** In practice, refrain from creating your own functions if a reliable package with the desired function is available. This not only saves time but also minimizes the risk of bugs and errors, as these functions are widely tested.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee9f8c6172c3a019d5c68f9a2003fd33",
     "grade": false,
     "grade_id": "cell-8f8a4c8fe2b330e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## **2.4 An automated procedure for model selection**\n",
    "\n",
    "When we don't know which variables should be included in the model, ideally, you want to select the best model out of *all possible models* of all possible sizes. \n",
    "\n",
    "For example, if the dataset has 2 explanatory variables $X_1$ and $X_2$, there are 4 models to compare: \n",
    "    \n",
    "1. an intercept-only model; \n",
    "2. a model with only $X_1$; \n",
    "3. a model with only $X_2$; and \n",
    "4. a model with both $X_1$ and $X_2$. \n",
    "\n",
    "Unfortunately, the number of *all possible* models becomes too large rapidly, even for a small subset of variables. In fact, from a set of $p$ variables, we can fit a total of $2^p$ different models. For example, if $p = 20$ (i.e., 20 available explanatory variables), we would need to evaluate more than a million models. \n",
    "\n",
    "There are methods to search more efficiently for a good model (although it may not find the \"best\" one out of all possible):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6def39e540fe3f7aa25a97b5b3285503",
     "grade": false,
     "grade_id": "cell-407d22a6a1e202f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **2.4.1 Forward selection**: \n",
    "Image from [ISLR](https://www.statlearning.com)\n",
    "![](https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/forward.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c754c33051a1988f0d596f18378e303",
     "grade": false,
     "grade_id": "cell-fb0d05896adad813",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. **Step 1:** Start with the intercept-only model: $y_i = \\beta_0 + \\varepsilon_i$ (remember that in this case, $\\hat{\\beta}_0 = \\bar{y}$ from the training samples, so $\\hat{y} = \\bar{y}$ for any observation from the training or the test set)\n",
    "\n",
    "2. **Step 2:** Evaluate all models of size 1, choose the \"best\" model with 1 covariate (based on RSS, equal size models), and call it $\\mathcal{M}_1$. \n",
    "\n",
    "3. **Step 3** *Starting with the best size 1 model*, add 1 variable to create a (expanded) model of size 2. Repeat for all remaining variables and evaluate all expanded models of size 2. Choose the best model of size 2 (based on RSS) and call it $\\mathcal{M}_2$. (*Note that there are more models of size 2 that we are not evaluating since 1 variable has already been chosen in the previous step*).\n",
    "\n",
    "\n",
    "$\\quad \\quad \\vdots$ \n",
    "\n",
    "continue until you reach a predetermined model size or the full model, $\\mathcal{M}_p$. Note that the full model is unique. \n",
    "\n",
    "\n",
    "Now, we have to select the best out of the $p$ selected models: \n",
    "- $\\mathcal{M}_1$ (the best model of size 1);\n",
    "- $\\mathcal{M}_2$ (the best-expanded model of size 2),\n",
    "- $\\ \\ \\vdots$\n",
    "- $\\mathcal{M}_p$ (the full model of size $p$). \n",
    "\n",
    "Unfortunately, we cannot use the RSS to compare models of different sizes. In fact, the metric will depend on the study goal. For generative models, the adjusted $R^2$ can be helpful. If the objective is predictions, then the test MSE, $C_p$, AIC, or BIC are useful.\n",
    " \n",
    "You can learn more about these measures in [ISLR](https://www.statlearning.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47fba39ea0fa6be89c9d21375475f315",
     "grade": false,
     "grade_id": "cell-de41449632c6590f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Other selection procedures include:\n",
    "\n",
    "- **Backward selection**: start with the full model and remove variables, one at a time\n",
    "\n",
    "\n",
    "- **Hybrid selection**: after adding a variable, the method may also remove variables \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "825e152c733ef9d2832b7cffa562d398",
     "grade": false,
     "grade_id": "cell-bf5842286faba0c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### **2.4.2 Selecting a smaller model**\n",
    "\n",
    "The OLS model estimates a generative model using all input variables. However, as we see from the results table, not all the terms in this regression are statistically significant, and this may not be the best predictive model either. You might want to select a smaller subset of variables that better explain the variation in `SalePrice` or to predict. In the following questions, you will use the forward selection algorithm to select a smaller model. We will compute different metrics to examine different types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed9dea9591c60cc63dbf42b9160bce9e",
     "grade": false,
     "grade_id": "cell-195b5904f0f0cd43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **R functions**\n",
    "\n",
    "Both the **forward** and **backward** selection algorithms are implemented in R by the function `regsubsets()` from library `leaps`. \n",
    "\n",
    "- The argument `x` of `regsubsets()` is analogous to `formula` in `lm()`. \n",
    "\n",
    "- The argument `nvmax` indicates the maximum number of variables to be used in the variable selection.\n",
    "\n",
    "This function identifies subsets of input variables that provide the best model for different model sizes and then selects the best among those.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61d66b3879afb69659da8805c46181c0",
     "grade": false,
     "grade_id": "cell-c5d137288b408d5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Forward selection in the `housing`  dataset**\n",
    "\n",
    "Let's select some of the input variables in the `housing` dataset using the **forward selection** algorithm, aiming for a strong generative model. \n",
    "\n",
    "Create one object using `regsubsets()`with `training_housing`: `housing_forward_sel`. This object has to indicate  selected models for each model size, from **1 to 19 input variables** (check argument `nvmax`).\n",
    "\n",
    "*Run the code below to select the best nested models of each size*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27646a33c608bd3447257b7fc3040e8c",
     "grade": false,
     "grade_id": "cell-7b173b9bec803e9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_forward_sel <- regsubsets(x = SalePrice ~ ., nvmax = 19,\n",
    "                                  data = training_housing,\n",
    "                                  method = \"forward\")\n",
    "\n",
    "housing_forward_summary <- summary(housing_forward_sel)\n",
    "housing_forward_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34388314172355e331817ee369bce019",
     "grade": false,
     "grade_id": "cell-04e315d7f0efdfff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can see that: \n",
    "\n",
    "- variables are selected one at a time.\n",
    "\n",
    "- once the variable is in the model, it stays, and another variable is selected\n",
    "\n",
    "- the algorithm continues until it builds a model of size `nvmax`\n",
    "\n",
    "**Final selection**\n",
    "\n",
    "Out of the 19 possible models obtained with forward selection and stored in `housing_forward_sel`, we can select the best one in terms of its *goodness of fit*. \n",
    "\n",
    "Let's store and examine different evaluation metrics contained in `housing_forward_summary`. Construct a tibble called `housing_forward_eval`. This object should contain the following columns:\n",
    "\n",
    "- `n_input_variables`: the number of input variables in each selected model (from 1 to 19).\n",
    "\n",
    "- `RSQ`: the $R^2$ of each model\n",
    "\n",
    "- `RSS`: the RSS of each model\n",
    "\n",
    "- `ADJ_R2`: the adjusted $R^2$ of each model\n",
    "\n",
    "- `Cp`: the $C_p$ of each model\n",
    "\n",
    "- `BIC`: the Bayesian Information Criterion of each model\n",
    "\n",
    "*Run the following code to evaluate the best models of each size*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be546281fd2225efca8e044139641f0e",
     "grade": false,
     "grade_id": "cell-6790f3a767aece0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_forward_summary_df <- tibble(\n",
    "    n_input_variables = 1:19,\n",
    "    RSQ = housing_forward_summary$rsq,\n",
    "    RSS = housing_forward_summary$rss,\n",
    "    ADJ_R2 = housing_forward_summary$adjr2,\n",
    "    Cp = housing_forward_summary$cp,\n",
    "    BIC = housing_forward_summary$bic,\n",
    ")\n",
    "housing_forward_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "183548836cb4de6b57815100647d58ca",
     "grade": false,
     "grade_id": "cell-69bc1407080925bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can see how the $R^2$ increases with more variables in the model. However, its adjusted version will start decreasing after 13 variables are selected. \n",
    "\n",
    "**The forward algorithm would select a generative model with 13 variables using the adjusted $R^2$**.\n",
    "\n",
    "**The forward algorithm would select a predictive model with 11 variables using BIC**.\n",
    "\n",
    "We can **visualize** how these measures change as variables are added to the selected model with the function `plot()`. \n",
    "\n",
    "Run this code to plot the $C_p$ of the models selected by the forward selection algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91e334b3f38b41d3477b0abef88e5e08",
     "grade": false,
     "grade_id": "cell-0693a2cff89dfa39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(summary(housing_forward_sel)$cp,\n",
    "     main = \"Cp for forward selection\",\n",
    "     xlab = \"Number of Input Variables\", \n",
    "     ylab = \"Rsq\",\n",
    "     type = \"b\",\n",
    "     pch = 19,\n",
    "     col = \"red\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61a486b5c1fc70d012c4c83e21c89f19",
     "grade": false,
     "grade_id": "cell-5b3fd20fb437c9de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **Prediction performance of the selected predictive model**\n",
    "\n",
    "In this problem, you will select the model that minimizes the $C_p$. Once we have a selected model we can train it using `lm()` with the training dataset and use it predict values of the residences in the test set. \n",
    "\n",
    "Run this code to obtain the name of the variables selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e25506558711ed992aa22be4838d90b1",
     "grade": false,
     "grade_id": "cell-a841f211bf64e777",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_min = which.min(housing_forward_summary$cp) \n",
    "\n",
    "selected_var <- names(coef(housing_forward_sel, cp_min))[-1]\n",
    "selected_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3b0f66ba514ff2d33e4722874dd46a3",
     "grade": false,
     "grade_id": "cell-67995940c0bcc135",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Run this code to subset only the predictors selected from the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85bd1b7ef061a546496cefdc22ff846b",
     "grade": false,
     "grade_id": "cell-943bb2d88f880089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_subset <- \n",
    "    training_housing %>% \n",
    "    select(selected_var, SalePrice)\n",
    "\n",
    "testing_subset <- \n",
    "    testing_housing %>% \n",
    "    select(selected_var, SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e355ca6f774247c9156932c2a9c3c41c",
     "grade": false,
     "grade_id": "cell-93e95f38df759d47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Run this code to train the selected models and use it to predict in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8844ca948175414b40c772173bda7ac2",
     "grade": false,
     "grade_id": "cell-05251bb3db6a3810",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimation\n",
    "\n",
    "housing_red_OLS <- lm(SalePrice ~ ., data = training_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04a7bebb25132f37cd4a7910b7e6a4f1",
     "grade": false,
     "grade_id": "cell-e6c3ceb269ad8bd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 4.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use the new reduced predictive model, `housing_red_OLS`, to predict the response in the test set `testing_subset`. Use the resulting predictive values to compute the error and the $\\text{RMSE}_{\\text{test}}$ of the predictive values. Add this metric as another row in the tibble `housing_RMSE_models` and store the expanded `housing_RMSE_models` in an object called `housing_RMSE_models_expanded`. Identify the new row as `\"OLS Reduced Regression\"` (in column `Model`) and enter the corresponding $\\text{RMSE}_{\\text{test}}$ in the column `RMSE`.\n",
    "\n",
    "> Note: since you are adding a row to an existing object, you may need to restart the kernel or rerun the cell with the original data frame to avoid extra concatenation.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf5bb79859f7ea658b07bac6af6861bc",
     "grade": false,
     "grade_id": "cell-b0bc48dc5dfd91bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [You are all grown up now, do your own coding :) ]\n",
    "\n",
    "# housing_RMSE_models_expanded <- \n",
    "#     bind_rows(\n",
    "#         housing_RMSE_models,\n",
    "#         tibble(Model = \"OLS Reduced Regression\",\n",
    "#                RMSE = ...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "housing_RMSE_models_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e0de85708ab2e73f45f1a982633928f",
     "grade": true,
     "grade_id": "cell-25b2040355c36cb8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_4.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "897843eb672ea8b9b974e9cca41072dd",
     "grade": false,
     "grade_id": "cell-897661ec25ffa521",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "While we selected a reduced model with an expected better prediction performance, for this test set, the RMSE of the full model is lower than that of the reduced one. Note that this is only one estimate of the true test RMSE based on a random data split. A different split may give a different result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
