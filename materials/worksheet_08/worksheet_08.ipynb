{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61f2158d4529b27457cbbd1d7bae293a",
     "grade": false,
     "grade_id": "cell-f1e1d845873036f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Worksheet 08: Classifiers as an Important Class of Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cca84cb3ce52ad19008100efebf7400a",
     "grade": false,
     "grade_id": "cell-82d9926086d47a80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Lecture and Tutorial Learning Goals:\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "\n",
    "1. Give an example of a research question that requires a predictive model to predict classes on new observations.\n",
    "2. Explain the trade-offs between model-based and non-model based approaches, and describe situations where each might be the preferred approach.\n",
    "3. Write a computer script to perform model selection using ridge and LASSO regressions to fit a logistic regression useful for predictive modeling.\n",
    "4. List model metrics that are suitable to evaluate predicted classes given by a predictive model with binary responses (e.g., Accuracy, Precision, Sensitivity, Specificity, Cohen's kappa).\n",
    "5. Write a computer script to compute these model metrics. Interpret and communicate the results from that computer script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b21f086e78645fc2c7cfdde000bd6384",
     "grade": false,
     "grade_id": "cell-a2a153352bc44a68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.1     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n",
      "\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "\n",
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "\n",
      "Attaching package: ‘pROC’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    cov, smooth, var\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘boot’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:lattice’:\n",
      "\n",
      "    melanoma\n",
      "\n",
      "\n",
      "Loading required package: Matrix\n",
      "\n",
      "\n",
      "Attaching package: ‘Matrix’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:tidyr’:\n",
      "\n",
      "    expand, pack, unpack\n",
      "\n",
      "\n",
      "Loaded glmnet 4.1-8\n",
      "\n",
      "\n",
      "Attaching package: ‘testthat’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    matches\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    is_null\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:readr’:\n",
      "\n",
      "    edition_get, local_edition\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    matches\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell before continuing.\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(infer)\n",
    "library(gridExtra)\n",
    "library(caret)\n",
    "library(pROC)\n",
    "library(boot)\n",
    "library(glmnet)\n",
    "source(\"tests_worksheet_08.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd5a7e3af167bf4e4a6abe6d668b4476",
     "grade": false,
     "grade_id": "cell-d49da5ef86c90dee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Predicting classes\n",
    "\n",
    "In previous weeks, we have focused more on the inferential aspects of the models. This week, we are switching our focus to prediction since in many situations the inference is not a priority. \n",
    "\n",
    "When diagnosing a disease, a doctor obtains the patient's medical history and some contextual information (e.g., profession, age, has the patient travelled abroad? etc.), wich combined with some tests results, allows the doctor to make a diagnosis. \n",
    "\n",
    "A priori, the patient doesn't care how exactly the doctor made the diagnosis. For example, did the doctor give more importance to the patient's age? or maybe to the result of a blood test? or even a complex combination of those two? Whatever! As long as the diagnosis is correct.\n",
    "\n",
    "However, to analyze whether the doctor's process (or *model*) to make the diagnosis is reliable, we must consider different aspects. For example,\n",
    "\n",
    "- Is the doctor able to positively diagnose a high percentage of sick patients? (*sensitivity*)\n",
    "- Is the doctor able to correctly identify a high percentage of non-sick patients? (*specificity*)\n",
    "- If the doctor says that a patient is sick, is there a high chance that the patient is sick? (*precision*)\n",
    "- Considering all the doctor's positive and negative diagnoses, is the doctor right in most cases? (*accuracy*)\n",
    "\n",
    "At first glance, looking at all these aspects might look redundant. But let's try to understand why it is not. \n",
    "\n",
    "For example, \n",
    "\n",
    "- If the doctors always said a patient was sick, all the sick patients would be diagnosed. Therefore, the doctor would have great *sensitivity*. However, this doesn't seem very helpful, right? This would be reflected by the doctor's precision.\n",
    "- On the other hand, if the doctor only diagnoses patients as sick if there's overwhelming evidence, then the *precision* would be quite high. However, the *sensitivity* would be low, i.e., many sick patients wouldn't be diagnosed.\n",
    "- Imagine a very rare disease. Say 1 case in 100K people. If the doctor always says that the patient is not sick of that disease, then the accuracy will still be pretty high because the part he is getting wrong is quite small. Nonetheless, quite important! \n",
    "\n",
    "We are going to define these metrics later in the worksheet; this is just a motivation to show you that, for classification problems, only one metric might not be enough to give you the whole picture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d39779c4637560218a3aaf385a417e3",
     "grade": false,
     "grade_id": "cell-9be71f65643c5906",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 1. Prediction in Logistic Regression\n",
    "\n",
    "In the previous week, we introduced logistic regression as a generative model for binary responses. We have already used this model for inferential purposes. Nonetheless, this model can also be used for predictions, i.e., using an estimated logistic model (via a training set) to classify new observations from a test set. \n",
    "\n",
    "To check prediction accuracy in classification, we cannot use metrics such as the **Root Mean Squared Error (R-MSE)** as in ordinary least squares (OLS) regression (check `worksheet_09` and `tutorial_09`). Therefore, this worksheet will introduce new metrics meant for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d38f4e0983e73bb19952302f676a7ed7",
     "grade": false,
     "grade_id": "cell-de7ac4434bc7a15a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Dataset\n",
    "\n",
    "For this worksheet, we will use the data frame `breast_cancer`. It is the Wisconsin Diagnostic Breast Cancer dataset ([Mangasarian et al., 1995](http://ubc.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwlV1Nb9QwEB2xPSA4tHQLohRKDoDgsDSJndiRKlApVBx74PNk2bGDKui2jbf8Ff4uM46tbpZKFZdIO55NvNLLeLx-8waAla_z2UpMEAZXtlZKzllZGSk7WTBdtDa3ts6N61aoOnUqjSGWZaAJhkN9zJfML7dHCi-yfnt-MaPmUXTIGjtpTGAi2cDr-rKkvFsPbQwYBpyafxsvQMTDbPEOVxE5yQSH8iZKHH2iKv4TrsMadLQBKk03kU9WagPHAo___7vuwXpMT7ODAU-bcMvNp3A7seOnsJG6QGQxKEzh7pKk4RQ2o91nL6Oi9ast-LN_qvufb94RAX6xvxc-ZIPtkFDXj23vB_rfiR-b9dxmx_3ZdUO_T_TYgFtsfIXHtuOBinaK84wD9-Hz0YdPhx9nsSPEDPeBJWmp6pJ3VS1tzlvR8Ua6WljWlm3RaMkMs52R1jmJWGu4a6wwtugaaauGtQWaH8Da_GzuHkJWVlpwbgpthKOz3aZsmeRWC9mJxnG7DS8STNT5IPyhaMOEO0xF_WkUZ4qrSuTomEB0k-MzgpiK3UXx4un_F_9DX3qvDjCPw2yPMbxfcCPwLXrd6lgngdMmqa5lx6cJqyoiNTzQLz3xeRq4YWZbAYxXXgGJ27CT8K5iZPOqJEFAUnl8dP2XduDOUPVPjObHsLboL92TIGmxCxPx9TteMcDshnf0L2aRR50)). It has a **binary** response `target`: whether the tumour is `benign` or `malignant`. Hence, the binary response $Y_i$ is mathematically set as:\n",
    "\n",
    "$$\n",
    "Y_i =\n",
    "\\begin{cases}\n",
    "1 \\; \\; \\; \\; \\mbox{if the $i$th tumour is malignant},\\\\\n",
    "0 \\; \\; \\; \\; \t\\mbox{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The data frame `breast_cancer` contains 569 observations from a digitized image of a breast mass' fine needle aspirate (FNA). The dataset details 30 real-valued characteristics (i.e., continuous input variables) plus the binary response and ID number. **We will only work with 16 input variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e57a241e0369bef028403a44ff65a5c",
     "grade": false,
     "grade_id": "cell-58d728f83cde45d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m569\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m32\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (1): target\n",
      "\u001b[32mdbl\u001b[39m (31): ID, mean_radius, mean_texture, mean_perimeter, mean_area, mean_smo...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "breast_cancer <- read_csv(\"data/breast_cancer.csv\") %>%\n",
    "  select(-c(\n",
    "    mean_area, area_error, concavity_error, concave_points_error, worst_radius, worst_texture, worst_perimeter,\n",
    "    worst_area, worst_smoothness, worst_compactness, worst_concavity, worst_concave_points, worst_symmetry,\n",
    "    worst_fractal_dimension\n",
    "  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 569 × 18</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>ID</th><th scope=col>mean_radius</th><th scope=col>mean_texture</th><th scope=col>mean_perimeter</th><th scope=col>mean_smoothness</th><th scope=col>mean_compactness</th><th scope=col>mean_concavity</th><th scope=col>mean_concave_points</th><th scope=col>mean_symmetry</th><th scope=col>mean_fractal_dimension</th><th scope=col>radius_error</th><th scope=col>texture_error</th><th scope=col>perimeter_error</th><th scope=col>smoothness_error</th><th scope=col>compactness_error</th><th scope=col>symmetry_error</th><th scope=col>fractal_dimension_error</th><th scope=col>target</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0</td><td>17.990</td><td>10.38</td><td>122.80</td><td>0.11840</td><td>0.27760</td><td>0.30010</td><td>0.14710</td><td>0.2419</td><td>0.07871</td><td>1.0950</td><td>0.9053</td><td> 8.589</td><td>0.006399</td><td>0.049040</td><td>0.03003</td><td>0.006193</td><td>malignant</td></tr>\n",
       "\t<tr><td> 1</td><td>20.570</td><td>17.77</td><td>132.90</td><td>0.08474</td><td>0.07864</td><td>0.08690</td><td>0.07017</td><td>0.1812</td><td>0.05667</td><td>0.5435</td><td>0.7339</td><td> 3.398</td><td>0.005225</td><td>0.013080</td><td>0.01389</td><td>0.003532</td><td>malignant</td></tr>\n",
       "\t<tr><td> 2</td><td>19.690</td><td>21.25</td><td>130.00</td><td>0.10960</td><td>0.15990</td><td>0.19740</td><td>0.12790</td><td>0.2069</td><td>0.05999</td><td>0.7456</td><td>0.7869</td><td> 4.585</td><td>0.006150</td><td>0.040060</td><td>0.02250</td><td>0.004571</td><td>malignant</td></tr>\n",
       "\t<tr><td> 3</td><td>11.420</td><td>20.38</td><td> 77.58</td><td>0.14250</td><td>0.28390</td><td>0.24140</td><td>0.10520</td><td>0.2597</td><td>0.09744</td><td>0.4956</td><td>1.1560</td><td> 3.445</td><td>0.009110</td><td>0.074580</td><td>0.05963</td><td>0.009208</td><td>malignant</td></tr>\n",
       "\t<tr><td> 4</td><td>20.290</td><td>14.34</td><td>135.10</td><td>0.10030</td><td>0.13280</td><td>0.19800</td><td>0.10430</td><td>0.1809</td><td>0.05883</td><td>0.7572</td><td>0.7813</td><td> 5.438</td><td>0.011490</td><td>0.024610</td><td>0.01756</td><td>0.005115</td><td>malignant</td></tr>\n",
       "\t<tr><td> 5</td><td>12.450</td><td>15.70</td><td> 82.57</td><td>0.12780</td><td>0.17000</td><td>0.15780</td><td>0.08089</td><td>0.2087</td><td>0.07613</td><td>0.3345</td><td>0.8902</td><td> 2.217</td><td>0.007510</td><td>0.033450</td><td>0.02165</td><td>0.005082</td><td>malignant</td></tr>\n",
       "\t<tr><td> 6</td><td>18.250</td><td>19.98</td><td>119.60</td><td>0.09463</td><td>0.10900</td><td>0.11270</td><td>0.07400</td><td>0.1794</td><td>0.05742</td><td>0.4467</td><td>0.7732</td><td> 3.180</td><td>0.004314</td><td>0.013820</td><td>0.01369</td><td>0.002179</td><td>malignant</td></tr>\n",
       "\t<tr><td> 7</td><td>13.710</td><td>20.83</td><td> 90.20</td><td>0.11890</td><td>0.16450</td><td>0.09366</td><td>0.05985</td><td>0.2196</td><td>0.07451</td><td>0.5835</td><td>1.3770</td><td> 3.856</td><td>0.008805</td><td>0.030290</td><td>0.01486</td><td>0.005412</td><td>malignant</td></tr>\n",
       "\t<tr><td> 8</td><td>13.000</td><td>21.82</td><td> 87.50</td><td>0.12730</td><td>0.19320</td><td>0.18590</td><td>0.09353</td><td>0.2350</td><td>0.07389</td><td>0.3063</td><td>1.0020</td><td> 2.406</td><td>0.005731</td><td>0.035020</td><td>0.02143</td><td>0.003749</td><td>malignant</td></tr>\n",
       "\t<tr><td> 9</td><td>12.460</td><td>24.04</td><td> 83.97</td><td>0.11860</td><td>0.23960</td><td>0.22730</td><td>0.08543</td><td>0.2030</td><td>0.08243</td><td>0.2976</td><td>1.5990</td><td> 2.039</td><td>0.007149</td><td>0.072170</td><td>0.01789</td><td>0.010080</td><td>malignant</td></tr>\n",
       "\t<tr><td>10</td><td>16.020</td><td>23.24</td><td>102.70</td><td>0.08206</td><td>0.06669</td><td>0.03299</td><td>0.03323</td><td>0.1528</td><td>0.05697</td><td>0.3795</td><td>1.1870</td><td> 2.466</td><td>0.004029</td><td>0.009269</td><td>0.01460</td><td>0.003042</td><td>malignant</td></tr>\n",
       "\t<tr><td>11</td><td>15.780</td><td>17.89</td><td>103.60</td><td>0.09710</td><td>0.12920</td><td>0.09954</td><td>0.06606</td><td>0.1842</td><td>0.06082</td><td>0.5058</td><td>0.9849</td><td> 3.564</td><td>0.005771</td><td>0.040610</td><td>0.02008</td><td>0.004144</td><td>malignant</td></tr>\n",
       "\t<tr><td>12</td><td>19.170</td><td>24.80</td><td>132.40</td><td>0.09740</td><td>0.24580</td><td>0.20650</td><td>0.11180</td><td>0.2397</td><td>0.07800</td><td>0.9555</td><td>3.5680</td><td>11.070</td><td>0.003139</td><td>0.082970</td><td>0.04484</td><td>0.012840</td><td>malignant</td></tr>\n",
       "\t<tr><td>13</td><td>15.850</td><td>23.95</td><td>103.70</td><td>0.08401</td><td>0.10020</td><td>0.09938</td><td>0.05364</td><td>0.1847</td><td>0.05338</td><td>0.4033</td><td>1.0780</td><td> 2.903</td><td>0.009769</td><td>0.031260</td><td>0.02981</td><td>0.003002</td><td>malignant</td></tr>\n",
       "\t<tr><td>14</td><td>13.730</td><td>22.61</td><td> 93.60</td><td>0.11310</td><td>0.22930</td><td>0.21280</td><td>0.08025</td><td>0.2069</td><td>0.07682</td><td>0.2121</td><td>1.1690</td><td> 2.061</td><td>0.006429</td><td>0.059360</td><td>0.01961</td><td>0.008093</td><td>malignant</td></tr>\n",
       "\t<tr><td>15</td><td>14.540</td><td>27.54</td><td> 96.73</td><td>0.11390</td><td>0.15950</td><td>0.16390</td><td>0.07364</td><td>0.2303</td><td>0.07077</td><td>0.3700</td><td>1.0330</td><td> 2.879</td><td>0.005607</td><td>0.042400</td><td>0.01857</td><td>0.005466</td><td>malignant</td></tr>\n",
       "\t<tr><td>16</td><td>14.680</td><td>20.13</td><td> 94.74</td><td>0.09867</td><td>0.07200</td><td>0.07395</td><td>0.05259</td><td>0.1586</td><td>0.05922</td><td>0.4727</td><td>1.2400</td><td> 3.195</td><td>0.005718</td><td>0.011620</td><td>0.01410</td><td>0.002085</td><td>malignant</td></tr>\n",
       "\t<tr><td>17</td><td>16.130</td><td>20.68</td><td>108.10</td><td>0.11700</td><td>0.20220</td><td>0.17220</td><td>0.10280</td><td>0.2164</td><td>0.07356</td><td>0.5692</td><td>1.0730</td><td> 3.854</td><td>0.007026</td><td>0.025010</td><td>0.01689</td><td>0.004142</td><td>malignant</td></tr>\n",
       "\t<tr><td>18</td><td>19.810</td><td>22.15</td><td>130.00</td><td>0.09831</td><td>0.10270</td><td>0.14790</td><td>0.09498</td><td>0.1582</td><td>0.05395</td><td>0.7582</td><td>1.0170</td><td> 5.865</td><td>0.006494</td><td>0.018930</td><td>0.01356</td><td>0.001997</td><td>malignant</td></tr>\n",
       "\t<tr><td>19</td><td>13.540</td><td>14.36</td><td> 87.46</td><td>0.09779</td><td>0.08129</td><td>0.06664</td><td>0.04781</td><td>0.1885</td><td>0.05766</td><td>0.2699</td><td>0.7886</td><td> 2.058</td><td>0.008462</td><td>0.014600</td><td>0.01980</td><td>0.002300</td><td>benign   </td></tr>\n",
       "\t<tr><td>20</td><td>13.080</td><td>15.71</td><td> 85.63</td><td>0.10750</td><td>0.12700</td><td>0.04568</td><td>0.03110</td><td>0.1967</td><td>0.06811</td><td>0.1852</td><td>0.7477</td><td> 1.383</td><td>0.004097</td><td>0.018980</td><td>0.01678</td><td>0.002425</td><td>benign   </td></tr>\n",
       "\t<tr><td>21</td><td> 9.504</td><td>12.44</td><td> 60.34</td><td>0.10240</td><td>0.06492</td><td>0.02956</td><td>0.02076</td><td>0.1815</td><td>0.06905</td><td>0.2773</td><td>0.9768</td><td> 1.909</td><td>0.009606</td><td>0.014320</td><td>0.02027</td><td>0.002968</td><td>benign   </td></tr>\n",
       "\t<tr><td>22</td><td>15.340</td><td>14.26</td><td>102.50</td><td>0.10730</td><td>0.21350</td><td>0.20770</td><td>0.09756</td><td>0.2521</td><td>0.07032</td><td>0.4388</td><td>0.7096</td><td> 3.384</td><td>0.006789</td><td>0.053280</td><td>0.03672</td><td>0.004394</td><td>malignant</td></tr>\n",
       "\t<tr><td>23</td><td>21.160</td><td>23.04</td><td>137.20</td><td>0.09428</td><td>0.10220</td><td>0.10970</td><td>0.08632</td><td>0.1769</td><td>0.05278</td><td>0.6917</td><td>1.1270</td><td> 4.303</td><td>0.004728</td><td>0.012590</td><td>0.01083</td><td>0.001987</td><td>malignant</td></tr>\n",
       "\t<tr><td>24</td><td>16.650</td><td>21.38</td><td>110.00</td><td>0.11210</td><td>0.14570</td><td>0.15250</td><td>0.09170</td><td>0.1995</td><td>0.06330</td><td>0.8068</td><td>0.9017</td><td> 5.455</td><td>0.006048</td><td>0.018820</td><td>0.01468</td><td>0.002801</td><td>malignant</td></tr>\n",
       "\t<tr><td>25</td><td>17.140</td><td>16.40</td><td>116.00</td><td>0.11860</td><td>0.22760</td><td>0.22290</td><td>0.14010</td><td>0.3040</td><td>0.07413</td><td>1.0460</td><td>0.9760</td><td> 7.276</td><td>0.008029</td><td>0.037990</td><td>0.02308</td><td>0.007444</td><td>malignant</td></tr>\n",
       "\t<tr><td>26</td><td>14.580</td><td>21.53</td><td> 97.41</td><td>0.10540</td><td>0.18680</td><td>0.14250</td><td>0.08783</td><td>0.2252</td><td>0.06924</td><td>0.2545</td><td>0.9832</td><td> 2.110</td><td>0.004452</td><td>0.030550</td><td>0.01454</td><td>0.003711</td><td>malignant</td></tr>\n",
       "\t<tr><td>27</td><td>18.610</td><td>20.25</td><td>122.10</td><td>0.09440</td><td>0.10660</td><td>0.14900</td><td>0.07731</td><td>0.1697</td><td>0.05699</td><td>0.8529</td><td>1.8490</td><td> 5.632</td><td>0.010750</td><td>0.027220</td><td>0.02293</td><td>0.004217</td><td>malignant</td></tr>\n",
       "\t<tr><td>28</td><td>15.300</td><td>25.27</td><td>102.40</td><td>0.10820</td><td>0.16970</td><td>0.16830</td><td>0.08751</td><td>0.1926</td><td>0.06540</td><td>0.4390</td><td>1.0120</td><td> 3.498</td><td>0.005233</td><td>0.030570</td><td>0.01768</td><td>0.002967</td><td>malignant</td></tr>\n",
       "\t<tr><td>29</td><td>17.570</td><td>15.05</td><td>115.00</td><td>0.09847</td><td>0.11570</td><td>0.09875</td><td>0.07953</td><td>0.1739</td><td>0.06149</td><td>0.6003</td><td>0.8225</td><td> 4.655</td><td>0.005627</td><td>0.030330</td><td>0.01925</td><td>0.003742</td><td>malignant</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>539</td><td> 7.691</td><td>25.44</td><td> 48.34</td><td>0.08668</td><td>0.11990</td><td>0.092520</td><td>0.013640</td><td>0.2037</td><td>0.07751</td><td>0.2196</td><td>1.479</td><td>1.4450</td><td>0.015470</td><td>0.064570</td><td>0.02105</td><td>0.007551</td><td>benign   </td></tr>\n",
       "\t<tr><td>540</td><td>11.540</td><td>14.44</td><td> 74.65</td><td>0.09984</td><td>0.11200</td><td>0.067370</td><td>0.025940</td><td>0.1818</td><td>0.06782</td><td>0.2784</td><td>1.768</td><td>1.6280</td><td>0.012150</td><td>0.041120</td><td>0.01840</td><td>0.005512</td><td>benign   </td></tr>\n",
       "\t<tr><td>541</td><td>14.470</td><td>24.99</td><td> 95.81</td><td>0.08837</td><td>0.12300</td><td>0.100900</td><td>0.038900</td><td>0.1872</td><td>0.06341</td><td>0.2542</td><td>1.079</td><td>2.6150</td><td>0.007138</td><td>0.046530</td><td>0.02068</td><td>0.006111</td><td>benign   </td></tr>\n",
       "\t<tr><td>542</td><td>14.740</td><td>25.42</td><td> 94.70</td><td>0.08275</td><td>0.07214</td><td>0.041050</td><td>0.030270</td><td>0.1840</td><td>0.05680</td><td>0.3031</td><td>1.385</td><td>2.1770</td><td>0.004775</td><td>0.011720</td><td>0.01870</td><td>0.002626</td><td>benign   </td></tr>\n",
       "\t<tr><td>543</td><td>13.210</td><td>28.06</td><td> 84.88</td><td>0.08671</td><td>0.06877</td><td>0.029870</td><td>0.032750</td><td>0.1628</td><td>0.05781</td><td>0.2351</td><td>1.597</td><td>1.5390</td><td>0.004973</td><td>0.013720</td><td>0.01724</td><td>0.001343</td><td>benign   </td></tr>\n",
       "\t<tr><td>544</td><td>13.870</td><td>20.70</td><td> 89.77</td><td>0.09578</td><td>0.10180</td><td>0.036880</td><td>0.023690</td><td>0.1620</td><td>0.06688</td><td>0.2720</td><td>1.047</td><td>2.0760</td><td>0.006298</td><td>0.021720</td><td>0.01490</td><td>0.003599</td><td>benign   </td></tr>\n",
       "\t<tr><td>545</td><td>13.620</td><td>23.23</td><td> 87.19</td><td>0.09246</td><td>0.06747</td><td>0.029740</td><td>0.024430</td><td>0.1664</td><td>0.05801</td><td>0.3460</td><td>1.336</td><td>2.0660</td><td>0.005868</td><td>0.020990</td><td>0.02087</td><td>0.002583</td><td>benign   </td></tr>\n",
       "\t<tr><td>546</td><td>10.320</td><td>16.35</td><td> 65.31</td><td>0.09434</td><td>0.04994</td><td>0.010120</td><td>0.005495</td><td>0.1885</td><td>0.06201</td><td>0.2104</td><td>0.967</td><td>1.3560</td><td>0.007086</td><td>0.007247</td><td>0.01560</td><td>0.002606</td><td>benign   </td></tr>\n",
       "\t<tr><td>547</td><td>10.260</td><td>16.58</td><td> 65.85</td><td>0.08877</td><td>0.08066</td><td>0.043580</td><td>0.024380</td><td>0.1669</td><td>0.06714</td><td>0.1144</td><td>1.023</td><td>0.9887</td><td>0.010270</td><td>0.030840</td><td>0.02277</td><td>0.005890</td><td>benign   </td></tr>\n",
       "\t<tr><td>548</td><td> 9.683</td><td>19.34</td><td> 61.05</td><td>0.08491</td><td>0.05030</td><td>0.023370</td><td>0.009615</td><td>0.1580</td><td>0.06235</td><td>0.2957</td><td>1.363</td><td>2.0540</td><td>0.007440</td><td>0.011230</td><td>0.02203</td><td>0.004154</td><td>benign   </td></tr>\n",
       "\t<tr><td>549</td><td>10.820</td><td>24.21</td><td> 68.89</td><td>0.08192</td><td>0.06602</td><td>0.015480</td><td>0.008160</td><td>0.1976</td><td>0.06328</td><td>0.5196</td><td>1.918</td><td>3.5640</td><td>0.008263</td><td>0.018700</td><td>0.02466</td><td>0.002977</td><td>benign   </td></tr>\n",
       "\t<tr><td>550</td><td>10.860</td><td>21.48</td><td> 68.51</td><td>0.07431</td><td>0.04227</td><td>0.000000</td><td>0.000000</td><td>0.1661</td><td>0.05948</td><td>0.3163</td><td>1.304</td><td>2.1150</td><td>0.009579</td><td>0.011040</td><td>0.03004</td><td>0.002228</td><td>benign   </td></tr>\n",
       "\t<tr><td>551</td><td>11.130</td><td>22.44</td><td> 71.49</td><td>0.09566</td><td>0.08194</td><td>0.048240</td><td>0.022570</td><td>0.2030</td><td>0.06552</td><td>0.2800</td><td>1.467</td><td>1.9940</td><td>0.003495</td><td>0.030510</td><td>0.02912</td><td>0.004723</td><td>benign   </td></tr>\n",
       "\t<tr><td>552</td><td>12.770</td><td>29.43</td><td> 81.35</td><td>0.08276</td><td>0.04234</td><td>0.019970</td><td>0.014990</td><td>0.1539</td><td>0.05637</td><td>0.2409</td><td>1.367</td><td>1.4770</td><td>0.008835</td><td>0.012330</td><td>0.01897</td><td>0.001726</td><td>benign   </td></tr>\n",
       "\t<tr><td>553</td><td> 9.333</td><td>21.94</td><td> 59.01</td><td>0.09240</td><td>0.05605</td><td>0.039960</td><td>0.012820</td><td>0.1692</td><td>0.06576</td><td>0.3013</td><td>1.879</td><td>2.1210</td><td>0.010940</td><td>0.018340</td><td>0.03759</td><td>0.004623</td><td>benign   </td></tr>\n",
       "\t<tr><td>554</td><td>12.880</td><td>28.92</td><td> 82.50</td><td>0.08123</td><td>0.05824</td><td>0.061950</td><td>0.023430</td><td>0.1566</td><td>0.05708</td><td>0.2116</td><td>1.360</td><td>1.5020</td><td>0.008412</td><td>0.021530</td><td>0.01695</td><td>0.002801</td><td>benign   </td></tr>\n",
       "\t<tr><td>555</td><td>10.290</td><td>27.61</td><td> 65.67</td><td>0.09030</td><td>0.07658</td><td>0.059990</td><td>0.027380</td><td>0.1593</td><td>0.06127</td><td>0.2199</td><td>2.239</td><td>1.4370</td><td>0.012050</td><td>0.027360</td><td>0.01843</td><td>0.004938</td><td>benign   </td></tr>\n",
       "\t<tr><td>556</td><td>10.160</td><td>19.59</td><td> 64.73</td><td>0.10030</td><td>0.07504</td><td>0.005025</td><td>0.011160</td><td>0.1791</td><td>0.06331</td><td>0.2441</td><td>2.090</td><td>1.6480</td><td>0.012910</td><td>0.022220</td><td>0.02572</td><td>0.002278</td><td>benign   </td></tr>\n",
       "\t<tr><td>557</td><td> 9.423</td><td>27.88</td><td> 59.26</td><td>0.08123</td><td>0.04971</td><td>0.000000</td><td>0.000000</td><td>0.1742</td><td>0.06059</td><td>0.5375</td><td>2.927</td><td>3.6180</td><td>0.011590</td><td>0.011240</td><td>0.03004</td><td>0.003324</td><td>benign   </td></tr>\n",
       "\t<tr><td>558</td><td>14.590</td><td>22.68</td><td> 96.39</td><td>0.08473</td><td>0.13300</td><td>0.102900</td><td>0.037360</td><td>0.1454</td><td>0.06147</td><td>0.2254</td><td>1.108</td><td>2.2240</td><td>0.004242</td><td>0.046390</td><td>0.01638</td><td>0.004406</td><td>benign   </td></tr>\n",
       "\t<tr><td>559</td><td>11.510</td><td>23.93</td><td> 74.52</td><td>0.09261</td><td>0.10210</td><td>0.111200</td><td>0.041050</td><td>0.1388</td><td>0.06570</td><td>0.2388</td><td>2.904</td><td>1.9360</td><td>0.008200</td><td>0.029820</td><td>0.01488</td><td>0.004738</td><td>benign   </td></tr>\n",
       "\t<tr><td>560</td><td>14.050</td><td>27.15</td><td> 91.38</td><td>0.09929</td><td>0.11260</td><td>0.044620</td><td>0.043040</td><td>0.1537</td><td>0.06171</td><td>0.3645</td><td>1.492</td><td>2.8880</td><td>0.007256</td><td>0.026780</td><td>0.02080</td><td>0.005304</td><td>benign   </td></tr>\n",
       "\t<tr><td>561</td><td>11.200</td><td>29.37</td><td> 70.67</td><td>0.07449</td><td>0.03558</td><td>0.000000</td><td>0.000000</td><td>0.1060</td><td>0.05502</td><td>0.3141</td><td>3.896</td><td>2.0410</td><td>0.007594</td><td>0.008878</td><td>0.01989</td><td>0.001773</td><td>benign   </td></tr>\n",
       "\t<tr><td>562</td><td>15.220</td><td>30.62</td><td>103.40</td><td>0.10480</td><td>0.20870</td><td>0.255000</td><td>0.094290</td><td>0.2128</td><td>0.07152</td><td>0.2602</td><td>1.205</td><td>2.3620</td><td>0.004625</td><td>0.048440</td><td>0.02137</td><td>0.006142</td><td>malignant</td></tr>\n",
       "\t<tr><td>563</td><td>20.920</td><td>25.09</td><td>143.00</td><td>0.10990</td><td>0.22360</td><td>0.317400</td><td>0.147400</td><td>0.2149</td><td>0.06879</td><td>0.9622</td><td>1.026</td><td>8.7580</td><td>0.006399</td><td>0.043100</td><td>0.02057</td><td>0.006213</td><td>malignant</td></tr>\n",
       "\t<tr><td>564</td><td>21.560</td><td>22.39</td><td>142.00</td><td>0.11100</td><td>0.11590</td><td>0.243900</td><td>0.138900</td><td>0.1726</td><td>0.05623</td><td>1.1760</td><td>1.256</td><td>7.6730</td><td>0.010300</td><td>0.028910</td><td>0.01114</td><td>0.004239</td><td>malignant</td></tr>\n",
       "\t<tr><td>565</td><td>20.130</td><td>28.25</td><td>131.20</td><td>0.09780</td><td>0.10340</td><td>0.144000</td><td>0.097910</td><td>0.1752</td><td>0.05533</td><td>0.7655</td><td>2.463</td><td>5.2030</td><td>0.005769</td><td>0.024230</td><td>0.01898</td><td>0.002498</td><td>malignant</td></tr>\n",
       "\t<tr><td>566</td><td>16.600</td><td>28.08</td><td>108.30</td><td>0.08455</td><td>0.10230</td><td>0.092510</td><td>0.053020</td><td>0.1590</td><td>0.05648</td><td>0.4564</td><td>1.075</td><td>3.4250</td><td>0.005903</td><td>0.037310</td><td>0.01318</td><td>0.003892</td><td>malignant</td></tr>\n",
       "\t<tr><td>567</td><td>20.600</td><td>29.33</td><td>140.10</td><td>0.11780</td><td>0.27700</td><td>0.351400</td><td>0.152000</td><td>0.2397</td><td>0.07016</td><td>0.7260</td><td>1.595</td><td>5.7720</td><td>0.006522</td><td>0.061580</td><td>0.02324</td><td>0.006185</td><td>malignant</td></tr>\n",
       "\t<tr><td>568</td><td> 7.760</td><td>24.54</td><td> 47.92</td><td>0.05263</td><td>0.04362</td><td>0.000000</td><td>0.000000</td><td>0.1587</td><td>0.05884</td><td>0.3857</td><td>1.428</td><td>2.5480</td><td>0.007189</td><td>0.004660</td><td>0.02676</td><td>0.002783</td><td>benign   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 569 × 18\n",
       "\\begin{tabular}{llllllllllllllllll}\n",
       " ID & mean\\_radius & mean\\_texture & mean\\_perimeter & mean\\_smoothness & mean\\_compactness & mean\\_concavity & mean\\_concave\\_points & mean\\_symmetry & mean\\_fractal\\_dimension & radius\\_error & texture\\_error & perimeter\\_error & smoothness\\_error & compactness\\_error & symmetry\\_error & fractal\\_dimension\\_error & target\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t  0 & 17.990 & 10.38 & 122.80 & 0.11840 & 0.27760 & 0.30010 & 0.14710 & 0.2419 & 0.07871 & 1.0950 & 0.9053 &  8.589 & 0.006399 & 0.049040 & 0.03003 & 0.006193 & malignant\\\\\n",
       "\t  1 & 20.570 & 17.77 & 132.90 & 0.08474 & 0.07864 & 0.08690 & 0.07017 & 0.1812 & 0.05667 & 0.5435 & 0.7339 &  3.398 & 0.005225 & 0.013080 & 0.01389 & 0.003532 & malignant\\\\\n",
       "\t  2 & 19.690 & 21.25 & 130.00 & 0.10960 & 0.15990 & 0.19740 & 0.12790 & 0.2069 & 0.05999 & 0.7456 & 0.7869 &  4.585 & 0.006150 & 0.040060 & 0.02250 & 0.004571 & malignant\\\\\n",
       "\t  3 & 11.420 & 20.38 &  77.58 & 0.14250 & 0.28390 & 0.24140 & 0.10520 & 0.2597 & 0.09744 & 0.4956 & 1.1560 &  3.445 & 0.009110 & 0.074580 & 0.05963 & 0.009208 & malignant\\\\\n",
       "\t  4 & 20.290 & 14.34 & 135.10 & 0.10030 & 0.13280 & 0.19800 & 0.10430 & 0.1809 & 0.05883 & 0.7572 & 0.7813 &  5.438 & 0.011490 & 0.024610 & 0.01756 & 0.005115 & malignant\\\\\n",
       "\t  5 & 12.450 & 15.70 &  82.57 & 0.12780 & 0.17000 & 0.15780 & 0.08089 & 0.2087 & 0.07613 & 0.3345 & 0.8902 &  2.217 & 0.007510 & 0.033450 & 0.02165 & 0.005082 & malignant\\\\\n",
       "\t  6 & 18.250 & 19.98 & 119.60 & 0.09463 & 0.10900 & 0.11270 & 0.07400 & 0.1794 & 0.05742 & 0.4467 & 0.7732 &  3.180 & 0.004314 & 0.013820 & 0.01369 & 0.002179 & malignant\\\\\n",
       "\t  7 & 13.710 & 20.83 &  90.20 & 0.11890 & 0.16450 & 0.09366 & 0.05985 & 0.2196 & 0.07451 & 0.5835 & 1.3770 &  3.856 & 0.008805 & 0.030290 & 0.01486 & 0.005412 & malignant\\\\\n",
       "\t  8 & 13.000 & 21.82 &  87.50 & 0.12730 & 0.19320 & 0.18590 & 0.09353 & 0.2350 & 0.07389 & 0.3063 & 1.0020 &  2.406 & 0.005731 & 0.035020 & 0.02143 & 0.003749 & malignant\\\\\n",
       "\t  9 & 12.460 & 24.04 &  83.97 & 0.11860 & 0.23960 & 0.22730 & 0.08543 & 0.2030 & 0.08243 & 0.2976 & 1.5990 &  2.039 & 0.007149 & 0.072170 & 0.01789 & 0.010080 & malignant\\\\\n",
       "\t 10 & 16.020 & 23.24 & 102.70 & 0.08206 & 0.06669 & 0.03299 & 0.03323 & 0.1528 & 0.05697 & 0.3795 & 1.1870 &  2.466 & 0.004029 & 0.009269 & 0.01460 & 0.003042 & malignant\\\\\n",
       "\t 11 & 15.780 & 17.89 & 103.60 & 0.09710 & 0.12920 & 0.09954 & 0.06606 & 0.1842 & 0.06082 & 0.5058 & 0.9849 &  3.564 & 0.005771 & 0.040610 & 0.02008 & 0.004144 & malignant\\\\\n",
       "\t 12 & 19.170 & 24.80 & 132.40 & 0.09740 & 0.24580 & 0.20650 & 0.11180 & 0.2397 & 0.07800 & 0.9555 & 3.5680 & 11.070 & 0.003139 & 0.082970 & 0.04484 & 0.012840 & malignant\\\\\n",
       "\t 13 & 15.850 & 23.95 & 103.70 & 0.08401 & 0.10020 & 0.09938 & 0.05364 & 0.1847 & 0.05338 & 0.4033 & 1.0780 &  2.903 & 0.009769 & 0.031260 & 0.02981 & 0.003002 & malignant\\\\\n",
       "\t 14 & 13.730 & 22.61 &  93.60 & 0.11310 & 0.22930 & 0.21280 & 0.08025 & 0.2069 & 0.07682 & 0.2121 & 1.1690 &  2.061 & 0.006429 & 0.059360 & 0.01961 & 0.008093 & malignant\\\\\n",
       "\t 15 & 14.540 & 27.54 &  96.73 & 0.11390 & 0.15950 & 0.16390 & 0.07364 & 0.2303 & 0.07077 & 0.3700 & 1.0330 &  2.879 & 0.005607 & 0.042400 & 0.01857 & 0.005466 & malignant\\\\\n",
       "\t 16 & 14.680 & 20.13 &  94.74 & 0.09867 & 0.07200 & 0.07395 & 0.05259 & 0.1586 & 0.05922 & 0.4727 & 1.2400 &  3.195 & 0.005718 & 0.011620 & 0.01410 & 0.002085 & malignant\\\\\n",
       "\t 17 & 16.130 & 20.68 & 108.10 & 0.11700 & 0.20220 & 0.17220 & 0.10280 & 0.2164 & 0.07356 & 0.5692 & 1.0730 &  3.854 & 0.007026 & 0.025010 & 0.01689 & 0.004142 & malignant\\\\\n",
       "\t 18 & 19.810 & 22.15 & 130.00 & 0.09831 & 0.10270 & 0.14790 & 0.09498 & 0.1582 & 0.05395 & 0.7582 & 1.0170 &  5.865 & 0.006494 & 0.018930 & 0.01356 & 0.001997 & malignant\\\\\n",
       "\t 19 & 13.540 & 14.36 &  87.46 & 0.09779 & 0.08129 & 0.06664 & 0.04781 & 0.1885 & 0.05766 & 0.2699 & 0.7886 &  2.058 & 0.008462 & 0.014600 & 0.01980 & 0.002300 & benign   \\\\\n",
       "\t 20 & 13.080 & 15.71 &  85.63 & 0.10750 & 0.12700 & 0.04568 & 0.03110 & 0.1967 & 0.06811 & 0.1852 & 0.7477 &  1.383 & 0.004097 & 0.018980 & 0.01678 & 0.002425 & benign   \\\\\n",
       "\t 21 &  9.504 & 12.44 &  60.34 & 0.10240 & 0.06492 & 0.02956 & 0.02076 & 0.1815 & 0.06905 & 0.2773 & 0.9768 &  1.909 & 0.009606 & 0.014320 & 0.02027 & 0.002968 & benign   \\\\\n",
       "\t 22 & 15.340 & 14.26 & 102.50 & 0.10730 & 0.21350 & 0.20770 & 0.09756 & 0.2521 & 0.07032 & 0.4388 & 0.7096 &  3.384 & 0.006789 & 0.053280 & 0.03672 & 0.004394 & malignant\\\\\n",
       "\t 23 & 21.160 & 23.04 & 137.20 & 0.09428 & 0.10220 & 0.10970 & 0.08632 & 0.1769 & 0.05278 & 0.6917 & 1.1270 &  4.303 & 0.004728 & 0.012590 & 0.01083 & 0.001987 & malignant\\\\\n",
       "\t 24 & 16.650 & 21.38 & 110.00 & 0.11210 & 0.14570 & 0.15250 & 0.09170 & 0.1995 & 0.06330 & 0.8068 & 0.9017 &  5.455 & 0.006048 & 0.018820 & 0.01468 & 0.002801 & malignant\\\\\n",
       "\t 25 & 17.140 & 16.40 & 116.00 & 0.11860 & 0.22760 & 0.22290 & 0.14010 & 0.3040 & 0.07413 & 1.0460 & 0.9760 &  7.276 & 0.008029 & 0.037990 & 0.02308 & 0.007444 & malignant\\\\\n",
       "\t 26 & 14.580 & 21.53 &  97.41 & 0.10540 & 0.18680 & 0.14250 & 0.08783 & 0.2252 & 0.06924 & 0.2545 & 0.9832 &  2.110 & 0.004452 & 0.030550 & 0.01454 & 0.003711 & malignant\\\\\n",
       "\t 27 & 18.610 & 20.25 & 122.10 & 0.09440 & 0.10660 & 0.14900 & 0.07731 & 0.1697 & 0.05699 & 0.8529 & 1.8490 &  5.632 & 0.010750 & 0.027220 & 0.02293 & 0.004217 & malignant\\\\\n",
       "\t 28 & 15.300 & 25.27 & 102.40 & 0.10820 & 0.16970 & 0.16830 & 0.08751 & 0.1926 & 0.06540 & 0.4390 & 1.0120 &  3.498 & 0.005233 & 0.030570 & 0.01768 & 0.002967 & malignant\\\\\n",
       "\t 29 & 17.570 & 15.05 & 115.00 & 0.09847 & 0.11570 & 0.09875 & 0.07953 & 0.1739 & 0.06149 & 0.6003 & 0.8225 &  4.655 & 0.005627 & 0.030330 & 0.01925 & 0.003742 & malignant\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 539 &  7.691 & 25.44 &  48.34 & 0.08668 & 0.11990 & 0.092520 & 0.013640 & 0.2037 & 0.07751 & 0.2196 & 1.479 & 1.4450 & 0.015470 & 0.064570 & 0.02105 & 0.007551 & benign   \\\\\n",
       "\t 540 & 11.540 & 14.44 &  74.65 & 0.09984 & 0.11200 & 0.067370 & 0.025940 & 0.1818 & 0.06782 & 0.2784 & 1.768 & 1.6280 & 0.012150 & 0.041120 & 0.01840 & 0.005512 & benign   \\\\\n",
       "\t 541 & 14.470 & 24.99 &  95.81 & 0.08837 & 0.12300 & 0.100900 & 0.038900 & 0.1872 & 0.06341 & 0.2542 & 1.079 & 2.6150 & 0.007138 & 0.046530 & 0.02068 & 0.006111 & benign   \\\\\n",
       "\t 542 & 14.740 & 25.42 &  94.70 & 0.08275 & 0.07214 & 0.041050 & 0.030270 & 0.1840 & 0.05680 & 0.3031 & 1.385 & 2.1770 & 0.004775 & 0.011720 & 0.01870 & 0.002626 & benign   \\\\\n",
       "\t 543 & 13.210 & 28.06 &  84.88 & 0.08671 & 0.06877 & 0.029870 & 0.032750 & 0.1628 & 0.05781 & 0.2351 & 1.597 & 1.5390 & 0.004973 & 0.013720 & 0.01724 & 0.001343 & benign   \\\\\n",
       "\t 544 & 13.870 & 20.70 &  89.77 & 0.09578 & 0.10180 & 0.036880 & 0.023690 & 0.1620 & 0.06688 & 0.2720 & 1.047 & 2.0760 & 0.006298 & 0.021720 & 0.01490 & 0.003599 & benign   \\\\\n",
       "\t 545 & 13.620 & 23.23 &  87.19 & 0.09246 & 0.06747 & 0.029740 & 0.024430 & 0.1664 & 0.05801 & 0.3460 & 1.336 & 2.0660 & 0.005868 & 0.020990 & 0.02087 & 0.002583 & benign   \\\\\n",
       "\t 546 & 10.320 & 16.35 &  65.31 & 0.09434 & 0.04994 & 0.010120 & 0.005495 & 0.1885 & 0.06201 & 0.2104 & 0.967 & 1.3560 & 0.007086 & 0.007247 & 0.01560 & 0.002606 & benign   \\\\\n",
       "\t 547 & 10.260 & 16.58 &  65.85 & 0.08877 & 0.08066 & 0.043580 & 0.024380 & 0.1669 & 0.06714 & 0.1144 & 1.023 & 0.9887 & 0.010270 & 0.030840 & 0.02277 & 0.005890 & benign   \\\\\n",
       "\t 548 &  9.683 & 19.34 &  61.05 & 0.08491 & 0.05030 & 0.023370 & 0.009615 & 0.1580 & 0.06235 & 0.2957 & 1.363 & 2.0540 & 0.007440 & 0.011230 & 0.02203 & 0.004154 & benign   \\\\\n",
       "\t 549 & 10.820 & 24.21 &  68.89 & 0.08192 & 0.06602 & 0.015480 & 0.008160 & 0.1976 & 0.06328 & 0.5196 & 1.918 & 3.5640 & 0.008263 & 0.018700 & 0.02466 & 0.002977 & benign   \\\\\n",
       "\t 550 & 10.860 & 21.48 &  68.51 & 0.07431 & 0.04227 & 0.000000 & 0.000000 & 0.1661 & 0.05948 & 0.3163 & 1.304 & 2.1150 & 0.009579 & 0.011040 & 0.03004 & 0.002228 & benign   \\\\\n",
       "\t 551 & 11.130 & 22.44 &  71.49 & 0.09566 & 0.08194 & 0.048240 & 0.022570 & 0.2030 & 0.06552 & 0.2800 & 1.467 & 1.9940 & 0.003495 & 0.030510 & 0.02912 & 0.004723 & benign   \\\\\n",
       "\t 552 & 12.770 & 29.43 &  81.35 & 0.08276 & 0.04234 & 0.019970 & 0.014990 & 0.1539 & 0.05637 & 0.2409 & 1.367 & 1.4770 & 0.008835 & 0.012330 & 0.01897 & 0.001726 & benign   \\\\\n",
       "\t 553 &  9.333 & 21.94 &  59.01 & 0.09240 & 0.05605 & 0.039960 & 0.012820 & 0.1692 & 0.06576 & 0.3013 & 1.879 & 2.1210 & 0.010940 & 0.018340 & 0.03759 & 0.004623 & benign   \\\\\n",
       "\t 554 & 12.880 & 28.92 &  82.50 & 0.08123 & 0.05824 & 0.061950 & 0.023430 & 0.1566 & 0.05708 & 0.2116 & 1.360 & 1.5020 & 0.008412 & 0.021530 & 0.01695 & 0.002801 & benign   \\\\\n",
       "\t 555 & 10.290 & 27.61 &  65.67 & 0.09030 & 0.07658 & 0.059990 & 0.027380 & 0.1593 & 0.06127 & 0.2199 & 2.239 & 1.4370 & 0.012050 & 0.027360 & 0.01843 & 0.004938 & benign   \\\\\n",
       "\t 556 & 10.160 & 19.59 &  64.73 & 0.10030 & 0.07504 & 0.005025 & 0.011160 & 0.1791 & 0.06331 & 0.2441 & 2.090 & 1.6480 & 0.012910 & 0.022220 & 0.02572 & 0.002278 & benign   \\\\\n",
       "\t 557 &  9.423 & 27.88 &  59.26 & 0.08123 & 0.04971 & 0.000000 & 0.000000 & 0.1742 & 0.06059 & 0.5375 & 2.927 & 3.6180 & 0.011590 & 0.011240 & 0.03004 & 0.003324 & benign   \\\\\n",
       "\t 558 & 14.590 & 22.68 &  96.39 & 0.08473 & 0.13300 & 0.102900 & 0.037360 & 0.1454 & 0.06147 & 0.2254 & 1.108 & 2.2240 & 0.004242 & 0.046390 & 0.01638 & 0.004406 & benign   \\\\\n",
       "\t 559 & 11.510 & 23.93 &  74.52 & 0.09261 & 0.10210 & 0.111200 & 0.041050 & 0.1388 & 0.06570 & 0.2388 & 2.904 & 1.9360 & 0.008200 & 0.029820 & 0.01488 & 0.004738 & benign   \\\\\n",
       "\t 560 & 14.050 & 27.15 &  91.38 & 0.09929 & 0.11260 & 0.044620 & 0.043040 & 0.1537 & 0.06171 & 0.3645 & 1.492 & 2.8880 & 0.007256 & 0.026780 & 0.02080 & 0.005304 & benign   \\\\\n",
       "\t 561 & 11.200 & 29.37 &  70.67 & 0.07449 & 0.03558 & 0.000000 & 0.000000 & 0.1060 & 0.05502 & 0.3141 & 3.896 & 2.0410 & 0.007594 & 0.008878 & 0.01989 & 0.001773 & benign   \\\\\n",
       "\t 562 & 15.220 & 30.62 & 103.40 & 0.10480 & 0.20870 & 0.255000 & 0.094290 & 0.2128 & 0.07152 & 0.2602 & 1.205 & 2.3620 & 0.004625 & 0.048440 & 0.02137 & 0.006142 & malignant\\\\\n",
       "\t 563 & 20.920 & 25.09 & 143.00 & 0.10990 & 0.22360 & 0.317400 & 0.147400 & 0.2149 & 0.06879 & 0.9622 & 1.026 & 8.7580 & 0.006399 & 0.043100 & 0.02057 & 0.006213 & malignant\\\\\n",
       "\t 564 & 21.560 & 22.39 & 142.00 & 0.11100 & 0.11590 & 0.243900 & 0.138900 & 0.1726 & 0.05623 & 1.1760 & 1.256 & 7.6730 & 0.010300 & 0.028910 & 0.01114 & 0.004239 & malignant\\\\\n",
       "\t 565 & 20.130 & 28.25 & 131.20 & 0.09780 & 0.10340 & 0.144000 & 0.097910 & 0.1752 & 0.05533 & 0.7655 & 2.463 & 5.2030 & 0.005769 & 0.024230 & 0.01898 & 0.002498 & malignant\\\\\n",
       "\t 566 & 16.600 & 28.08 & 108.30 & 0.08455 & 0.10230 & 0.092510 & 0.053020 & 0.1590 & 0.05648 & 0.4564 & 1.075 & 3.4250 & 0.005903 & 0.037310 & 0.01318 & 0.003892 & malignant\\\\\n",
       "\t 567 & 20.600 & 29.33 & 140.10 & 0.11780 & 0.27700 & 0.351400 & 0.152000 & 0.2397 & 0.07016 & 0.7260 & 1.595 & 5.7720 & 0.006522 & 0.061580 & 0.02324 & 0.006185 & malignant\\\\\n",
       "\t 568 &  7.760 & 24.54 &  47.92 & 0.05263 & 0.04362 & 0.000000 & 0.000000 & 0.1587 & 0.05884 & 0.3857 & 1.428 & 2.5480 & 0.007189 & 0.004660 & 0.02676 & 0.002783 & benign   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 569 × 18\n",
       "\n",
       "| ID &lt;dbl&gt; | mean_radius &lt;dbl&gt; | mean_texture &lt;dbl&gt; | mean_perimeter &lt;dbl&gt; | mean_smoothness &lt;dbl&gt; | mean_compactness &lt;dbl&gt; | mean_concavity &lt;dbl&gt; | mean_concave_points &lt;dbl&gt; | mean_symmetry &lt;dbl&gt; | mean_fractal_dimension &lt;dbl&gt; | radius_error &lt;dbl&gt; | texture_error &lt;dbl&gt; | perimeter_error &lt;dbl&gt; | smoothness_error &lt;dbl&gt; | compactness_error &lt;dbl&gt; | symmetry_error &lt;dbl&gt; | fractal_dimension_error &lt;dbl&gt; | target &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  0 | 17.990 | 10.38 | 122.80 | 0.11840 | 0.27760 | 0.30010 | 0.14710 | 0.2419 | 0.07871 | 1.0950 | 0.9053 |  8.589 | 0.006399 | 0.049040 | 0.03003 | 0.006193 | malignant |\n",
       "|  1 | 20.570 | 17.77 | 132.90 | 0.08474 | 0.07864 | 0.08690 | 0.07017 | 0.1812 | 0.05667 | 0.5435 | 0.7339 |  3.398 | 0.005225 | 0.013080 | 0.01389 | 0.003532 | malignant |\n",
       "|  2 | 19.690 | 21.25 | 130.00 | 0.10960 | 0.15990 | 0.19740 | 0.12790 | 0.2069 | 0.05999 | 0.7456 | 0.7869 |  4.585 | 0.006150 | 0.040060 | 0.02250 | 0.004571 | malignant |\n",
       "|  3 | 11.420 | 20.38 |  77.58 | 0.14250 | 0.28390 | 0.24140 | 0.10520 | 0.2597 | 0.09744 | 0.4956 | 1.1560 |  3.445 | 0.009110 | 0.074580 | 0.05963 | 0.009208 | malignant |\n",
       "|  4 | 20.290 | 14.34 | 135.10 | 0.10030 | 0.13280 | 0.19800 | 0.10430 | 0.1809 | 0.05883 | 0.7572 | 0.7813 |  5.438 | 0.011490 | 0.024610 | 0.01756 | 0.005115 | malignant |\n",
       "|  5 | 12.450 | 15.70 |  82.57 | 0.12780 | 0.17000 | 0.15780 | 0.08089 | 0.2087 | 0.07613 | 0.3345 | 0.8902 |  2.217 | 0.007510 | 0.033450 | 0.02165 | 0.005082 | malignant |\n",
       "|  6 | 18.250 | 19.98 | 119.60 | 0.09463 | 0.10900 | 0.11270 | 0.07400 | 0.1794 | 0.05742 | 0.4467 | 0.7732 |  3.180 | 0.004314 | 0.013820 | 0.01369 | 0.002179 | malignant |\n",
       "|  7 | 13.710 | 20.83 |  90.20 | 0.11890 | 0.16450 | 0.09366 | 0.05985 | 0.2196 | 0.07451 | 0.5835 | 1.3770 |  3.856 | 0.008805 | 0.030290 | 0.01486 | 0.005412 | malignant |\n",
       "|  8 | 13.000 | 21.82 |  87.50 | 0.12730 | 0.19320 | 0.18590 | 0.09353 | 0.2350 | 0.07389 | 0.3063 | 1.0020 |  2.406 | 0.005731 | 0.035020 | 0.02143 | 0.003749 | malignant |\n",
       "|  9 | 12.460 | 24.04 |  83.97 | 0.11860 | 0.23960 | 0.22730 | 0.08543 | 0.2030 | 0.08243 | 0.2976 | 1.5990 |  2.039 | 0.007149 | 0.072170 | 0.01789 | 0.010080 | malignant |\n",
       "| 10 | 16.020 | 23.24 | 102.70 | 0.08206 | 0.06669 | 0.03299 | 0.03323 | 0.1528 | 0.05697 | 0.3795 | 1.1870 |  2.466 | 0.004029 | 0.009269 | 0.01460 | 0.003042 | malignant |\n",
       "| 11 | 15.780 | 17.89 | 103.60 | 0.09710 | 0.12920 | 0.09954 | 0.06606 | 0.1842 | 0.06082 | 0.5058 | 0.9849 |  3.564 | 0.005771 | 0.040610 | 0.02008 | 0.004144 | malignant |\n",
       "| 12 | 19.170 | 24.80 | 132.40 | 0.09740 | 0.24580 | 0.20650 | 0.11180 | 0.2397 | 0.07800 | 0.9555 | 3.5680 | 11.070 | 0.003139 | 0.082970 | 0.04484 | 0.012840 | malignant |\n",
       "| 13 | 15.850 | 23.95 | 103.70 | 0.08401 | 0.10020 | 0.09938 | 0.05364 | 0.1847 | 0.05338 | 0.4033 | 1.0780 |  2.903 | 0.009769 | 0.031260 | 0.02981 | 0.003002 | malignant |\n",
       "| 14 | 13.730 | 22.61 |  93.60 | 0.11310 | 0.22930 | 0.21280 | 0.08025 | 0.2069 | 0.07682 | 0.2121 | 1.1690 |  2.061 | 0.006429 | 0.059360 | 0.01961 | 0.008093 | malignant |\n",
       "| 15 | 14.540 | 27.54 |  96.73 | 0.11390 | 0.15950 | 0.16390 | 0.07364 | 0.2303 | 0.07077 | 0.3700 | 1.0330 |  2.879 | 0.005607 | 0.042400 | 0.01857 | 0.005466 | malignant |\n",
       "| 16 | 14.680 | 20.13 |  94.74 | 0.09867 | 0.07200 | 0.07395 | 0.05259 | 0.1586 | 0.05922 | 0.4727 | 1.2400 |  3.195 | 0.005718 | 0.011620 | 0.01410 | 0.002085 | malignant |\n",
       "| 17 | 16.130 | 20.68 | 108.10 | 0.11700 | 0.20220 | 0.17220 | 0.10280 | 0.2164 | 0.07356 | 0.5692 | 1.0730 |  3.854 | 0.007026 | 0.025010 | 0.01689 | 0.004142 | malignant |\n",
       "| 18 | 19.810 | 22.15 | 130.00 | 0.09831 | 0.10270 | 0.14790 | 0.09498 | 0.1582 | 0.05395 | 0.7582 | 1.0170 |  5.865 | 0.006494 | 0.018930 | 0.01356 | 0.001997 | malignant |\n",
       "| 19 | 13.540 | 14.36 |  87.46 | 0.09779 | 0.08129 | 0.06664 | 0.04781 | 0.1885 | 0.05766 | 0.2699 | 0.7886 |  2.058 | 0.008462 | 0.014600 | 0.01980 | 0.002300 | benign    |\n",
       "| 20 | 13.080 | 15.71 |  85.63 | 0.10750 | 0.12700 | 0.04568 | 0.03110 | 0.1967 | 0.06811 | 0.1852 | 0.7477 |  1.383 | 0.004097 | 0.018980 | 0.01678 | 0.002425 | benign    |\n",
       "| 21 |  9.504 | 12.44 |  60.34 | 0.10240 | 0.06492 | 0.02956 | 0.02076 | 0.1815 | 0.06905 | 0.2773 | 0.9768 |  1.909 | 0.009606 | 0.014320 | 0.02027 | 0.002968 | benign    |\n",
       "| 22 | 15.340 | 14.26 | 102.50 | 0.10730 | 0.21350 | 0.20770 | 0.09756 | 0.2521 | 0.07032 | 0.4388 | 0.7096 |  3.384 | 0.006789 | 0.053280 | 0.03672 | 0.004394 | malignant |\n",
       "| 23 | 21.160 | 23.04 | 137.20 | 0.09428 | 0.10220 | 0.10970 | 0.08632 | 0.1769 | 0.05278 | 0.6917 | 1.1270 |  4.303 | 0.004728 | 0.012590 | 0.01083 | 0.001987 | malignant |\n",
       "| 24 | 16.650 | 21.38 | 110.00 | 0.11210 | 0.14570 | 0.15250 | 0.09170 | 0.1995 | 0.06330 | 0.8068 | 0.9017 |  5.455 | 0.006048 | 0.018820 | 0.01468 | 0.002801 | malignant |\n",
       "| 25 | 17.140 | 16.40 | 116.00 | 0.11860 | 0.22760 | 0.22290 | 0.14010 | 0.3040 | 0.07413 | 1.0460 | 0.9760 |  7.276 | 0.008029 | 0.037990 | 0.02308 | 0.007444 | malignant |\n",
       "| 26 | 14.580 | 21.53 |  97.41 | 0.10540 | 0.18680 | 0.14250 | 0.08783 | 0.2252 | 0.06924 | 0.2545 | 0.9832 |  2.110 | 0.004452 | 0.030550 | 0.01454 | 0.003711 | malignant |\n",
       "| 27 | 18.610 | 20.25 | 122.10 | 0.09440 | 0.10660 | 0.14900 | 0.07731 | 0.1697 | 0.05699 | 0.8529 | 1.8490 |  5.632 | 0.010750 | 0.027220 | 0.02293 | 0.004217 | malignant |\n",
       "| 28 | 15.300 | 25.27 | 102.40 | 0.10820 | 0.16970 | 0.16830 | 0.08751 | 0.1926 | 0.06540 | 0.4390 | 1.0120 |  3.498 | 0.005233 | 0.030570 | 0.01768 | 0.002967 | malignant |\n",
       "| 29 | 17.570 | 15.05 | 115.00 | 0.09847 | 0.11570 | 0.09875 | 0.07953 | 0.1739 | 0.06149 | 0.6003 | 0.8225 |  4.655 | 0.005627 | 0.030330 | 0.01925 | 0.003742 | malignant |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 539 |  7.691 | 25.44 |  48.34 | 0.08668 | 0.11990 | 0.092520 | 0.013640 | 0.2037 | 0.07751 | 0.2196 | 1.479 | 1.4450 | 0.015470 | 0.064570 | 0.02105 | 0.007551 | benign    |\n",
       "| 540 | 11.540 | 14.44 |  74.65 | 0.09984 | 0.11200 | 0.067370 | 0.025940 | 0.1818 | 0.06782 | 0.2784 | 1.768 | 1.6280 | 0.012150 | 0.041120 | 0.01840 | 0.005512 | benign    |\n",
       "| 541 | 14.470 | 24.99 |  95.81 | 0.08837 | 0.12300 | 0.100900 | 0.038900 | 0.1872 | 0.06341 | 0.2542 | 1.079 | 2.6150 | 0.007138 | 0.046530 | 0.02068 | 0.006111 | benign    |\n",
       "| 542 | 14.740 | 25.42 |  94.70 | 0.08275 | 0.07214 | 0.041050 | 0.030270 | 0.1840 | 0.05680 | 0.3031 | 1.385 | 2.1770 | 0.004775 | 0.011720 | 0.01870 | 0.002626 | benign    |\n",
       "| 543 | 13.210 | 28.06 |  84.88 | 0.08671 | 0.06877 | 0.029870 | 0.032750 | 0.1628 | 0.05781 | 0.2351 | 1.597 | 1.5390 | 0.004973 | 0.013720 | 0.01724 | 0.001343 | benign    |\n",
       "| 544 | 13.870 | 20.70 |  89.77 | 0.09578 | 0.10180 | 0.036880 | 0.023690 | 0.1620 | 0.06688 | 0.2720 | 1.047 | 2.0760 | 0.006298 | 0.021720 | 0.01490 | 0.003599 | benign    |\n",
       "| 545 | 13.620 | 23.23 |  87.19 | 0.09246 | 0.06747 | 0.029740 | 0.024430 | 0.1664 | 0.05801 | 0.3460 | 1.336 | 2.0660 | 0.005868 | 0.020990 | 0.02087 | 0.002583 | benign    |\n",
       "| 546 | 10.320 | 16.35 |  65.31 | 0.09434 | 0.04994 | 0.010120 | 0.005495 | 0.1885 | 0.06201 | 0.2104 | 0.967 | 1.3560 | 0.007086 | 0.007247 | 0.01560 | 0.002606 | benign    |\n",
       "| 547 | 10.260 | 16.58 |  65.85 | 0.08877 | 0.08066 | 0.043580 | 0.024380 | 0.1669 | 0.06714 | 0.1144 | 1.023 | 0.9887 | 0.010270 | 0.030840 | 0.02277 | 0.005890 | benign    |\n",
       "| 548 |  9.683 | 19.34 |  61.05 | 0.08491 | 0.05030 | 0.023370 | 0.009615 | 0.1580 | 0.06235 | 0.2957 | 1.363 | 2.0540 | 0.007440 | 0.011230 | 0.02203 | 0.004154 | benign    |\n",
       "| 549 | 10.820 | 24.21 |  68.89 | 0.08192 | 0.06602 | 0.015480 | 0.008160 | 0.1976 | 0.06328 | 0.5196 | 1.918 | 3.5640 | 0.008263 | 0.018700 | 0.02466 | 0.002977 | benign    |\n",
       "| 550 | 10.860 | 21.48 |  68.51 | 0.07431 | 0.04227 | 0.000000 | 0.000000 | 0.1661 | 0.05948 | 0.3163 | 1.304 | 2.1150 | 0.009579 | 0.011040 | 0.03004 | 0.002228 | benign    |\n",
       "| 551 | 11.130 | 22.44 |  71.49 | 0.09566 | 0.08194 | 0.048240 | 0.022570 | 0.2030 | 0.06552 | 0.2800 | 1.467 | 1.9940 | 0.003495 | 0.030510 | 0.02912 | 0.004723 | benign    |\n",
       "| 552 | 12.770 | 29.43 |  81.35 | 0.08276 | 0.04234 | 0.019970 | 0.014990 | 0.1539 | 0.05637 | 0.2409 | 1.367 | 1.4770 | 0.008835 | 0.012330 | 0.01897 | 0.001726 | benign    |\n",
       "| 553 |  9.333 | 21.94 |  59.01 | 0.09240 | 0.05605 | 0.039960 | 0.012820 | 0.1692 | 0.06576 | 0.3013 | 1.879 | 2.1210 | 0.010940 | 0.018340 | 0.03759 | 0.004623 | benign    |\n",
       "| 554 | 12.880 | 28.92 |  82.50 | 0.08123 | 0.05824 | 0.061950 | 0.023430 | 0.1566 | 0.05708 | 0.2116 | 1.360 | 1.5020 | 0.008412 | 0.021530 | 0.01695 | 0.002801 | benign    |\n",
       "| 555 | 10.290 | 27.61 |  65.67 | 0.09030 | 0.07658 | 0.059990 | 0.027380 | 0.1593 | 0.06127 | 0.2199 | 2.239 | 1.4370 | 0.012050 | 0.027360 | 0.01843 | 0.004938 | benign    |\n",
       "| 556 | 10.160 | 19.59 |  64.73 | 0.10030 | 0.07504 | 0.005025 | 0.011160 | 0.1791 | 0.06331 | 0.2441 | 2.090 | 1.6480 | 0.012910 | 0.022220 | 0.02572 | 0.002278 | benign    |\n",
       "| 557 |  9.423 | 27.88 |  59.26 | 0.08123 | 0.04971 | 0.000000 | 0.000000 | 0.1742 | 0.06059 | 0.5375 | 2.927 | 3.6180 | 0.011590 | 0.011240 | 0.03004 | 0.003324 | benign    |\n",
       "| 558 | 14.590 | 22.68 |  96.39 | 0.08473 | 0.13300 | 0.102900 | 0.037360 | 0.1454 | 0.06147 | 0.2254 | 1.108 | 2.2240 | 0.004242 | 0.046390 | 0.01638 | 0.004406 | benign    |\n",
       "| 559 | 11.510 | 23.93 |  74.52 | 0.09261 | 0.10210 | 0.111200 | 0.041050 | 0.1388 | 0.06570 | 0.2388 | 2.904 | 1.9360 | 0.008200 | 0.029820 | 0.01488 | 0.004738 | benign    |\n",
       "| 560 | 14.050 | 27.15 |  91.38 | 0.09929 | 0.11260 | 0.044620 | 0.043040 | 0.1537 | 0.06171 | 0.3645 | 1.492 | 2.8880 | 0.007256 | 0.026780 | 0.02080 | 0.005304 | benign    |\n",
       "| 561 | 11.200 | 29.37 |  70.67 | 0.07449 | 0.03558 | 0.000000 | 0.000000 | 0.1060 | 0.05502 | 0.3141 | 3.896 | 2.0410 | 0.007594 | 0.008878 | 0.01989 | 0.001773 | benign    |\n",
       "| 562 | 15.220 | 30.62 | 103.40 | 0.10480 | 0.20870 | 0.255000 | 0.094290 | 0.2128 | 0.07152 | 0.2602 | 1.205 | 2.3620 | 0.004625 | 0.048440 | 0.02137 | 0.006142 | malignant |\n",
       "| 563 | 20.920 | 25.09 | 143.00 | 0.10990 | 0.22360 | 0.317400 | 0.147400 | 0.2149 | 0.06879 | 0.9622 | 1.026 | 8.7580 | 0.006399 | 0.043100 | 0.02057 | 0.006213 | malignant |\n",
       "| 564 | 21.560 | 22.39 | 142.00 | 0.11100 | 0.11590 | 0.243900 | 0.138900 | 0.1726 | 0.05623 | 1.1760 | 1.256 | 7.6730 | 0.010300 | 0.028910 | 0.01114 | 0.004239 | malignant |\n",
       "| 565 | 20.130 | 28.25 | 131.20 | 0.09780 | 0.10340 | 0.144000 | 0.097910 | 0.1752 | 0.05533 | 0.7655 | 2.463 | 5.2030 | 0.005769 | 0.024230 | 0.01898 | 0.002498 | malignant |\n",
       "| 566 | 16.600 | 28.08 | 108.30 | 0.08455 | 0.10230 | 0.092510 | 0.053020 | 0.1590 | 0.05648 | 0.4564 | 1.075 | 3.4250 | 0.005903 | 0.037310 | 0.01318 | 0.003892 | malignant |\n",
       "| 567 | 20.600 | 29.33 | 140.10 | 0.11780 | 0.27700 | 0.351400 | 0.152000 | 0.2397 | 0.07016 | 0.7260 | 1.595 | 5.7720 | 0.006522 | 0.061580 | 0.02324 | 0.006185 | malignant |\n",
       "| 568 |  7.760 | 24.54 |  47.92 | 0.05263 | 0.04362 | 0.000000 | 0.000000 | 0.1587 | 0.05884 | 0.3857 | 1.428 | 2.5480 | 0.007189 | 0.004660 | 0.02676 | 0.002783 | benign    |\n",
       "\n"
      ],
      "text/plain": [
       "    ID  mean_radius mean_texture mean_perimeter mean_smoothness\n",
       "1    0  17.990      10.38        122.80         0.11840        \n",
       "2    1  20.570      17.77        132.90         0.08474        \n",
       "3    2  19.690      21.25        130.00         0.10960        \n",
       "4    3  11.420      20.38         77.58         0.14250        \n",
       "5    4  20.290      14.34        135.10         0.10030        \n",
       "6    5  12.450      15.70         82.57         0.12780        \n",
       "7    6  18.250      19.98        119.60         0.09463        \n",
       "8    7  13.710      20.83         90.20         0.11890        \n",
       "9    8  13.000      21.82         87.50         0.12730        \n",
       "10   9  12.460      24.04         83.97         0.11860        \n",
       "11  10  16.020      23.24        102.70         0.08206        \n",
       "12  11  15.780      17.89        103.60         0.09710        \n",
       "13  12  19.170      24.80        132.40         0.09740        \n",
       "14  13  15.850      23.95        103.70         0.08401        \n",
       "15  14  13.730      22.61         93.60         0.11310        \n",
       "16  15  14.540      27.54         96.73         0.11390        \n",
       "17  16  14.680      20.13         94.74         0.09867        \n",
       "18  17  16.130      20.68        108.10         0.11700        \n",
       "19  18  19.810      22.15        130.00         0.09831        \n",
       "20  19  13.540      14.36         87.46         0.09779        \n",
       "21  20  13.080      15.71         85.63         0.10750        \n",
       "22  21   9.504      12.44         60.34         0.10240        \n",
       "23  22  15.340      14.26        102.50         0.10730        \n",
       "24  23  21.160      23.04        137.20         0.09428        \n",
       "25  24  16.650      21.38        110.00         0.11210        \n",
       "26  25  17.140      16.40        116.00         0.11860        \n",
       "27  26  14.580      21.53         97.41         0.10540        \n",
       "28  27  18.610      20.25        122.10         0.09440        \n",
       "29  28  15.300      25.27        102.40         0.10820        \n",
       "30  29  17.570      15.05        115.00         0.09847        \n",
       "⋮   ⋮   ⋮           ⋮            ⋮              ⋮              \n",
       "540 539  7.691      25.44         48.34         0.08668        \n",
       "541 540 11.540      14.44         74.65         0.09984        \n",
       "542 541 14.470      24.99         95.81         0.08837        \n",
       "543 542 14.740      25.42         94.70         0.08275        \n",
       "544 543 13.210      28.06         84.88         0.08671        \n",
       "545 544 13.870      20.70         89.77         0.09578        \n",
       "546 545 13.620      23.23         87.19         0.09246        \n",
       "547 546 10.320      16.35         65.31         0.09434        \n",
       "548 547 10.260      16.58         65.85         0.08877        \n",
       "549 548  9.683      19.34         61.05         0.08491        \n",
       "550 549 10.820      24.21         68.89         0.08192        \n",
       "551 550 10.860      21.48         68.51         0.07431        \n",
       "552 551 11.130      22.44         71.49         0.09566        \n",
       "553 552 12.770      29.43         81.35         0.08276        \n",
       "554 553  9.333      21.94         59.01         0.09240        \n",
       "555 554 12.880      28.92         82.50         0.08123        \n",
       "556 555 10.290      27.61         65.67         0.09030        \n",
       "557 556 10.160      19.59         64.73         0.10030        \n",
       "558 557  9.423      27.88         59.26         0.08123        \n",
       "559 558 14.590      22.68         96.39         0.08473        \n",
       "560 559 11.510      23.93         74.52         0.09261        \n",
       "561 560 14.050      27.15         91.38         0.09929        \n",
       "562 561 11.200      29.37         70.67         0.07449        \n",
       "563 562 15.220      30.62        103.40         0.10480        \n",
       "564 563 20.920      25.09        143.00         0.10990        \n",
       "565 564 21.560      22.39        142.00         0.11100        \n",
       "566 565 20.130      28.25        131.20         0.09780        \n",
       "567 566 16.600      28.08        108.30         0.08455        \n",
       "568 567 20.600      29.33        140.10         0.11780        \n",
       "569 568  7.760      24.54         47.92         0.05263        \n",
       "    mean_compactness mean_concavity mean_concave_points mean_symmetry\n",
       "1   0.27760          0.30010        0.14710             0.2419       \n",
       "2   0.07864          0.08690        0.07017             0.1812       \n",
       "3   0.15990          0.19740        0.12790             0.2069       \n",
       "4   0.28390          0.24140        0.10520             0.2597       \n",
       "5   0.13280          0.19800        0.10430             0.1809       \n",
       "6   0.17000          0.15780        0.08089             0.2087       \n",
       "7   0.10900          0.11270        0.07400             0.1794       \n",
       "8   0.16450          0.09366        0.05985             0.2196       \n",
       "9   0.19320          0.18590        0.09353             0.2350       \n",
       "10  0.23960          0.22730        0.08543             0.2030       \n",
       "11  0.06669          0.03299        0.03323             0.1528       \n",
       "12  0.12920          0.09954        0.06606             0.1842       \n",
       "13  0.24580          0.20650        0.11180             0.2397       \n",
       "14  0.10020          0.09938        0.05364             0.1847       \n",
       "15  0.22930          0.21280        0.08025             0.2069       \n",
       "16  0.15950          0.16390        0.07364             0.2303       \n",
       "17  0.07200          0.07395        0.05259             0.1586       \n",
       "18  0.20220          0.17220        0.10280             0.2164       \n",
       "19  0.10270          0.14790        0.09498             0.1582       \n",
       "20  0.08129          0.06664        0.04781             0.1885       \n",
       "21  0.12700          0.04568        0.03110             0.1967       \n",
       "22  0.06492          0.02956        0.02076             0.1815       \n",
       "23  0.21350          0.20770        0.09756             0.2521       \n",
       "24  0.10220          0.10970        0.08632             0.1769       \n",
       "25  0.14570          0.15250        0.09170             0.1995       \n",
       "26  0.22760          0.22290        0.14010             0.3040       \n",
       "27  0.18680          0.14250        0.08783             0.2252       \n",
       "28  0.10660          0.14900        0.07731             0.1697       \n",
       "29  0.16970          0.16830        0.08751             0.1926       \n",
       "30  0.11570          0.09875        0.07953             0.1739       \n",
       "⋮   ⋮                ⋮              ⋮                   ⋮            \n",
       "540 0.11990          0.092520       0.013640            0.2037       \n",
       "541 0.11200          0.067370       0.025940            0.1818       \n",
       "542 0.12300          0.100900       0.038900            0.1872       \n",
       "543 0.07214          0.041050       0.030270            0.1840       \n",
       "544 0.06877          0.029870       0.032750            0.1628       \n",
       "545 0.10180          0.036880       0.023690            0.1620       \n",
       "546 0.06747          0.029740       0.024430            0.1664       \n",
       "547 0.04994          0.010120       0.005495            0.1885       \n",
       "548 0.08066          0.043580       0.024380            0.1669       \n",
       "549 0.05030          0.023370       0.009615            0.1580       \n",
       "550 0.06602          0.015480       0.008160            0.1976       \n",
       "551 0.04227          0.000000       0.000000            0.1661       \n",
       "552 0.08194          0.048240       0.022570            0.2030       \n",
       "553 0.04234          0.019970       0.014990            0.1539       \n",
       "554 0.05605          0.039960       0.012820            0.1692       \n",
       "555 0.05824          0.061950       0.023430            0.1566       \n",
       "556 0.07658          0.059990       0.027380            0.1593       \n",
       "557 0.07504          0.005025       0.011160            0.1791       \n",
       "558 0.04971          0.000000       0.000000            0.1742       \n",
       "559 0.13300          0.102900       0.037360            0.1454       \n",
       "560 0.10210          0.111200       0.041050            0.1388       \n",
       "561 0.11260          0.044620       0.043040            0.1537       \n",
       "562 0.03558          0.000000       0.000000            0.1060       \n",
       "563 0.20870          0.255000       0.094290            0.2128       \n",
       "564 0.22360          0.317400       0.147400            0.2149       \n",
       "565 0.11590          0.243900       0.138900            0.1726       \n",
       "566 0.10340          0.144000       0.097910            0.1752       \n",
       "567 0.10230          0.092510       0.053020            0.1590       \n",
       "568 0.27700          0.351400       0.152000            0.2397       \n",
       "569 0.04362          0.000000       0.000000            0.1587       \n",
       "    mean_fractal_dimension radius_error texture_error perimeter_error\n",
       "1   0.07871                1.0950       0.9053         8.589         \n",
       "2   0.05667                0.5435       0.7339         3.398         \n",
       "3   0.05999                0.7456       0.7869         4.585         \n",
       "4   0.09744                0.4956       1.1560         3.445         \n",
       "5   0.05883                0.7572       0.7813         5.438         \n",
       "6   0.07613                0.3345       0.8902         2.217         \n",
       "7   0.05742                0.4467       0.7732         3.180         \n",
       "8   0.07451                0.5835       1.3770         3.856         \n",
       "9   0.07389                0.3063       1.0020         2.406         \n",
       "10  0.08243                0.2976       1.5990         2.039         \n",
       "11  0.05697                0.3795       1.1870         2.466         \n",
       "12  0.06082                0.5058       0.9849         3.564         \n",
       "13  0.07800                0.9555       3.5680        11.070         \n",
       "14  0.05338                0.4033       1.0780         2.903         \n",
       "15  0.07682                0.2121       1.1690         2.061         \n",
       "16  0.07077                0.3700       1.0330         2.879         \n",
       "17  0.05922                0.4727       1.2400         3.195         \n",
       "18  0.07356                0.5692       1.0730         3.854         \n",
       "19  0.05395                0.7582       1.0170         5.865         \n",
       "20  0.05766                0.2699       0.7886         2.058         \n",
       "21  0.06811                0.1852       0.7477         1.383         \n",
       "22  0.06905                0.2773       0.9768         1.909         \n",
       "23  0.07032                0.4388       0.7096         3.384         \n",
       "24  0.05278                0.6917       1.1270         4.303         \n",
       "25  0.06330                0.8068       0.9017         5.455         \n",
       "26  0.07413                1.0460       0.9760         7.276         \n",
       "27  0.06924                0.2545       0.9832         2.110         \n",
       "28  0.05699                0.8529       1.8490         5.632         \n",
       "29  0.06540                0.4390       1.0120         3.498         \n",
       "30  0.06149                0.6003       0.8225         4.655         \n",
       "⋮   ⋮                      ⋮            ⋮             ⋮              \n",
       "540 0.07751                0.2196       1.479         1.4450         \n",
       "541 0.06782                0.2784       1.768         1.6280         \n",
       "542 0.06341                0.2542       1.079         2.6150         \n",
       "543 0.05680                0.3031       1.385         2.1770         \n",
       "544 0.05781                0.2351       1.597         1.5390         \n",
       "545 0.06688                0.2720       1.047         2.0760         \n",
       "546 0.05801                0.3460       1.336         2.0660         \n",
       "547 0.06201                0.2104       0.967         1.3560         \n",
       "548 0.06714                0.1144       1.023         0.9887         \n",
       "549 0.06235                0.2957       1.363         2.0540         \n",
       "550 0.06328                0.5196       1.918         3.5640         \n",
       "551 0.05948                0.3163       1.304         2.1150         \n",
       "552 0.06552                0.2800       1.467         1.9940         \n",
       "553 0.05637                0.2409       1.367         1.4770         \n",
       "554 0.06576                0.3013       1.879         2.1210         \n",
       "555 0.05708                0.2116       1.360         1.5020         \n",
       "556 0.06127                0.2199       2.239         1.4370         \n",
       "557 0.06331                0.2441       2.090         1.6480         \n",
       "558 0.06059                0.5375       2.927         3.6180         \n",
       "559 0.06147                0.2254       1.108         2.2240         \n",
       "560 0.06570                0.2388       2.904         1.9360         \n",
       "561 0.06171                0.3645       1.492         2.8880         \n",
       "562 0.05502                0.3141       3.896         2.0410         \n",
       "563 0.07152                0.2602       1.205         2.3620         \n",
       "564 0.06879                0.9622       1.026         8.7580         \n",
       "565 0.05623                1.1760       1.256         7.6730         \n",
       "566 0.05533                0.7655       2.463         5.2030         \n",
       "567 0.05648                0.4564       1.075         3.4250         \n",
       "568 0.07016                0.7260       1.595         5.7720         \n",
       "569 0.05884                0.3857       1.428         2.5480         \n",
       "    smoothness_error compactness_error symmetry_error fractal_dimension_error\n",
       "1   0.006399         0.049040          0.03003        0.006193               \n",
       "2   0.005225         0.013080          0.01389        0.003532               \n",
       "3   0.006150         0.040060          0.02250        0.004571               \n",
       "4   0.009110         0.074580          0.05963        0.009208               \n",
       "5   0.011490         0.024610          0.01756        0.005115               \n",
       "6   0.007510         0.033450          0.02165        0.005082               \n",
       "7   0.004314         0.013820          0.01369        0.002179               \n",
       "8   0.008805         0.030290          0.01486        0.005412               \n",
       "9   0.005731         0.035020          0.02143        0.003749               \n",
       "10  0.007149         0.072170          0.01789        0.010080               \n",
       "11  0.004029         0.009269          0.01460        0.003042               \n",
       "12  0.005771         0.040610          0.02008        0.004144               \n",
       "13  0.003139         0.082970          0.04484        0.012840               \n",
       "14  0.009769         0.031260          0.02981        0.003002               \n",
       "15  0.006429         0.059360          0.01961        0.008093               \n",
       "16  0.005607         0.042400          0.01857        0.005466               \n",
       "17  0.005718         0.011620          0.01410        0.002085               \n",
       "18  0.007026         0.025010          0.01689        0.004142               \n",
       "19  0.006494         0.018930          0.01356        0.001997               \n",
       "20  0.008462         0.014600          0.01980        0.002300               \n",
       "21  0.004097         0.018980          0.01678        0.002425               \n",
       "22  0.009606         0.014320          0.02027        0.002968               \n",
       "23  0.006789         0.053280          0.03672        0.004394               \n",
       "24  0.004728         0.012590          0.01083        0.001987               \n",
       "25  0.006048         0.018820          0.01468        0.002801               \n",
       "26  0.008029         0.037990          0.02308        0.007444               \n",
       "27  0.004452         0.030550          0.01454        0.003711               \n",
       "28  0.010750         0.027220          0.02293        0.004217               \n",
       "29  0.005233         0.030570          0.01768        0.002967               \n",
       "30  0.005627         0.030330          0.01925        0.003742               \n",
       "⋮   ⋮                ⋮                 ⋮              ⋮                      \n",
       "540 0.015470         0.064570          0.02105        0.007551               \n",
       "541 0.012150         0.041120          0.01840        0.005512               \n",
       "542 0.007138         0.046530          0.02068        0.006111               \n",
       "543 0.004775         0.011720          0.01870        0.002626               \n",
       "544 0.004973         0.013720          0.01724        0.001343               \n",
       "545 0.006298         0.021720          0.01490        0.003599               \n",
       "546 0.005868         0.020990          0.02087        0.002583               \n",
       "547 0.007086         0.007247          0.01560        0.002606               \n",
       "548 0.010270         0.030840          0.02277        0.005890               \n",
       "549 0.007440         0.011230          0.02203        0.004154               \n",
       "550 0.008263         0.018700          0.02466        0.002977               \n",
       "551 0.009579         0.011040          0.03004        0.002228               \n",
       "552 0.003495         0.030510          0.02912        0.004723               \n",
       "553 0.008835         0.012330          0.01897        0.001726               \n",
       "554 0.010940         0.018340          0.03759        0.004623               \n",
       "555 0.008412         0.021530          0.01695        0.002801               \n",
       "556 0.012050         0.027360          0.01843        0.004938               \n",
       "557 0.012910         0.022220          0.02572        0.002278               \n",
       "558 0.011590         0.011240          0.03004        0.003324               \n",
       "559 0.004242         0.046390          0.01638        0.004406               \n",
       "560 0.008200         0.029820          0.01488        0.004738               \n",
       "561 0.007256         0.026780          0.02080        0.005304               \n",
       "562 0.007594         0.008878          0.01989        0.001773               \n",
       "563 0.004625         0.048440          0.02137        0.006142               \n",
       "564 0.006399         0.043100          0.02057        0.006213               \n",
       "565 0.010300         0.028910          0.01114        0.004239               \n",
       "566 0.005769         0.024230          0.01898        0.002498               \n",
       "567 0.005903         0.037310          0.01318        0.003892               \n",
       "568 0.006522         0.061580          0.02324        0.006185               \n",
       "569 0.007189         0.004660          0.02676        0.002783               \n",
       "    target   \n",
       "1   malignant\n",
       "2   malignant\n",
       "3   malignant\n",
       "4   malignant\n",
       "5   malignant\n",
       "6   malignant\n",
       "7   malignant\n",
       "8   malignant\n",
       "9   malignant\n",
       "10  malignant\n",
       "11  malignant\n",
       "12  malignant\n",
       "13  malignant\n",
       "14  malignant\n",
       "15  malignant\n",
       "16  malignant\n",
       "17  malignant\n",
       "18  malignant\n",
       "19  malignant\n",
       "20  benign   \n",
       "21  benign   \n",
       "22  benign   \n",
       "23  malignant\n",
       "24  malignant\n",
       "25  malignant\n",
       "26  malignant\n",
       "27  malignant\n",
       "28  malignant\n",
       "29  malignant\n",
       "30  malignant\n",
       "⋮   ⋮        \n",
       "540 benign   \n",
       "541 benign   \n",
       "542 benign   \n",
       "543 benign   \n",
       "544 benign   \n",
       "545 benign   \n",
       "546 benign   \n",
       "547 benign   \n",
       "548 benign   \n",
       "549 benign   \n",
       "550 benign   \n",
       "551 benign   \n",
       "552 benign   \n",
       "553 benign   \n",
       "554 benign   \n",
       "555 benign   \n",
       "556 benign   \n",
       "557 benign   \n",
       "558 benign   \n",
       "559 benign   \n",
       "560 benign   \n",
       "561 benign   \n",
       "562 benign   \n",
       "563 malignant\n",
       "564 malignant\n",
       "565 malignant\n",
       "566 malignant\n",
       "567 malignant\n",
       "568 malignant\n",
       "569 benign   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "defd3801b3ece0618703af3ea5bd27ab",
     "grade": false,
     "grade_id": "cell-fed4931d39f05ba2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Replace the levels `malignant` and `benign` for `target` in the dataset `breast_cancer_train` with the numerical values `1` and `0`, respectively.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc82bacbaeb57af9c96e8bfa5d5ef699",
     "grade": false,
     "grade_id": "cell-86a9d67fa594ae9e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# breast_cancer <- \n",
    "#     breast_cancer %>% \n",
    "#     ...(... = ...(..., 1, 0))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(breast_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d536288cf07603e6e0c5a051a8f6b04",
     "grade": true,
     "grade_id": "cell-6e2885a75ccc8ce2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db3c36afb4a8517bb536810b71e40124",
     "grade": false,
     "grade_id": "cell-eaf6ea583cad0ee1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 2}\n",
    "\n",
    "Since we will work with predictive modelling, let us use the *holdout method* in `breast_cancer` to produce two datasets: one for training and another for testing. Therefore, start by randomly splitting `breast_cancer` in two sets on a 70-30% basis: `breast_cancer_train` (70% of the data) and `breast_cancer_test` (the remaining 30%). You can do the following:\n",
    "\n",
    "1. Use the function [`slice_sample()`](https://dplyr.tidyverse.org/reference/slice.html) to create `breast_cancer_train` (sampling without replacement) with 70\\% of the observations coming from `breast_cancer`.\n",
    "2. Use [`anti_join()`](https://dplyr.tidyverse.org/reference/filter-joins.html) with `breast_cancer` and `breast_cancer_train` to create `breast_cancer_test` by column `ID`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7c9bef3e6234a36db92c27241730e5d",
     "grade": false,
     "grade_id": "cell-8c999de0b7705de1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(20211130) # Do not change this\n",
    "\n",
    "# breast_cancer_train <- \n",
    "#     ... %>% \n",
    "#     ...(prop = ...)\n",
    "\n",
    "# breast_cancer_test <- \n",
    "#     ... %>% \n",
    "#     ...(..., by = \"ID\")\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(breast_cancer_train)\n",
    "nrow(breast_cancer_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e808d48568666d9860f1b31c5d867617",
     "grade": true,
     "grade_id": "cell-9990adb5e3448aca",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.1_partI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38200b4806f86a7c72daadcd413e49de",
     "grade": true,
     "grade_id": "cell-e1748249da4b53b1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.1_partII()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b52b631ede24612bc0816164d2b0ccf3",
     "grade": false,
     "grade_id": "cell-a94a43ef4039f9fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to remove the variable \"ID\"\n",
    "\n",
    "breast_cancer_train <- breast_cancer_train  %>% select(-ID)\n",
    "breast_cancer_test <- breast_cancer_test  %>% select(-ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dab68b03e5f43d04d2989d5fedb13112",
     "grade": false,
     "grade_id": "cell-8395793c47962a29",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using the `glm` function, fit a logistic regression model. The model's response will be `target` and the rest of the variables will be inputs. Call the resulting object `breast_cancer_logistic_model`.\n",
    "\n",
    "**Note**: You need to write most of this code cell. Go back to `worksheet_12` if you don't recall how to fit a logistic model.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "856e2c25a4175df72d7425e8bcb6d145",
     "grade": false,
     "grade_id": "cell-5bc9c77c17efb184",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# breast_cancer_logistic_model <- \n",
    "#     ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "summary(breast_cancer_logistic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "100e091e4e6ef44edc1be1f303a72f3b",
     "grade": true,
     "grade_id": "cell-4f91f421a400af8f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "382867326f4f0aea6ede899b0313f739",
     "grade": false,
     "grade_id": "cell-d4109b007e5a8d2f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Error in classification\n",
    "\n",
    "We know that the predicted value of the logistic regression is a predicted probability $\\hat{p}_i$\n",
    "\n",
    "> or the predicted odds or log-odds \n",
    "\n",
    "The predicted probability can be used to predict a class. For example, if the predicted probability of having cancer is 0.8, you can predict that the patient has cancer. These models are also known as *classifiers* since you use them to predict a *class*.\n",
    "\n",
    "For example: \n",
    "\n",
    "$$\n",
    "\\hat{Y}_i =\n",
    "\\begin{cases}\n",
    "1 \\; \\; \\; \\; \\mbox{if $\\hat{p}_i \\geq 0.5$},\\\\\n",
    "0 \\; \\; \\; \\; \\mbox{if $\\hat{p}_i < 0.5$.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $0.5$ is a threshold used to predict the classes.\n",
    "\n",
    "Of course, this is only a prediction and the patient may not actually have cancer. The difference between the actual and the predicted class is the *error* of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac4be507dafba58f12773615fca788f2",
     "grade": false,
     "grade_id": "cell-e60940adfc8e4698",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "Let’s start by checking our misclassification error rate in the training data. \n",
    "\n",
    "Your job is to create a function with two input arguments: `y` (the actual class of the data points) and `p.hat` (the predicted probability). \n",
    "\n",
    "- using $0.5$ as a cut-off, the function predicts the class of each observation based on the predicted probabilty `p.hat`\n",
    "\n",
    "- the predicted class is then compared to the actual class to calculate the proportion of misclassification in the sample. \n",
    "\n",
    "> note that a different cutoff can be used depending on the context of the problem\n",
    "\n",
    "Use the created function with response variable `target` from `breast_cancer_train` and the (in-sample) predicted values from the model. Store the output in an object named `error_rate_train`.\n",
    "\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a71d26aff3f9b55e8312fe7f4d61b3ea",
     "grade": false,
     "grade_id": "cell-4d6160f58cf93adb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# misclassification_rate <- function(y, p.hat){\n",
    "#     y_hat <- round(..., 0)\n",
    "#     error_rate <- ...(abs(... - ...))\n",
    "#     return(error_rate)\n",
    "# }\n",
    "\n",
    "# error_rate_train <- \n",
    "#     misclassification_rate(\n",
    "#         ..., \n",
    "#         ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "error_rate_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "045e623f2258fe476d9b5aba2714e5e1",
     "grade": true,
     "grade_id": "cell-e46b12ee4d9228f0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5300368712d3d906679b9cb822774de6",
     "grade": false,
     "grade_id": "cell-ea385eb9ec9dcf9f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "The training error rate you calculated in the previous exercise will probably underestimate the out-of-sample error (i.e., the error of data never seen by your model). The parameters were estimated based on that same data!! \n",
    "\n",
    "We can estimate the *out-of-sample* error rate by using cross-validation. Use the function `cv.glm`, from the package `boot`, to conduct a 10-fold cross-validation. The arguments of this function are:\n",
    "\n",
    "- `glmfit`: the trained model that will be used to predict\n",
    "\n",
    "- `data`: the (test) data you want to predict (not to train the model)\n",
    "\n",
    "- `K`: number of folds for cross-validation\n",
    "\n",
    "- `cost`: function to measure error. For this question, use `misclassification_rate`. \n",
    "\n",
    "**Note**: note that in this question the test and the training set used are the same since you are computing the confusion matrix for predictions of the training set.\n",
    "\n",
    "Store the output of the `cv.glm` in an object called `cv_logistic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9dc4c2913875fc5c6bfd94b27a7e7ec",
     "grade": false,
     "grade_id": "cell-f4a194e828eea4df",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(20211130) # do not change this\n",
    "\n",
    "# cv_logistic <- \n",
    "#     cv.glm(\n",
    "#         glmfit = ..., \n",
    "#         data = ..., \n",
    "#         K = ..., \n",
    "#         cost = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "cv_logistic$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e4f0e6db4cd0fbb1a1c121b28b59ae6",
     "grade": true,
     "grade_id": "cell-c5371c7c365a75df",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "242fc8224a98fe0c680211aa6a25db21",
     "grade": false,
     "grade_id": "cell-6eff54123ce5757f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The training error is less than the 10-fold cross validation error.\n",
    "\n",
    "_Assign your answer to an object called `answer1.5`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f6e2dbdd24ff99974ae83712a0b5ab7",
     "grade": false,
     "grade_id": "cell-ffd3a4810d740603",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.5 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9e89a65eaa9e92a892d349df976537b",
     "grade": true,
     "grade_id": "cell-e1815efdf47ce9cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00ae9ff8d71da578af1ef6a446a36b26",
     "grade": false,
     "grade_id": "cell-353018c79aafc398",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The training error will **always** be lower than the cross-validation error. \n",
    "\n",
    "_Assign your answer to an object called `answer1.6`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70682530a0b4ce4f28c638fcbaa39e4e",
     "grade": false,
     "grade_id": "cell-a78dae1a647d3f20",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.6 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98a640fcd64807ab8338028fbf261106",
     "grade": true,
     "grade_id": "cell-7096aa86b0682792",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baeab973e25383acf2cc9cc1a901598c",
     "grade": false,
     "grade_id": "cell-091e7009ad626655",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Prediction Performance\n",
    "\n",
    "Classifiers can be evaluated using different metrics that compare the actual *versus* the predicted classes in absolute or relative values. \n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "The confusion matrix shows you the types of errors made by the model. \n",
    "\n",
    "|  Predicted \\ Actual | Success | Failure |\n",
    "| :-------------: |:-------------:| :-----:|\n",
    "| **Success** | $\\text{TP}$ | $\\text{FP}$ |\n",
    "| **Failure** | $\\text{FN}$ | $$\\text{TN}$$ |\n",
    "\n",
    "\n",
    "This matrix has the following case counts:\n",
    "\n",
    "- **True positive ($\\text{TP}$):** the number of observations **correctly predicted as `1`** (*Malignant*) using the threshold. \n",
    "\n",
    "\n",
    "- **False positive ($\\text{FP}$):** the number observations **incorrectly predicted as `1`** (*Malignant*) when they are in fact 0.\n",
    "\n",
    "\n",
    "- **True negative ($\\text{TN}$):** the number of observations in **correctly predicted as `0`** (*Benign*).\n",
    "\n",
    "\n",
    "- **False negative ($\\text{FN}$):** the number of observations in  **incorrectly predicted as `0`** (*Benign*) when in fact they are 1. \n",
    "\n",
    "> The confusion matrix is usually calculated based on *test* data since that is the primary goal of prediction. \n",
    "\n",
    "Luckily for us, the `confusionMatrix()` function from the package `caret` gives us the confusion matrix and other quantities to evaluate classifier. \n",
    "\n",
    "#### Sensitivity and Specificity\n",
    "\n",
    "While the previous measures are all absolute error counts, we can also define relative measures:\n",
    "\n",
    "\n",
    "- **Sensitivity ($\\text{SN}$):** the number of **correct** success predictions divided by the total number of real successes ($\\text{S}$), in other words, it is the estimated probability of predicting 1 given that the true class is 1.\n",
    "$$\\text{SN} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} = \\frac{\\text{TP}}{\\text{S}}$$\n",
    "    - *Example: the probability that a blood test is positive for a sick  patient.*\n",
    "\n",
    "\n",
    "- **Specificity ($\\text{SP}$):** the number of **correct** failure predictions divided by the total number of real failures ($\\text{F}$). In other words, it is the estimated probability of predicting 0 given that the true class is 0.\n",
    "$$\\text{SP} = \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} = \\frac{\\text{TN}}{\\text{F}}$$\n",
    "    - *Example: the probability that a blood test is negative for a healthy  patient.*\n",
    "    \n",
    "#### Other common measures\n",
    "\n",
    "- **Precision ($\\text{PR}$):** the number of **correct** success predictions divided by the total number of predicted successes.\n",
    "$$\\text{PR} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n",
    "    - *Example: the probability that a patient is sick if the blood test is positive.*\n",
    "\n",
    "\n",
    "- **Accuracy ($\\text{ACC}$):** the number of **correct** predictions (both success and failure) divided by the total number of observations ($n$).\n",
    "$$\\text{ACC} = \\frac{\\text{TP} + \\text{TN}}{n}$$\n",
    "    - *Example: the probability that the blood test correctly classifies the patient.*\n",
    "\n",
    "\n",
    "- **Cohen's Kappa ($\\kappa$):** It is another accuracy metric adjusted by how often the predictions and actual classification coincide just by chance. We compute it as:\n",
    "\n",
    "$$\\kappa = \\frac{\\text{ACC} - \\text{AGG}}{1 - \\text{AGG}}.$$\n",
    "\n",
    "For $\\kappa$, the random agreement is defined as\n",
    "\n",
    "$$\\text{AGG} = \\frac{\\text{TP} + \\text{FP}}{n} \\times \\frac{\\text{TP} + \\text{FN}}{n} + \\frac{\\text{FN} + \\text{TN}}{n} \\times \\frac{\\text{FP} + \\text{TN}}{n}.$$\n",
    "\n",
    "> **Heads-up:** All the metrics above (except $\\kappa$) have a range between $0$ and $1$, where values close to $1$ indicate good predictive performance. \n",
    "\n",
    "> In the case of $\\kappa$, it ranges between $-1$ and $1$ where values close to $1$ indicate good predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a054aaf8acaf25681369e9fbfd8d80a2",
     "grade": false,
     "grade_id": "cell-fca83dfe4c59358d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.7**\n",
    "<br>{points: 1}\n",
    "\n",
    "To compute the confusion matrix for the classifier built from the estimated logistic regression `breast_cancer_logistic_model`, we need to obtain predicted classes. \n",
    "\n",
    "Use the `predict` function to obtain the predicted classes for the training set `breast_cancer_train` and store them in a variable called `breast_cancer_pred_class`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d03c10ad3dc19d05d55dd40a64772c8",
     "grade": false,
     "grade_id": "cell-7768de07001d0afa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# breast_cancer_pred_class <- \n",
    "#   ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(breast_cancer_pred_class, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c59ecf0ce4aef3347ceb311679faf61",
     "grade": true,
     "grade_id": "cell-539c1d4e1a835857",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a9ec6ccafeb27f9605b894234cb3f327",
     "grade": false,
     "grade_id": "cell-a5f9a1545e253124",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.8**\n",
    "<br>{points: 1}\n",
    "\n",
    "The arguments of the `confusionMatrix()` function are:\n",
    "\n",
    "- `data`: factor with the predicted classes (use `as.factor()`).\n",
    "- `reference`: factor with the real classes (use `as.factor()`).\n",
    "- `positive`: the level considered positive (as a character). \n",
    "\n",
    "Store the output of `confusionMatrix` in an object called `breast_cancer_confusion_matrix`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b12119f721997dca332974178f048c7",
     "grade": false,
     "grade_id": "cell-1f7718031c8b6b7a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# breast_cancer_confusion_matrix <- \n",
    "#     ...(\n",
    "#     data = as.factor(...),\n",
    "#     reference = as.factor(...),\n",
    "#     positive = ...\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "breast_cancer_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec298f0ecd49a297939ced7167235fe0",
     "grade": true,
     "grade_id": "cell-1496d3f3bc0c04c0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7853041d751a5ffce0d7c57dfdead5cf",
     "grade": false,
     "grade_id": "cell-c87768c9e94a0d70",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Threshold\n",
    "\n",
    "Note that the *sensitivity* (or *specificity*) of our model depends on the threshold used to predict the classes. \n",
    "\n",
    "So far, we have predicted $\\hat{y}_i = 1$ if the predicted probability, $\\hat{p}_i$, was higher than 50%. But we can also use other values, like 30%, 10%, or 90%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c23706d06aa4962634e68c35a87207e",
     "grade": false,
     "grade_id": "cell-a570194a8c7fd1ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.9**\n",
    "<br>{points: 1}\n",
    "\n",
    "What do you expect to happen if you decrease the threshold from 0.5 to 0.4.\n",
    "\n",
    "A. Both the specificity and sensitivity would stay the same.\n",
    "\n",
    "B. Both the specificity and sensitivity would increase.\n",
    "\n",
    "C. Both the specificity and sensitivity would decrease.\n",
    "\n",
    "D. The specificity would increase and sensitivity would decrease.\n",
    "\n",
    "E. The specificity would decrease and sensitivity would increase.\n",
    "\n",
    "F. There's no way to tell. \n",
    "\n",
    "_Assign your answer to an object called `answer1.9`. Your answer should be a single character surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ba7f7dc010d837e1bd6b45f8a096f8b",
     "grade": false,
     "grade_id": "cell-64b6aa4cd25e1098",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.9 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7677df4561646f5a6480d0e29bc5b86a",
     "grade": true,
     "grade_id": "cell-6314e62308714c43",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7fb81cceb99a70ac7f4a322ce7f2ea02",
     "grade": false,
     "grade_id": "cell-1ff747717d880769",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.10**\n",
    "<br>{points: 1}\n",
    "\n",
    "Let's change our confusion matrix from the previous question by adjusting the threshold to $p_0 = 0.3$. \n",
    "\n",
    "\n",
    "1. Update your predictions using the new threshold and store it in an object named `breast_cancer_pred_class_threshold_0.3`.\n",
    "\n",
    "\n",
    "2. Use the `confusionMatrix` function to obtain the confusion matrix and associated quantities. Save the output in an object named `confusion_matrix_threshold_0.3`.\n",
    "\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79f735743e045187c00d90e804845c2e",
     "grade": false,
     "grade_id": "cell-95fcb9bdb826b4af",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# p_0 <- ...\n",
    "\n",
    "# breast_cancer_pred_class_threshold_0.3 <- \n",
    "#   as.interger(...(..., type = ...) > ...)\n",
    "\n",
    "# confusion_matrix_threshold_0.3 <- \n",
    "#     ...(\n",
    "#     ...,\n",
    "#     ...,\n",
    "#     ...)\n",
    "\n",
    "#confusion_matrix_threshold_0.3\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "confusion_matrix_threshold_0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72ef2d02b83cbd1cee910945b00b4369",
     "grade": true,
     "grade_id": "cell-8e3d1d7c2330d231",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.10()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "617f47c2d817340fd49485268182a1ca",
     "grade": false,
     "grade_id": "cell-0e7c36595100dcbd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Was this what you expected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "947435c0579c2966eb6e800e412c2cfd",
     "grade": false,
     "grade_id": "cell-66dceddef862ac64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### AUC and ROC \n",
    "\n",
    "A limitation of the approach taken in the previous question is that the evaluation of the classifier depends critically on the threshold $p_0$, but the most appropriate choice of $p_0$ may not be clear. \n",
    "\n",
    "Alternatively, we can evaluate the predictive performance of a given classifier for all possible value of $p_0 \\in [0, 1]$. The resulting curve is known as the *receiver operating characteristic* (ROC) curve. \n",
    "\n",
    "The *area under the curve* (AUC) measures the classification ability of the classifier. The AUC goes from $0$ to $1$. \n",
    "\n",
    "> the higher the AUC, the better predictive performance!!\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Roc_curve.svg/440px-Roc_curve.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6090317bcb983b153f316fd255e94e2b",
     "grade": false,
     "grade_id": "cell-8a0b3b07c1e2b569",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.11**\n",
    "<br>{points: 1}\n",
    "\n",
    "The package `pROC`, via its function `roc()`, plots ROC curves. You need to specify the real observed classes in the argument `response` and the predictions in `predictor`. \n",
    "\n",
    "Using `breast_cancer_train` create the ROC curve for `breast_cancer_logistic_model` and call it `ROC_full_log`. Then, use `plot()` to display it.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d43630a578c8fc49760f80951e8e29e",
     "grade": false,
     "grade_id": "cell-bd64b06b49b63a19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 8) # Adjust these numbers so the plot looks good in your desktop.\n",
    "\n",
    "# ROC_full_log <- roc(\n",
    "#   response = ...,\n",
    "#   predictor = ...\n",
    "# )\n",
    "# plot(...,\n",
    "#   print.auc = TRUE, col = \"blue\", lwd = 3, lty = 2,\n",
    "#   main = \"ROC Curves for Breast Cancer Dataset\"\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8516440801e74c7dee6de2c68206d603",
     "grade": true,
     "grade_id": "cell-dc1845ad5804f178",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.11()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c931fa3783ef2544eddc6d1d992c2b5a",
     "grade": false,
     "grade_id": "cell-ce7b18eb07e85907",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One last comment for this worksheet is that here we have used the training data to obtain the confusion matrix. As we know, the training data will most probably be underestimating our error. A much better approach would be to use a cross-validation or the test set to make a similar analysis. \n",
    "\n",
    "We abstained from this step to focus on the concepts but, in the tutorial, we will use cross-validation to evaluate the prediction accuracy of different classifiers."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
