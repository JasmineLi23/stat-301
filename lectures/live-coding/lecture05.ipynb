{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a5da2f-17e3-473a-80ff-b428c66b8ad6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Comparing Models**\n",
    "**Lecture 05**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecaaae-5eb6-4530-a613-5d56282c853f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [1c]\n",
    "# Run this cell before continuing.\n",
    "library(repr)\n",
    "library(infer)\n",
    "library(cowplot)\n",
    "library(broom)\n",
    "library(GGally)\n",
    "library(AER)\n",
    "library(modelr)\n",
    "library(tidyverse)\n",
    "library(palmerpenguins)\n",
    "library(titanic)\n",
    "library(faraway)\n",
    "\n",
    "penguins_clean <-\n",
    "    penguins %>%\n",
    "    drop_na()\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2601c74b-a205-4c88-b51b-79908d57d7fe",
   "metadata": {},
   "source": [
    "## 0. Let's get our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce5028-e26d-4841-b3b2-f113422aed84",
   "metadata": {},
   "source": [
    "Let's start with our usual dataset, the penguins dataset. Next week we'll explore a different dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded57da-7665-41f9-801b-15a904722829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58c561-cc1d-43fa-99fd-c620efa5060b",
   "metadata": {},
   "source": [
    "Let's plot the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c81f5-abb7-4ae5-ae0c-379cf2e82d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [3c]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82159d5b-46d8-4fe3-ba97-9d7e9f6544ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **1. Evaluation metrics**\n",
    "\n",
    "Many metrics used to evaluate LR measure how far $y$ is from $\\hat{y}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c59ce3-26a6-4af5-bad2-8f91c251aa79",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **1.1 Basic Quantities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ac893-58b7-4223-953c-e9908567386d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1.1 Residuals Sum of Squares:\n",
    "$$\\text{RSS} = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n r_i^2$$ where $r_i$ are the residuals. This is the quantity we minimize in the Least Square method. \n",
    "\n",
    "> sum of the squared residuals, small is good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1e50d-e6d1-4b7e-aa40-b28e17b7ba4a",
   "metadata": {},
   "source": [
    "We typically do not use RSS for comparing models, as it will become clearer soon. However, other commonly used measures are derived from RSS (e.g., MSE). Hence, understanding RSS is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbc547-609b-42e1-86a0-f27ad4f1bd75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [4]\n",
    "# Each dashed red line is one of the residuals. \n",
    "# Take the square of it, and sum all of them\n",
    "penguins_pred_slr %>%\n",
    "    ggplot(aes(flipper_length_mm, body_mass_g)) +\n",
    "    geom_point() + \n",
    "    geom_line(aes(y = pred), color = 'blue') + \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ead3405-69ad-4156-94ad-f33f128b050d",
   "metadata": {},
   "source": [
    "Let's do this by hand just so you understand what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc780f6-a262-4640-bffd-b9121844f22b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f216ea-9c08-4d60-be5b-de32a7aef9dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42268c5-a92b-459b-984b-cde1b279d415",
   "metadata": {},
   "source": [
    "#### 1.1.2 Residuals Standard Error\n",
    "\n",
    "$$\\text{RSE} = \\sqrt{\\frac{1}{n-p-1} \\text{RSS}}$$ where the quantity $p$ is the number of covariate and $n - p - 1$ is the so-called `Degrees of Freedom` \n",
    "\n",
    "> gives an idea of the size of the *irreducible* error, very similar to the RSS, small is good\n",
    "\n",
    "> estimates the standard deviation of the error term $\\varepsilon$ (the RSS is divided by the appropriate degrees of freedom to give a \"good\" estimate of $\\sigma = \\sqrt{Var(\\varepsilon)}$)\n",
    "\n",
    "> a measure based on *training* data to evaluate the fit of the model (for inference) and needed to estimate the standard errors of $\\hat{\\beta}_j$ in classical theory!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7cefab-449e-4c52-a3d8-2bb8dcbbb026",
   "metadata": {},
   "source": [
    "Again, let's do it by hand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf16ac0-ed6f-40c6-a558-74f20f470b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [7]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f0e11d-16b7-43d8-8978-b854f2f3294b",
   "metadata": {},
   "source": [
    "But R gives you this already: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce238058-2453-4772-9065-e94ae0c40b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903d5ed-8b96-4a9d-a0f2-78cb08ef6f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3914d69-4fbf-44ee-ad08-64e25abca493",
   "metadata": {},
   "source": [
    "#### 1.1.3 Mean Squared Error \n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\frac{\\text{RSS}}{n}$$\n",
    "You know this one from DSCI 100, right? Usually computed on both the *training* (MSE) and the *test* sets (MSPE)\n",
    "\n",
    "> mean of the squared residuals, small is good. \n",
    "\n",
    "> *Testing MSE (i.e., DSCI 100's MSPE)*: can be computed on new data $y_{\\text{new}}$ and their predicted values (formula above) to evaluate *out-of-sample* prediction performance "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b8746d-558c-4313-bfba-761b145b20a0",
   "metadata": {},
   "source": [
    "All the three measures listed above, `RSS`, `RSE`, and `MSE`, are *absolute* measures. It is not easy to judge if these are small enough. \n",
    "\n",
    "Let's explore some relative measures:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee73b2-2484-4e46-bc88-14efe3dedf46",
   "metadata": {},
   "source": [
    "# Part 2 - Goodness of Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deabc59-0822-4ccb-9317-e1b22cb65402",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We know that the best predictor of the response $Y$, in terms of mean squared error, is $E[Y]$, which we can estimate with the sample mean of $Y$. Remember, the mean of $Y$ is the same as the `null model` (i.e., a model with no covariate, only intercept). \n",
    "\n",
    "- **Question: So how does a LR help us?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764426ce-2f3b-4847-bde4-bcc726fe9dc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **2. Coefficient of Determination**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d58edc-14bc-4df5-9bc2-828824a45b82",
   "metadata": {},
   "source": [
    "### **2.1 Variance decomposition**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6a077-6c18-468d-a2a3-dbffb50e5de0",
   "metadata": {},
   "source": [
    "**Explained Sum of Squares**: $ESS=\\sum_{i=1}^n(\\hat{y}_i-\\bar{y})^2$\n",
    "\n",
    "- $\\hat{y}_i$ predicts $y_i$ using the LR, while $\\bar{y}$ predicts $y_i$ without a model. If our model is better than nothing, this should be large!!\n",
    "\n",
    "- measures how much variation in the data is *explained* by the additional information given by the LR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47e1e24-288a-4b18-b118-d6cffae325a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Total Sum of Squares**: $TSS=\\sum_{i=1}^n(y_i-\\bar{y})^2$\n",
    "\n",
    "- this is the sum of the squares of the residuals from the null (intercept-only, no explanatory variables) model\n",
    "\n",
    "- when properly scaled, it is the sample variance of $Y$ which *estimates* the population variance of $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c455b63e-c43d-486c-a477-e46fc858dc20",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "As it turns out, <font color=\"darkred\"> if parameters are estimated using LS and the LR has an intercept</font>, then, \n",
    "\n",
    "$$\\text{TSS} = \\text{ESS} + \\text{RSS}$$\n",
    "\n",
    "or, replacing the formulae\n",
    "\n",
    "$$\\sum_{i=1}^n(y_i-\\bar{y})^2 = \\sum_{i=1}^n(\\hat{y}_i-\\bar{y})^2 + \\sum_{i=1}^n(y_i - \\hat{y}_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edaca9b-b8de-4b5e-8bd9-ae4c6e138c3d",
   "metadata": {},
   "source": [
    "### **2.2 Coefficient of Determination: $R^2$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6deff9-72e1-4b87-b072-bbbb2711dbd2",
   "metadata": {},
   "source": [
    "If our model provides a good fit, we expect the TSS (residuals from the null model, in red) to be much larger than the RSS (residuals from the fitted model, which we minimized by LS, in blue)!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c414f59c-0496-450a-b01e-323adff21dfe",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/800px-Coefficient_of_Determination.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc712a3-fd7e-4310-92ba-028ec4aad9c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Using the decomposition above and dividing by TSS: \n",
    "\n",
    "$$1=\\frac{\\text{ESS}}{\\text{TSS}} + \\frac{\\text{RSS}}{\\text{TSS}}$$\n",
    "\n",
    "\n",
    "**The Coefficient of determination**, $R^2$, was first defined as:\n",
    "\n",
    "$$R^2=1 - \\frac{\\text{RSS}}{\\text{TSS}}$$\n",
    "\n",
    "*For a LR with an intercept and estimated by LS* it is equivalent to \n",
    "\n",
    "$$R^2=\\frac{\\text{ESS}}{\\text{TSS}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab59e9-728f-47c2-ac87-563022fcace7",
   "metadata": {},
   "source": [
    "This seems complicated, but we can code this entire thing in a few lines of code. Let's try! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5e09b-1142-45a2-9379-d65bda1f5b39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a103e-0560-4c9d-b22a-0df73d0bb0f8",
   "metadata": {},
   "source": [
    "<font color=\"blue\">**Don't worry; R computes this statistic for you**</font>. I won't ask you to do this calculation by hand. This is for illustration and learning purposes only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ebfa5-1b39-498f-a4d0-34c9b185efea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ead02e9-fb67-4b1a-bdb9-a68304ed902e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113f89ee-9a8e-4eeb-8d96-514b8916169c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### **2.2.1 About $R^2$**\n",
    "\n",
    "For a LR with an intercept and estimated by LS, the coefficient of determination:\n",
    "\n",
    "- the $R^2$ can be used to compare the size of the residuals of the fitted model with those of the null \n",
    "\n",
    "- is also interpreted as the proportion of variance of the response (TSS) explained by the model (ESS)\n",
    "\n",
    "- is between 0 and 1 since we expect TSS to be much larger than RSS (thus their ratio is smaller than 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe05fdd-5385-4a9a-91da-f03654deac55",
   "metadata": {},
   "source": [
    "Therefore, for our model \n",
    "\n",
    "$$\n",
    "\\text{body_mass}_i = \\beta_0 + \\beta_1\\times \\text{flipper_length}_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "the `flipper_length_mm` explains $76.21\\%$ of the total variation of `body_mass_g`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce04c7c8-cb3b-40b2-b1c1-53d5fe3a62a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### **2.2.2 Scope and limitations**\n",
    "\n",
    "- The $R^2$ is computed based on *in-sample* observations and it does not provide a sense of how good is our model in predicting *out-of-sample* cases (aka test set)!!\n",
    "\n",
    "- Note that $R^2$ computed as $R^2 = 1 - \\frac{\\text{RSS}}{\\text{TSS}}$ ranges between 0 and 1 *if* the LR model has an intercept and is estimated by LS!! \n",
    "    - Well, in general we always want a model with intercept anyway; \n",
    "    \n",
    "- The $R^2$ increases as new variables are added to the model, regardless of their relevance! Thus, <font color='darkred'>**it can't be used to compare nested models**</font>.\n",
    "\n",
    "- The $R^2$  can't be used to *test* any hypothesis to answer this question since its distribution is unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7af2d-5f63-451c-87eb-525569e50911",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### **2.3 Adjusted $R^2$**\n",
    "\n",
    "The $R^2$ increases as more input variables are added to the model since the $\\text{RSS} = \\sum_{i = 1}^n(y_i - \\hat{y}_i)^2$ decreases as more input variables are included in the model. \n",
    "\n",
    "To overcome this issue with $R^2$, we can obtain an **adjusted $R^2$** as follows:\n",
    "\n",
    "$$ \\text{adjusted } R^2 = 1- \\frac{\\text{RSS}/(n - p - 1)}{\\text{TSS}/(n - 1)},$$\n",
    "\n",
    "where \n",
    "\n",
    "- $p$ is the number of regression covariates in the model.\n",
    "- $n$ is our sample size to estimate the model.\n",
    "\n",
    "This adjusted coefficient of determination discounts $\\text{RSS}$ according to \"size\" of the model $n - p - 1$. Hence, even if the $\\text{RSS}$ decreases, we divide it by $n - p - 1$ to compensate for the model's size.\n",
    "\n",
    "It is like we are putting a price for the model to grow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b4eb9f-5dbd-436f-96fb-d3e0d44c0802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899786b4-cd9e-45fb-b02a-1aa00fd7d002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [14]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9c6c4-6401-4981-81f0-beece8d0178b",
   "metadata": {},
   "source": [
    "## **3. F-test: Comparing nested models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb90d64f-940e-45d3-b5f7-f6bff282c400",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "We have learned how to test single coefficients in our regression model using the `t-test`. However, when there are many coefficients, the probability of a false positive grows considerably. \n",
    "\n",
    "There's a way we can test multiple coefficients simultaneously.\n",
    "\n",
    "For example, imagine we have two competing models: \n",
    "\n",
    "- Model 1: \n",
    "$$\n",
    "\\text{body_mass}_i = \\beta_0 + \\beta_1\\times \\text{flipper_length}_i + \\beta_2\\times \\text{bill_depth}_i + \\beta_3\\times \\text{bill_length}_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "- Model 2: \n",
    "$$\n",
    "\\text{body_mass}_i = \\beta_0 + \\beta_1\\times \\text{flipper_length}_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "Do we have enough evidence that including $\\text{bill_depth}$ and $\\text{bill_length}$ improves the model?\n",
    "\n",
    "In other words, we want to test:\n",
    "\n",
    "$$ \n",
    "H_0: \\beta_2 = \\beta_3 = 0\\quad\\quad vs\\quad\\quad H_A: \\text{at least one of } \\beta_2 \\text{ and } \\beta_3 \\text{ is different from zero}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b156c8-5f18-492c-96f1-f11c394045cd",
   "metadata": {},
   "source": [
    "### **3.1 Nested Models**\n",
    "In general terms, we have two models: \n",
    "\n",
    "- Model 1 (reduced or smaller model): a LR with $q+1$ coefficients $$Y_i=\\beta_0 + \\beta_1 X_{i1} + \\ldots + \\beta_q X_{iq} + \\varepsilon_i$$\n",
    "\n",
    "- Model 2 (full model or larger model): LR with $p+1$ coefficients, $k$ additional explanatory variables compared with Model 1\n",
    "$$Y_i=\\underbrace{\\beta_0 + \\beta_1 X_{i1} +  \\ldots + \\beta_q X_{iq}}_{\\text{Model 1}} + \\ldots +  \\beta_p X_{ip} + \\varepsilon_i$$\n",
    "    \n",
    "Is the full model significantly different from a reduced model? \n",
    "\n",
    "To answer this question, we need to *simulataneously* test if many parameters (all the additional ones) are zero!.\n",
    "\n",
    "$$H_0: \\beta_{q+1} = \\beta_{q+2} = \\ldots = \\beta_{p} = 0\\quad\\quad vs \\quad\\quad H_1: \\text{at least one } \\beta_j \\neq 0 \\text{ (for } j = q+1, q+2, \\dots, p \\text{)}$$\n",
    "\n",
    "<font color='darkred'>It's crucial for the smaller model to be encapsulated within the larger model. This means we should be able to derive the smaller model from the larger one by setting some coefficients to zero.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e33fa5-925f-498d-bfec-396636deb421",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### **3.2 The F-statistic**\n",
    "\n",
    "\n",
    "<font size=4>$$\\frac{(RSS_{reduced}-RSS_{full})/k}{RSS_{full}/(n - p - 1)} \\sim \\mathcal{F}_{k, n-p}$$</font>\n",
    "\n",
    "- $RSS_{reduced}$ is the **RSS** of the reduced model \n",
    "\n",
    "\n",
    "- $RSS_{full}$ is the **RSS** of the full model \n",
    "\n",
    "\n",
    "- $k$ is the number of parameters tested (difference between models)\n",
    "\n",
    "\n",
    "- $p$ is the number of covariates of the full model\n",
    "\n",
    "\n",
    "<font color=\"blue\">**Don't worry, R computes this statistic for you.**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b556954-f2be-4919-b23c-2eff2e1d02ef",
   "metadata": {},
   "source": [
    "#### **3.2.1 Comparing nested models in R**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b018c-02a2-42b9-a6c2-981a8f7cdcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc967e79-2576-4415-abb6-b36cd13439c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [16]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3197e6ac-a194-4a5d-a8f0-0c24b3290387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [16-2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b2e66-15cc-46dc-97ee-60de46f50567",
   "metadata": {},
   "source": [
    "### **3.3 Comparing with the null model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6e9eb-307d-4cff-bdfe-cf472659eb8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "The fundamental comparison we want to make with any model we develop is against the *null model*. If our model cannot \"beat\" the *null model*, there's no justification for using the covariates at all. \n",
    "\n",
    "- **Question: Is our linear regression better than just using $E[Y]$ to predict?**\n",
    "    - <font color='darkred'>Statistically, we want to compare our prediction $\\hat{Y}$ (the best predictor of $E[Y|\\mathbf{X}]$) with $\\bar{Y}$ (the best predictor of $E[Y]$).</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34aa6ad3-9dac-414c-9292-f554ce68eac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [17]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a78bf-1675-4ecf-8bf4-45300f73f6b0",
   "metadata": {},
   "source": [
    "The good news is that R does this automatically for us, and provide this test in the summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97414ef-7404-45f2-987a-dd0fcafdd6d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [18] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749ec8e6-d72b-4624-aa6f-b35b10ab8f63",
   "metadata": {},
   "source": [
    "### **3.4 t-tests vs F-test**\n",
    "\n",
    "- The test with only one coefficient is just a particular case of the comparison of nested models (the full model has only one additional variable compared to the reduced model). \n",
    "    - In this particular case, it can be shown that using classical results the $F$-test (by `anova`) is equivalent to the $t$-test (by `lm`): $F=t^2$ \n",
    "\n",
    "<br>\n",
    "- Both tests ($F$ and $t$) are based on Normality assumptions or approximate Normality distribution given by large sample theory;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8effbe4-b84c-4576-a76a-5f5540641527",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 4. **Variable (Model) Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d961897-0fa2-4359-b1d1-bad3d003937e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "Some datasets contain *many* variables, but not all of them are relevant. Do we need all the available predictors in the model? You may want to identify the *most relevant* variables to build a model.\n",
    "\n",
    "But again, what is your goal? Inference or prediction?\n",
    "    \n",
    "We need to choose an evaluation metric to decide whether a variable (or set of variables) is relevant. The evaluation metric depends on the goal of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4619f-a755-4954-8b89-8f9953a041e0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **4.1 Inference**\n",
    "\n",
    "Do all the predictors help to explain the response, or is only a subset of the predictors useful?\n",
    "\n",
    "- The $F$-test\n",
    "     - you can use `anova` to compare a full model (with all terms) vs a reduced model (which excludes terms from $q+1$ to $p$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f811ff1-84df-43c1-83d3-dad1ad1dd302",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The $t$- tests:\n",
    "    - In previous lectures, we evaluated the contribution of individual variables to explain a response using $t$-tests calculated by `lm` and given in the `tidy` table (note that $H_0$ contains only *one* coefficient):\n",
    "$$H_0: \\beta_j = 0,  \\text{ versus }  H_1: \\beta_j \\neq 0$$ \n",
    "\n",
    "\n",
    "    - The results of the $t$-tests evaluate the contribution of *each* variable (separately) to explain the variation observed in the response ***with all other variables are included*** in the model, in other words, after controlling for other explanatory variables.\n",
    "\n",
    "    - We can use the results of these tests to establish a *selection rule* to evaluate variables one at a time:\n",
    "    - for example: discard variables with *p-values* above a threshold\n",
    "    - <font color='red'>**Warning**</font>: if there are many variables in the model (i.e., $p$ is large) using individual $t$-tests may result in many false discoveries (i.e., reject a true $H_0$, by chance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b9c78-c43c-42a0-a0d5-f923ace2c018",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before moving forward, it's important to be aware that the training set is used multiple times to choose variables, which makes it unsuitable for evaluating the final significance of the model. This issue is commonly known as the *\"post-inference\"* problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b8a8a3-0321-43da-9db7-7bc88a2d2a6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **4.2 The $R^2$ (or the RSS) and the adjusted $R^2$**\n",
    "\n",
    "- You can use the $R^2$ to compare models of equal size (not necessarily nested) \n",
    "\n",
    "- You can use the adjusted $R^2$ to compare models of different sizes (not necessarily nested)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31844240-757a-4553-b71e-4f0f611c6ac7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **4.3 An automated procedure**\n",
    "\n",
    "When we don't know which variables should be included in the model, ideally, you want to select the best model out of *all possible models* of all possible sizes. \n",
    "\n",
    "For example, for a dataset with 2 explanatory variables $X_1$ and $X_2$ there are 4 models to compare: (1) an intercept-only model, (2) a model with only $X_1$, (3) a model with only $X_2$, and (4) a model with both $X_1$ and $X_2$. \n",
    "\n",
    "However, the number of *all possible* models quickly becomes too large, even for a small subset of variables. There are a total of $2p$ models from a set of $p$ variables (without considering interaction terms). For $p = 20$ (i.e., 20 available explanatory variables), we need to evaluate more than a million models. \n",
    "\n",
    "There are methods to search more efficiently for a good model (although it may not find the \"best\" one out of all possible):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58375f80-f466-420b-9241-411d2addc90c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **4.3.1 Forward selection**: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2519d78-7f66-4f27-b2d9-0d8ed19bc52d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Start with the intercept-only model: $Y_i = \\beta_0 + \\varepsilon_i$\n",
    "    - remember that $\\hat{\\beta}_0 = \\bar{y}$ from the training samples, so $\\hat{y}_{0} = \\bar{y}$ for any observation (from the training or the test set)\n",
    "\n",
    "<br>\n",
    "\n",
    "2. Select the best model of each size: \n",
    "    - **Size 1** Considering one variable at a time, evaluate all models of size 1, and choose the best model of size 1 based on a given measure (RSS, F-statistic, adjusted-$R^2$, call it $\\mathcal{M}_1$.   \n",
    "    - **Size 2** Starting with the best size 1 model, add 1 variable and evaluate all models of size 2. Choose the best model of size 2, call it $\\mathcal{M}_2$.\n",
    "    - $\\vdots$ continue until you reach the full model\n",
    "    - **Size p** there's only one full model, call it $\\mathcal{M}_p$.\n",
    "\n",
    "> Note that we can stop this iteration earlier if we want a model of a predetermined size\n",
    "\n",
    "3. Now we have to select the best out of $p$ models: $\\mathcal{M}_1$ (the best model of size 1), $\\mathcal{M}_2$ (the best model of size 2 evaluated), $\\ldots, \\mathcal{M}_p$ (the full model of size $p$)\n",
    "\n",
    "> You can't use the RSS to compare models of different sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33566a-ac4f-410c-b6ee-3733bfa7058f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Other selection procedures include:\n",
    "\n",
    "- **Backward selection**: start with the full model and remove variables, one at a time\n",
    "\n",
    "\n",
    "- **Hybrid selection**: after adding a variable, the method may also remove variables \n",
    "\n",
    "## **4.4 Regularization** \n",
    "\n",
    "Some regularization methods, such as Lasso, offer an alternative way to select a model by penalizing the RSS. Lasso is a different estimation method that estimates coefficients to be exactly zero.\n",
    "They are mainly used when the goal is to predict, but we could also adapt when the purpose is inference. We'll discuss Lasso in the coming lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b17f1c-b122-4337-9cf4-2cef08ce9ddf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **4.5 What is your goal? Inference vs Prediction**\n",
    "\n",
    "Before we assess or select a model there is a more essential question to answer: \n",
    "    \n",
    "<font color=darkred>**What is your goal?**</font>\n",
    "    \n",
    "The evaluation metrics are different depending on the goal of the analysis.\n",
    "    \n",
    "> The estimation methodologies can also differ although we cover only LS in the course\n",
    "   \n",
    "- **Inference**: your primary goal is to understand the relation between a response variable $Y$ and a set of input variables $X_1, \\ldots, X_p$ \n",
    "    \n",
    "    > you estimate the LR using a sample to understand how variables are associated (in the population)\n",
    "    \n",
    "    > you use methods to draw conclusions about the population from the results obtained in the sample (inference)\n",
    "    \n",
    "- **Prediction**: your primary goal is to make predictions about the response $Y$, and you are not so concerned about how you got those predictions\n",
    "    \n",
    "    > you estimate the LR using a sample to make predictions of the response for *new* units (houses, subjects, counties, etc) from the population\n",
    "  \n",
    "**Examples of inference problems**: \n",
    "    \n",
    "- A real estate agent wants to identify factors that are related to the assessed values of homes (e.g., size of houses, age, amenities, etc) \n",
    "    \n",
    "    \n",
    "- Biologists want to verify empirically the central dogma of biology that relates mRNA to protein values \n",
    "    \n",
    "    \n",
    "**Examples of prediction problems**: \n",
    "    \n",
    "\n",
    "- A real estate agent is interested in determining if a house is under- or over-valued given its characteristics (prediction problem)\n",
    "\n",
    "\n",
    "- Biologists want to use mRNA data to predict protein values\n",
    "    \n",
    "**In this worksheet you will learn different methods to evaluate and select appropriate models based on the goal of your study.**\n",
    "    \n",
    "Most of the measures we have seen today are usually used in the context of estimation and inference to build good *generative* models.\n",
    "\n",
    "In the coming classes, we are going to focus on *prediction*: AIC, BIC, $C_P$, cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0ef7b-ecf3-4ce6-a1d1-ac1fbfc18ca6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **5. What have you learned today?**\n",
    "\n",
    "- We have reviewed different metrics to evaluate a model \n",
    "   \n",
    "   \n",
    "- Different metrics should be used depending on the goal of the analysis: inference vs prediction\n",
    "\n",
    "\n",
    "- It is important to understand the set used to compute these metrics: training vs test sets\n",
    "\n",
    "\n",
    "- Different procedures exist to automate an efficient search of a good model: greedy variable selection\n",
    "\n",
    "\n",
    "- The $R^2$, coefficient of determination can be used to compare the sum of squares of the residuals of the fitted model with that of the null model\n",
    "\n",
    "\n",
    "- The $R^2$ is usually interpreted as the part of the variation in the response explained by the model\n",
    "\n",
    "\n",
    "- Many definitions and interpretations of the $R^2$ are for LS estimators of LR containing an intercept\n",
    "\n",
    "- The $R^2$ can not be used to compare models of different sizes since bigger models always have larger $R^2$.\n",
    "\n",
    "\n",
    "- Instead, the $R^2$ can be computed to consider the models' sizes.\n",
    "\n",
    "\n",
    "- The $R^2$ is not a test; it does not provide a probabilistic result, and its distribution is unknown!\n",
    "\n",
    "\n",
    "- Instead, we can use an $F$ test, also refer as ANOVA, to compare nested models\n",
    "\n",
    "    - tests the simultaneous significance of additional coefficients of the full model (not in the reduced model)\n",
    "    \n",
    "    - in particular, we can use it to test the significance of the fitted model over the null model\n",
    "    \n",
    "    \n",
    "- These $F$ tests can be used to select variables. Since we are comparing and testing how the fit changes as we select variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
