---
jupyter:
  jupytext:
    formats: ipynb,Rmd
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.0
  kernelspec:
    display_name: R
    language: R
    name: ir
---

<!-- #region nbgrader={"grade": false, "grade_id": "cell-f1e1d845873036f4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
# Tutorial 09: Introduction to Statistical Modelling and A/B Testing 
<!-- #endregion -->

<!-- #region nbgrader={"grade": false, "grade_id": "cell-82d9926086d47a80", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## Learning Objectives

After completing this week's worksheet and tutorial work, you will be able to:

1. Describe the goals of hypothesis testing, in particular difference in means tests related to A/B testing.
2. Give an example of a problem that requires A/B testing.
3. List methods used to test difference in means between two populations.
4. Interpret the results of hypothesis tests.
5. Explain the relation between type I and type II errors, power and sample size in 2-sample hypothesis testing.
6. Write a computer script to perform difference in means hypothesis testing and compute errors, power and p-values.
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-a2a153352bc44a68', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
# Run this cell before continuing.
library(tidyverse)
library(infer)
library(broom)
library(cowplot)
library(binom)
source("tests_tutorial_09.R")
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-8a0e4c973d199032", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
## 1. Analysis of an A/B Testing Paper

In Worksheet 1, we reviewed key concepts of hypothesis tests to test the difference between two population means and discussed their relation to A/B testing. In this tutorial, you will review concepts related to the difference between two proportions, also seen before in STAT 201.

In this exercise, we will work with the paper ["Improving Library User Experience with A/B Testing: Principles and Process"](https://quod.lib.umich.edu/w/weave/12535642.0001.101?view=text;rgn=main) by Young (2014). This paper presents a case study where A/B testing is applied with different webpage designs. The primary aim is to compare user interactions to determine which one statistically improves the navigation experience by increasing the homepage click-through rate. The experiment was conducted using the web analytics software Google Analytics and Crazy Egg. The data from the paper can be found [here](https://scholarworks.montana.edu/xmlui/handle/1/3507).

The setup was done on the **Interact** category in the Montana State University's library webpage (more information can be found in the section *Step 1* in the paper). The experimental treatments (as explained and shown in *Step 4* in the paper) are the following: **Interact** (the control treatment), **Connect**, **Learn**, **Help**, and **Services**. The response variable is what we call the **click-through rate**, i.e., ratio of users that click on a specific link to the total number of users who view the page (a proportion that goes from 0 to 1).

We have already processed the data for you. Firstly, we load the Crazy Egg data from the web.
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-63b8c78459dc81f1', 'locked': True, 'schema_version': 3, 'solution': False, 'task': False}}
click_through <- 
    read_csv("data/click_through.csv") %>% 
    select(webpage, adjusted_clicks, target_clicks)

head(click_through)
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-6c537789fff51e16", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.0**
<br>{points: 1}

The `adjusted_clicks` in the data frame `click_through` are the total clicks we will use to compute the click-through rate by treatment, where `target_clicks` are what we could define as **“successes”**. Compute the corresponding click-through rate by row by dividing `target_clicks` over `adjusted_clicks`. Add it as a new column in the data frame called `click_rate`. Then, reorder the experimental treatments (i.e., factor levels) in descending order by click-through rate.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-84902e751c5c2aa3', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# click_through <- 
#     ... %>% 
#     mutate(click_rate = ...) %>% 
#     mutate(webpage = fct_reorder(..., desc(...)))

### BEGIN SOLUTION
click_through <- 
    click_through %>% 
    mutate(click_rate = target_clicks/adjusted_clicks) %>% 
    mutate(webpage = fct_reorder(webpage, desc(click_rate)))
### END SOLUTION

click_through
levels(click_through$webpage)
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-1fbf41f936a624e5', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.0()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-2c6561413b54d3c4", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.1**
<br>{points: 1}

The sampled click-through rates in the data frame `click_through` are estimates of population proportions. Hence, it is possible to obtain confidence intervals by relying on the Central Limit Theorem. Obtain the 95% confidence interval for each population click rate and store the lower and upper bounds in two new columns `click_through`: `lower_ci` and `upper_ci`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-a27d500f0b4c420e', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# click_through <- 
#     click_through %>% 
#     ...(lower_ci = ...,
#            upper_ci = ...)

### BEGIN SOLUTION
click_through <- 
    click_through %>% 
    mutate(lower_ci = click_rate - 1.96*sqrt(click_rate*(1-click_rate)/adjusted_clicks),
           upper_ci = click_rate + 1.96*sqrt(click_rate*(1-click_rate)/adjusted_clicks))
### END SOLUTION

click_through
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-c70d7b2c2aa8f378', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.1()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-a283262115be27b8", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.2**
<br>{points: 1}

Let's create an effective visualization for the point estimate click_rate and the confidence intervals you obtained above. The `ggplot()` object's name shoud be `CIs_click_through_rates`.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-41b3cbbf1bc49165', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Plotting click-through rates as points with 95% confidence intervals.
# CIs_click_through_rates <- 
#   click_through %>% 
#   ggplot(aes(..., ...)) +
#   ...() +
#   geom_errorbar(aes(ymin = ..., ymax = ...), width = 0.1) +
#   theme(
#     text = element_text(size = 22),
#     plot.title = element_text(face = "bold"),
#     axis.title = element_text(face = "bold")
#   ) +
#   ggtitle(...) +
#   xlab(...) +
#   ylab(...)

### BEGIN SOLUTION
CIs_click_through_rates <- 
    click_through %>% 
    ggplot(aes(webpage, click_rate)) +
    geom_point() +
    geom_errorbar(aes(ymin = lower_ci, ymax = upper_ci), width = 0.1) +
    scale_y_continuous(labels = scales::percent) +
    theme(
        text = element_text(size = 22),
        plot.title = element_text(face = "bold"),
        axis.title = element_text(face = "bold")
    ) +
    ggtitle("95% Confidence Intervals by Click-Through Rate") +
    xlab("Webpage Version (Experimental Treatment)") +
    ylab("Click-Through Rate")
### END SOLUTION

CIs_click_through_rates
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-062200921c05e43f', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.2()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-bdcee83be072fc15", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.3**
<br>{points: 1}

Based on the findings in the plot `CIs_click_through_rates`, what can we statistically conclude from these confidence intervals?

**A.** We can see that treatment **Connect** has the largest click-through rate among the five treatments. It is statistically larger than the control treatment **Interact**.

**B.** We cannot state that treatment **Connect** is statistically larger than treatment **Services** since their confidence intervals overlap. However, we can state that these two treatments are statistically larger than the control treatment **Interact** and **Learn** given that their corresponding confidence intervals do not overlap.

*Assign your answer to an object called `answer1.3`. Your answer should be one of `"A"` or `"B"` surrounded by quotes.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-314d32111def21c7', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.3 <- 

### BEGIN SOLUTION
answer1.3 <- "B"
### END SOLUTION
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-772a2e6ece3841c1', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.3()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-690cc2c5994c6b30", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.4**
<br>{points: 1}

Recall that the click-through rates by treatment are proportions that go from 0 to 1. We want to compare whether the rate of a given treatment is larger than the rate corresponding to another one. Suppose we rely on the Central Limit Theorem and assume that our sample sizes are large enough. What is the specific analysis we need to perform?

**A.** One-sample $z$-test. 

**B.** One-sample $t$-test.

**C.** Two-sample $z$-test.

**D.** Two-sample $t$-test.

**E.** Two-way ANOVA.

*Assign your answer to an object called `answer1.4`. Your answer should be one of `"A"`, `"B"`, `"C"`, `"D"`, or `"E"` surrounded by quotes.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-4a49471cf41f1f67', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.4 <- 

### BEGIN SOLUTION
answer1.4 <- "C"
### END SOLUTION
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-e76acfb5401abd0f', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.4()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-4b98156347b21735", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.5**
<br>{points: 1}

Let $p_A$ and $p_B$ be the click-through rates of two given treatments **A** and **B**, respectively. Suppose you want to assess whether the click-through rate of treatment **A** is larger than the one corresponding to treatment **B**. What is the set of hypotheses we are testing in this case?

**A.** $H_0: p_A = p_B$ vs. $H_1: p_A > p_B$

**B.** $H_0: p_A > p_B$ vs. $H_1: p_A < p_B$

**C.** $H_0: p_A = p_B$ vs. $H_1: p_A \neq p_B$

**D.** $H_0: p_A = p_B$ vs. $H_1: p_A < p_B$

*Assign your answer to an object called `answer1.5`. Your answer should be one of `"A"`, `"B"`, `"C"`, or `"D"` surrounded by quotes.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-1b95fba9a44c72e9', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.5 <- 

### BEGIN SOLUTION
answer1.5 <- "A"
### END SOLUTION
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-6fa8808a79a82d33', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.5()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-e362f03b9d1a63a9", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.6**
<br>{points: 1}

Perform pairwise frequentist hypothesis test analyses to assess statistically significant differences between all the experimental treatments. This will require control for multiple comparisons. You can use the Bonferroni correction along with the function `pairwise.prop.test()`. Create an object named `pairwise_comparisons`. 

> **Heads-up:** Given the answer in **Question 1.6**, rows in `pairwise_comparisons` will correspond to treatment **A** and columns to treatment **B**.

*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-b02a02d1ffacef41', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# Assigning numbers of "successes" from data frame `click_through`
# successes <- click_through$...

# Assigning numbers of "trials" from data frame `click_through`
# trials <- click_through$...

# Putting labels on vector cells
# names(successes) <- click_through$webpage
# names(trials) <- click_through$webpage

# pairwise_comparisons <- pairwise.prop.test(x = ...,
#   n = ....,
#   p.adjust.method = ..., 
#   alternative = ...,
# )

### BEGIN SOLUTION
successes <- click_through$target_clicks

trials <- click_through$adjusted_clicks

names(successes) <- click_through$webpage
names(trials) <- click_through$webpage

pairwise_comparisons <- pairwise.prop.test(x = successes,
  n = trials,
  p.adjust.method = "bonferroni", 
  alternative = "two.sided",
)

pairwise_comparisons
### END SOLUTION
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-19c172b9d9dea3d5', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.6()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-e322c432c68a60e8", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.7**
<br>{points: 1}

Based on your results in **Question 1.6**, using $\alpha = 0.05$, indicate what experimental treatments have a significantly larger click-through rate than the control **Interact**.

**A.** Connect.

**B.** Learn.

**C.** Help.

**D.** Services.

*Assign your answers to the object `answer1.7`. Your answer has to be a single string indicating the correct treatment labels **in alphabetical order** and surrounded by quotes (e.g., `"ABCD"` indicates you are selecting the four options).*
<!-- #endregion -->

```{r nbgrader={'grade': False, 'grade_id': 'cell-8200f9e61e2c939b', 'locked': False, 'schema_version': 3, 'solution': True, 'task': False}}
# answer1.7 <- 

### BEGIN SOLUTION
answer1.7 <- "AD"
### END SOLUTION
```

```{r nbgrader={'grade': True, 'grade_id': 'cell-8dcfca69365d2a13', 'locked': True, 'points': 1, 'schema_version': 3, 'solution': False, 'task': False}}
test_1.7()
```

<!-- #region nbgrader={"grade": false, "grade_id": "cell-b71652c72a001c12", "locked": true, "schema_version": 3, "solution": false, "task": false} -->
**Question 1.8**
<br>{points: 1}

a) In one or two sentences, explain why a Bonferroni correction is needed to assess the significance of the pairwise the test performed in **Question 1.7**.

b) In one or two sentences, explain how to implement a Bonferroni correction in this case.
<!-- #endregion -->

<!-- #region nbgrader={"grade": true, "grade_id": "cell-1f021334bf7674f3", "locked": false, "points": 1, "schema_version": 3, "solution": true, "task": false} -->
### BEGIN SOLUTION

a) Multiple testing problem: Since the test simultaneously performs 10 pairwise comparisons, the overall probability of a type I error gets inflated and greater than the significance level.

b) We can implement a Bonferroni correction by adjusting the significance level used in each test to be alpha/m, where alpha is the overall significance level and m is the total number of tests. In this case, we can use an adjusted alpha of 0.05/10.

Alternatively, we can adjust the p-value of each test by multiplying it to the number of tests and compare it to the original significance level.

### END SOLUTION
<!-- #endregion -->
